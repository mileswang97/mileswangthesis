{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MRNet-master.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7RQQrFFtr1kC","colab_type":"code","colab":{}},"source":["from google.colab import drive \n","drive.mount('/content/gdrive') \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jqvUXbEDHe0","colab_type":"code","colab":{}},"source":["# model.py\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import models\n","\n","class MRNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        #self.model = models.alexnet(pretrained=True)\n","        #self.model = models.googlenet(pretrained=True)\n","        #self.model = models.densenet169(pretrained=True)\n","        self.model = models.densenet121(pretrained=True)\n","        #self.model = models.densenet161(pretrained=True)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.classifier = nn.Linear(1024, 1)\n","        #self.classifier = nn.Linear(256, 1)\n","\n","    # change this to adapt to different networks\n","    def forward(self, x):\n","        print('x size', x.size())\n","        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n","        #x = torch.squeeze(x)\n","        print('x size', x.size())\n","        x = self.model.features(x)\n","        print('x size', x.size())\n","        # make sure that gap returns size 256\n","        x = self.gap(x).view(x.size(0), -1)\n","        print('x size', x.size())\n","        #print('x size', x.size())\n","        x = torch.max(x, 0, keepdim=True)[0]\n","        print('x size', x.size())\n","        #print('x size max', x.size())\n","        x = self.classifier(x)\n","        print('x size', x.size())\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNtBJxgjDWSi","colab_type":"code","outputId":"5302e370-ea64-4d87-8e3f-e655070804db","executionInfo":{"status":"ok","timestamp":1578708447580,"user_tz":300,"elapsed":13644,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBoamf98Ps_CKrFfYjJMHw0Y9ECEjSVq0loIKKBTN7jqQ0w2SpAV-8WMiM3pKsJoz_wwebVsU0V884Un9dAVFOKEp-PvX6zOXkw7g97cBoJNKU4eP2VmyFKc-6-3cLAJvlfgYpX37ir5N6V--LMmCI59w_AdOiqiJ0j62sewiHfHVFvekdQYsVYt7zt0GHA_xaG50klbLG6oLoFR_s29RG7L2RkXO25Wpkk1o6w24UouiuLnX4HfegO3sIXAj0zz0V95Ubt58gXFT6x7NxaNuqIAxsNVx0SDZBytvxzGrLsGAX_kRE6McHXYi6fBu637WZkz4dEOL3T50LBC07E3xkwv2Qh8IPUKeR7vcLPtf6BudBwFIPqIO5Tfd8z-trJSLEtqJOn4N3HyBvjjGxNAEQV1cQLHZPpc8Ir-U0p0ojLfswl9WQJ9H7TjrmeryFUQ83Kp4pRDpCq2JYQMeSdFuCXJ9GIkdjpUPHqy77uYe5GYaz6stVI3-Cs-9vi5cZsGz9dkxLrbfziPt6lszaR8tyhMWdwtKJOZ_inPVzIZhkd7Q-gwWwl7tI6wQdt71xALYLQZ3pv27yehZVgJfDPc4NYpnb0M7MQv85JdygsoV2qRxdDh5CnbJidEoZVycGVbwNwzgm3AoATq6zcxN3Pfn6XHJGHj5CnUWrHLbN_81qjLSaXlMvmdJA8QReB6zVKdGT-1nOyeg-Fq_rvDEAfPV9fwuzP8daiQMY8unP4l71loLFtsfAv48JSHm3Q3cs=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","\n","        self.transformbool = transformbool\n","        self.transforms = torchvision.transforms.Compose([\n","        #    torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            #torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n","        #    torchvision.transforms.RandomHorizontalFlip(p=1.0),\n","        #    torchvision.transforms.RandomRotation((20,20), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            #torchvision.transforms.Resize((224,224)),\n","        #    torchvision.transforms.ToTensor()\n","        \n","            mt_transforms.CenterCrop2D((200,200)),\n","            mt_transforms.RandomAffine(degrees = 0.0, scale = (1, 1), translate=(0,0)),\n","            mt_transforms.ToTensor()\n","\n","         ])\n","        \n","        self.train_transforms = torchvision.transforms.Compose([\n","            mt_transforms.Resample(0.25, 0.25),\n","            mt_transforms.ElasticTransform(alpha_range=(40.0, 60.0),\n","                                           sigma_range=(2.5, 4.0),\n","                                           p=0.3),\n","            mt_transforms.ToTensor()]\n","        )\n","        \n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","      \n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        path = self.paths[index]\n","        with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","            vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        #vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        #ver_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-20, 20)\n","        #uni_noise = np.random.rand(1)\n","\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","\n","        #if uni_noise < 0.5:\n","        #  noise_array = np.random.uniform(0.9,1.1,224*224)\n","        #  noise_array.resize((224,224))\n","          \n","        #  vol = \n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)),\n","            #torchvision.transforms.RandomVerticalFlip(p=(ver_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        \"\"\"\n","        # see if this transform policy can take in a 3d volume\n","        #vol = np.asarray(vol).astype(np.uint8)\n","        # save the 15th slice to see if transformation happened\n","        #print('volume mean', np.mean(vol, axis=0))\n","        #save_fig = PIL.Image.fromarray(np.uint8(np.array(vol[15,:,:] * 255)))\n","        save_fig = PIL.Image.fromarray(np.uint8(np.array(vol[15,:,:])))\n","        save_fig = save_fig.convert(\"L\")\n","        newpath = str(path).replace('/', ' ')\n","        file_name = \"path\" + newpath + \" transform\" + str(flag) + \" angle\" + str(round(randomangle)) + \"_0.png\"\n","        save_path = Path(rundir) / \"images1\" /  file_name\n","        save_fig.save(save_path)\n","        \"\"\"\n","\n","        #vol = vol.transpose(2,1,0)\n","        #print('vol shape', vol.shape)\n","        #print('vol sum', np.sum(vol))\n","\n","        #print('vol type', vol.dtype)\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","\n","        \"\"\"\n","        save_fig = PIL.Image.fromarray(np.uint8(np.array(vol[15,:,:])))\n","        save_fig = save_fig.convert(\"L\") \n","        #save_fig.show()\n","        #file_name = f'path{path}_transform{flag}_angle{randomangle:0.4f}'\n","        newpath = str(path).replace('/', ' ')\n","        file_name = \"path\" + newpath + \" transform\" + str(flag) + \" angle\" + str(round(randomangle)) + \"_1.png\"\n","        save_path = Path(rundir) / \"images2\" /  file_name\n","        save_fig.save(save_path)\n","\n","        if problemflag:\n","          save_fig = PIL.Image.fromarray(np.uint8(np.array(vol[15,:,:])))\n","          save_fig = save_fig.convert(\"L\") \n","          #save_fig.show()\n","          #file_name = f'path{path}_transform{flag}_angle{randomangle:0.4f}'\n","          newpath = str(path).replace('/', ' ')\n","          file_name = \"path\" + newpath + \" transform\" + str(flag) + \" angle\" + str(round(randomangle)) + \"_1.png\"\n","          save_path = Path(rundir) / \"problems\" /  file_name\n","          save_fig.save(save_path)\n","\n","        \"\"\"  \n","        # normalize\n","        # problems with the normalization, fix\n","        # vol = (vol - MEAN) / STDDEV\n","\n","\n","        #print('vol1', vol.shape)\n","\n","        #print('vol shape', vol.shape)\n","\n","        # convert to RGB\n","        #vol = np.stack((vol,)*3, axis=1)\n","        #print('vol2', vol.shape)\n","\n","        #new_vol = self.transforms(vol).float()\n","        #print('new_vol', new_vol.shape)\n","\n","        #assert(1==2)\n","        #if self.transformbool:\n","        #  vol = np.mean(self.transforms(vol).float(), axis=(0,1))\n","\n","        \"\"\"\n","        save_fig = PIL.Image.fromarray(np.uint8(np.array(vol[15,:,:])))\n","        save_fig = save_fig.convert(\"L\")\n","        #save_fig.show()\n","        #file_name = f'path{path}_transform{flag}_angle{randomangle:0.4f}'\n","        newpath = str(path).replace('/', ' ')\n","        file_name = \"path\" + newpath + \" transform\" + str(flag) + \" angle\" + str(round(randomangle)) + \"_2.png\"\n","        save_path = Path(rundir) / \"images5\" /  file_name\n","        save_fig.save(save_path)\n","        \"\"\"\n","\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","\n","        print('vol shape', vol.shape)\n","\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","        #print('vol tensor shape', vol_tensor.shape)\n","        #print('label_tensor shape', label_tensor.shape)\n","        #assert(1==3)\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(self, diagnosis, use_gpu=True):\n","\n","    #vol_list = ['vol01', 'vol02', 'vol03', 'vol04', 'vol05', 'vol06', 'vol07', 'vol08', 'vol09', 'vol10']\n","    #vol_ind = [0,1,2,3,4,5,6,7,8,9]\n","    \n","    #train_ind = sample(vol_ind, 6)\n","    #train_dirs = [vol_list[i] for i in train_ind]\n","\n","    #val_test_ind = [index for index in vol_ind if index not in train_ind]\n","    #val_ind = sample(val_test_ind, 2)\n","    #valid_dirs = [vol_list[i] for i in val_ind]\n","\n","    #test_ind = [index for index in val_test_ind if index not in val_ind]\n","    #test_dirs = [vol_list[i] for i in test_ind]\n","    train_dirs = ['vol08','vol04','vol03','vol09','vol06','vol07']\n","    valid_dirs = ['vol10','vol05']\n","    test_dirs = ['vol01','vol02']\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_dirs, diagnosis, use_gpu, True)\n","    valid_dataset = Dataset(valid_dirs, diagnosis, use_gpu, False)\n","    test_dataset = Dataset(test_dirs, diagnosis, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting medicaltorch\n","  Downloading https://files.pythonhosted.org/packages/5a/85/b3fa267c6cdec058c937a5046e357de61dda938179aeeca72485f13b1fa2/medicaltorch-0.2-py3-none-any.whl\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n","Installing collected packages: medicaltorch\n","Successfully installed medicaltorch-0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M_Olw5OZDqFc","colab_type":"code","colab":{}},"source":["\n","\n","# evaluate.py\n","\n","import argparse\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import torch\n","\n","from sklearn import metrics\n","from torch.autograd import Variable\n","\n","#from loader import load_data\n","#from model import MRNet\n","\n","def get_parser():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--model_path', type=str, required=True)\n","    parser.add_argument('--split', type=str, required=True)\n","    parser.add_argument('--diagnosis', type=int, required=True)\n","    parser.add_argument('--gpu', action='store_true')\n","    return parser\n","\n","def run_model(model, loader, train=False, optimizer=None):\n","    preds = []\n","    labels = []\n","\n","    if train:\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    total_loss = 0.\n","    num_batches = 0\n","\n","    for batch in loader:\n","        if train:\n","            optimizer.zero_grad()\n","\n","        vol, label = batch\n","        if loader.dataset.use_gpu:\n","            vol = vol.cuda()\n","            label = label.cuda()\n","        vol = Variable(vol)\n","        label = Variable(label)\n","\n","        logit = model.forward(vol)\n","\n","        loss = loader.dataset.weighted_loss(logit, label)\n","        total_loss += loss.item()\n","\n","        pred = torch.sigmoid(logit)\n","        pred_npy = pred.data.cpu().numpy()[0][0]\n","        label_npy = label.data.cpu().numpy()[0][0]\n","\n","        preds.append(pred_npy)\n","        labels.append(label_npy)\n","\n","        if train:\n","            loss.backward()\n","            optimizer.step()\n","        num_batches += 1\n","\n","    avg_loss = total_loss / num_batches\n","\n","    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n","    auc = metrics.auc(fpr, tpr)\n","\n","    return avg_loss, auc, preds, labels\n","\n","def evaluate(split, model_path, diagnosis, use_gpu):\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, use_gpu)\n","\n","    model = MRNet()\n","    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n","    model.load_state_dict(state_dict)\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    if split == 'train':\n","        loader = train_loader\n","    elif split == 'valid':\n","        loader = valid_loader\n","    elif split == 'test':\n","        loader = test_loader\n","    else:\n","        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n","\n","    loss, auc, preds, labels = run_model(model, loader)\n","\n","    print(f'{split} loss: {loss:0.4f}')\n","    print(f'{split} AUC: {auc:0.4f}')\n","\n","    return preds, labels\n","\n","#if __name__ == '__main__':\n","#    args = get_parser().parse_args()\n","#   evaluate(args.split, args.model_path, args.diagnosis, args.gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5_S6k0IDwVi","colab_type":"code","colab":{}},"source":["# train.py\n","\n","import argparse\n","import json\n","import numpy as np\n","import os\n","import torch\n","\n","from datetime import datetime\n","from pathlib import Path\n","from sklearn import metrics\n","\n","#from evaluate import run_model\n","#from loader import load_data\n","#from model import MRNet\n","\n","def train(rundir, diagnosis, epochs, learning_rate, use_gpu):\n","    val_auc_array = list()\n","    train_auc_array = list()\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, use_gpu)\n","    \n","    model = MRNet()\n","    \n","    if use_gpu:\n","        model = model.cuda()\n","\n","    # modify the code in this\n","    # try with RAdam\n","    # grid search?\n","    # can try without weight decay\n","    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=.01)\n","    #optimizer = torch.optim.AdamW(model.parameters(), learning_rate, weight_decay=0.01)\n","\n","    # patience too low (after 5 epochs, if AUC hasnt improved, slash learning rate .3), which is why high learning rate seems to work better\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=.3, threshold=1e-4)\n","\n","    best_val_loss = float('inf')\n","\n","    start_time = datetime.now()\n","\n","    for epoch in range(epochs):\n","        change = datetime.now() - start_time\n","        print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n","        \n","        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer)\n","        print(f'train loss: {train_loss:0.4f}')\n","        print(f'train AUC: {train_auc:0.4f}')\n","\n","        val_loss, val_auc, _, _ = run_model(model, valid_loader)\n","        print(f'valid loss: {val_loss:0.4f}')\n","        print(f'valid AUC: {val_auc:0.4f}')\n","        val_auc_array.append(val_auc)\n","        train_auc_array.append(train_auc)\n","        \n","        scheduler.step(val_loss)\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","\n","            file_name = f'val{val_loss:0.4f}_train{train_loss:0.4f}_epoch{epoch+1}'\n","            save_path = Path(rundir) / file_name\n","\n","            # dont need to save stuff for now, model is too shitty\n","            torch.save(model.state_dict(), save_path)\n","            #if epoch == (epochs-1):\n","            #  print('model saved at', str(save_path))\n","            #  torch.save(model.state_dict(), save_path)\n","            \n","    return val_auc_array, train_auc_array\n","\n","def get_parser():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--rundir', type=str, required=True)\n","    parser.add_argument('--diagnosis', type=int, required=True)\n","    parser.add_argument('--seed', default=42, type=int)\n","    parser.add_argument('--gpu', action='store_true')\n","    parser.add_argument('--learning_rate', default=1e-05, type=float)\n","    parser.add_argument('--weight_decay', default=0.01, type=float)\n","    parser.add_argument('--epochs', default=50, type=int)\n","    parser.add_argument('--max_patience', default=5, type=int)\n","    parser.add_argument('--factor', default=0.3, type=float)\n","    return parser\n","\n","#if __name__ == '__main__':\n","#    args = get_parser().parse_args()\n","    \n","#    np.random.seed(args.seed)\n","#    torch.manual_seed(args.seed)\n","#    if args.gpu:\n","#        torch.cuda.manual_seed_all(args.seed)\n","\n","#    os.makedirs(args.rundir, exist_ok=True)\n","    \n","#    with open(Path(args.rundir) / 'args.json', 'w') as out:\n","#        json.dump(vars(args), out, indent=4)\n","\n","#    train(args.rundir, args.diagnosis, args.epochs, args.learning_rate, args.gpu)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDIZFy0IrqVs","colab_type":"code","outputId":"d17abfae-91a6-43d1-e213-c59976f27510","executionInfo":{"status":"error","timestamp":1578708475438,"user_tz":300,"elapsed":40208,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBoamf98Ps_CKrFfYjJMHw0Y9ECEjSVq0loIKKBTN7jqQ0w2SpAV-8WMiM3pKsJoz_wwebVsU0V884Un9dAVFOKEp-PvX6zOXkw7g97cBoJNKU4eP2VmyFKc-6-3cLAJvlfgYpX37ir5N6V--LMmCI59w_AdOiqiJ0j62sewiHfHVFvekdQYsVYt7zt0GHA_xaG50klbLG6oLoFR_s29RG7L2RkXO25Wpkk1o6w24UouiuLnX4HfegO3sIXAj0zz0V95Ubt58gXFT6x7NxaNuqIAxsNVx0SDZBytvxzGrLsGAX_kRE6McHXYi6fBu637WZkz4dEOL3T50LBC07E3xkwv2Qh8IPUKeR7vcLPtf6BudBwFIPqIO5Tfd8z-trJSLEtqJOn4N3HyBvjjGxNAEQV1cQLHZPpc8Ir-U0p0ojLfswl9WQJ9H7TjrmeryFUQ83Kp4pRDpCq2JYQMeSdFuCXJ9GIkdjpUPHqy77uYe5GYaz6stVI3-Cs-9vi5cZsGz9dkxLrbfziPt6lszaR8tyhMWdwtKJOZ_inPVzIZhkd7Q-gwWwl7tI6wQdt71xALYLQZ3pv27yehZVgJfDPc4NYpnb0M7MQv85JdygsoV2qRxdDh5CnbJidEoZVycGVbwNwzgm3AoATq6zcxN3Pfn6XHJGHj5CnUWrHLbN_81qjLSaXlMvmdJA8QReB6zVKdGT-1nOyeg-Fq_rvDEAfPV9fwuzP8daiQMY8unP4l71loLFtsfAv48JSHm3Q3cs=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":673}},"source":["import os\n","%cd \"/content/gdrive/My Drive/thesis/Data/vols\"\n","\n","#data path\n","train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","data_path = \"/content/gdrive/My Drive/thesis/Data/vols\"\n","#train_meniscus_csv_path = data_path + '/train-meniscus.csv'\n","\n","gpu = True\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","\n","#learningrate = 5e-05\n","epochs = 150\n","diagnosis = 1\n","rundir = data_path\n","\n","if gpu:\n","  torch.cuda.manual_seed_all(seed)\n","\n","# larger learning rates\n","learn1 = 0.0001\n","learn2 = 0.0001\n","learn3 = 0.0001\n","learn4 = 0.0001\n","learn5 = 0.0001\n","\n","varray1, tarray1 = train(rundir, diagnosis, epochs, learn1, gpu)\n","#varray2, tarray2 = train(rundir, diagnosis, epochs, learn2, gpu)\n","#varray3, tarray3 = train(rundir, diagnosis, epochs, learn3, gpu)\n","#varray4, tarray4 = train(rundir, diagnosis, epochs, learn4, gpu)\n","#varray5, tarray5 = train(rundir, diagnosis, epochs, learn5, gpu)\n","\n","varray2, tarray2 = varray1, tarray1\n","varray3, tarray3 = varray1, tarray1\n","varray4, tarray4 = varray1, tarray1\n","varray5, tarray5 = varray1, tarray1\n","\n","def display_line(x_length, lr1, y1, lr2, y2, lr3, y3, lr4, y4, lr5, y5, title, xlabel, ylabel):\n","  plt.figure(0)\n","  # see if we can set axis later\n","  #ax = plt.axis()\n","  #ax.set(xlim = (np.min(x),np.max(x)), option='tight')\n","  plt.title(title)\n","  plt.plot(np.arange(x_length), y1, label=str(lr1))\n","  plt.plot(np.arange(x_length), y2, label=str(lr2))\n","  plt.plot(np.arange(x_length), y3, label=str(lr3))\n","  plt.plot(np.arange(x_length), y4, label=str(lr4))\n","  plt.plot(np.arange(x_length), y5, label=str(lr5))\n","  plt.legend()\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.show()\n","  return\n","\n","display_line(epochs, learn1, varray1, learn2, varray2, learn3, varray3, learn4, varray4, learn5, varray5, \"Trained AlexNet Val AUC over epochs diagnosis = \" + str(diagnosis), \"epoch\", \"Validation AUC\")\n","display_line(epochs, learn1, tarray1, learn2, tarray2, learn3, tarray3, learn4, tarray4, learn5, tarray5, \"Trained AlexNet Train AUC over epochs diagnosis = \" + str(diagnosis), \"epoch\", \"Training AUC\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/thesis/Data/vols\n","['vol08', 'vol04', 'vol03', 'vol09', 'vol06', 'vol07']\n","['vol10', 'vol05']\n","['vol01', 'vol02']\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n","100%|██████████| 30.8M/30.8M [00:01<00:00, 23.0MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000013\n","vol shape (33, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n","vol shape (30, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n","vol shape (30, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n","vol shape (31, 3, 224, 224)\n","vol shape (32, 3, 224, 224)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f38a422b718e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mlearn5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrundir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnosis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#varray2, tarray2 = train(rundir, diagnosis, epochs, learn2, gpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#varray3, tarray3 = train(rundir, diagnosis, epochs, learn3, gpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-a1757180bf56>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rundir, diagnosis, epochs, learning_rate, use_gpu)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting epoch {}. time passed: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train loss: {train_loss:0.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train AUC: {train_auc:0.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-b21009a52346>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, loader, train, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"_WkAra1-5PfZ","colab_type":"code","colab":{}},"source":["\n","#evaluate('test', 'val0.0175_train0.0139_epoch50', 1, True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vX6gABy_8OZ0","colab_type":"code","outputId":"8bf7a5ba-cc25-4a33-a5cf-06a6f79c09cb","executionInfo":{"status":"ok","timestamp":1578485818421,"user_tz":300,"elapsed":18,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAxXHOR7aoQ7neUX4j3X43nPF5A65N2Wokkihg-aGVtT5mGFiUxmuiyql9pyH71gAvx96vhzzjM3B2Zq400qZyKXgoH0SxtOqCX-wNuN95uiWnqX-jTZ75g3zOxQ3ObDoXkKozGcQgmUHivMyjAMnwrNDiA1G3le8xKI85FytcjXIiBYRbmXljab-fPFkwHXJHwhYTHCaPbuBFPPJf6KOQpEivchS9mh_b1B7Xua1UsINHPGJyekG5bx28biFl0T2YnnDM2lhDhhl740EYwgywXWwA2jHbIfv5TMdX41ctKoJWdLQYimW_vjzgUP5GDNkBAg8Cd-a9TnP71Fdh1rP4COqhvw2sm4jigv3vCYmeEJs5G2M2yrciAO6eLoj6zqPfAGGA32102SLlwfzMLM4hGaUhOMtZFZdq3_4XaWvtbmF4iyVFVBK1MZnRapGMY7c9McVpbSKH86-6UBKofdAeao4eyhOk2pcdapL_JIU-lwuW9t1r7l_DliZgWzQZnOxkmXionVJiIP6e1_Gqe2cXyHP3rgpYdb-euf8Mn-Gf885_GwKSg0-lInDtQXexnAYz0ntrfEdZ9ScKL5P6ctseCdm-17jtujOVsLWhYJJAYV36C5l8vhjGAIvR84VMJ6OStiZJlTljtElsU7gsgypRfA9Buoq9U1XhunriDwXIdtfW-vvLraTlt8OvbwPJcv_R3Q_Gf3oDvH3IZK5yrULgJPwR9r3MpWFbfIaMQo5Zl1YQYSzX_pzibn4dsIRc=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["\n","def display1_line(x_length, lr1, y1, lr2, y2, lr3, y3, lr4, y4, lr5, y5, title, xlabel, ylabel):\n","  plt.figure(0)\n","  # see if we can set axis later\n","  #ax = plt.axis()\n","  #ax.set(xlim = (np.min(x),np.max(x)), option='tight')\n","  plt.title(title)\n","  plt.plot(np.arange(x_length), y1, label=str(lr1))\n","  plt.plot(np.arange(x_length), y2, label=str(lr2))\n","  plt.plot(np.arange(x_length), y3, label=str(lr3))\n","  plt.plot(np.arange(x_length), y4, label=str(lr4))\n","  plt.plot(np.arange(x_length), y5, label=str(lr5))\n","  plt.legend()\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.show()\n","  return\n","\n","display1_line(epochs, 5e-06, varray1, 1e-05, varray2, 5e-05, varray3, 1e-04, varray4, 1e-03, varray5, \"AUC loss over epochs diagnosis = \" + str(diagnosis), \"epoch\", \"Validation AUC\")"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFIKIiJ5LIYiI6LkUgoiInkshiIjouX8B1urNfG2JUUIAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"bg-KWGHW8Wlo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJPhauQm8X4F","colab_type":"code","colab":{}},"source":["# notes from ben\n","# get rid of double standardization, dont have RGB channels all have same information, make AlexNet take 1 channel instead of 3. \n","# try to dissect images into two camps, 3.0T and 1.5T.\n","# Then we can try to change into DenseNets. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4L4xN-i77gB2","colab_type":"code","outputId":"bcf2b0ad-047d-4947-dbd3-a88f63f05099","executionInfo":{"status":"error","timestamp":1578485818793,"user_tz":300,"elapsed":26,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAxXHOR7aoQ7neUX4j3X43nPF5A65N2Wokkihg-aGVtT5mGFiUxmuiyql9pyH71gAvx96vhzzjM3B2Zq400qZyKXgoH0SxtOqCX-wNuN95uiWnqX-jTZ75g3zOxQ3ObDoXkKozGcQgmUHivMyjAMnwrNDiA1G3le8xKI85FytcjXIiBYRbmXljab-fPFkwHXJHwhYTHCaPbuBFPPJf6KOQpEivchS9mh_b1B7Xua1UsINHPGJyekG5bx28biFl0T2YnnDM2lhDhhl740EYwgywXWwA2jHbIfv5TMdX41ctKoJWdLQYimW_vjzgUP5GDNkBAg8Cd-a9TnP71Fdh1rP4COqhvw2sm4jigv3vCYmeEJs5G2M2yrciAO6eLoj6zqPfAGGA32102SLlwfzMLM4hGaUhOMtZFZdq3_4XaWvtbmF4iyVFVBK1MZnRapGMY7c9McVpbSKH86-6UBKofdAeao4eyhOk2pcdapL_JIU-lwuW9t1r7l_DliZgWzQZnOxkmXionVJiIP6e1_Gqe2cXyHP3rgpYdb-euf8Mn-Gf885_GwKSg0-lInDtQXexnAYz0ntrfEdZ9ScKL5P6ctseCdm-17jtujOVsLWhYJJAYV36C5l8vhjGAIvR84VMJ6OStiZJlTljtElsU7gsgypRfA9Buoq9U1XhunriDwXIdtfW-vvLraTlt8OvbwPJcv_R3Q_Gf3oDvH3IZK5yrULgJPwR9r3MpWFbfIaMQo5Zl1YQYSzX_pzibn4dsIRc=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["p-values[rot, crop, shift] = [0.3, 0.4, 0.5]\n","\n","for every image in folder:\n","  load image\n","\n","  if random number generator < p-values rot:\n","    image = rotate image (by x degrees)\n","  if random number generator < p-values crop:\n","    image = crop image (by x,y values)\n","  if random number generator < p-values shift:\n","    image = shift image (by x values in y direction)\n","\n","  convert image into tensor for processing\n","  send image to training batch, grab next image"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-bc7f5fcd9e16>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for every image in folder:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","metadata":{"id":"rEu3cRZK7fgG","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"6o5ou_z-8axx","colab_type":"code","colab":{}},"source":["define initial state of model\n","(Lets say a simple model of 3 layers, with ReLU activation functions and\n"," down-sampling method of max pool. Input image is 256x256)\n","features = Sequential model: \n","  Layer: Convolutional 2 dimensional (256 input, 128 output, padding = 2)\n","  Activation Function: ReLU\n","  Down-Sample: maxpool\n","  Layer: Convolutional 2 dimensional (128 input, 64 output, padding = 2)\n","  Activation Function: ReLU\n","  Down-Sample: maxpool\n","  Layer: Convolutional 2 dimensional (64 input, 32 output, padding = 2)\n","  Activation Function: ReLU\n","  Down-Sample: maxpool\n","\n","  Layer: Softmax (to convert a 32x32 matrix to probability distribution used to classify)\n"],"execution_count":0,"outputs":[]}]}