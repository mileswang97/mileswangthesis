{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"sg-uUxX5Ydry","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":760},"outputId":"d845dc0f-96df-4d55-f07b-161a91c97b0d","executionInfo":{"status":"error","timestamp":1574447531190,"user_tz":300,"elapsed":11532,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB4eNaCHlOTa7lni7D4Cpf35nBFSqIxgpUw8VxVaqIGlUaQUj55F5JdG717W4IRFBNs3qN-Y8T0FmTPWnALgS7SYNlDVTgY8Wmx_Hy91why3PZVd4ftuq0Ta3VC972d3V-H7WdegXPHkZ99JPBftI5zSUnXnyzOCu9aMfiFaUJQp2tkbK7c1JYiOdjatItjR0kiq9tYsNJ867nmPNspoYiDIOVMao-Qo_vMrZnfDqWRh2073To3MyBr6mVInn3B8xfYVpUa_tQCaqV97wyX5rOf1l1tb_5abB3ihlMmy39OqbV72AuEi2hp760lam1R2taxPqZPpkQMUPQGZmgtFKqVdBR1-wF2701_9Q7rYe-2Gs4tSSy2FMjEeZOxfvpsTMeRcpoQFnX3Q02bv5g-Nz_n3SwbW3JlF_rKdq3mRKppFQROK-VmA90XTqN0FgJKHVTF9SGCRZe_qow1iwUc0n5IpYzHHqtnyo52y1lf-qE1iERw6Nnx3Tz7zwhBVIhGhcm1T7yZJSAV8cPRm1Sdw4j855ZNqTgMd6gnltjStldRRupVK6fmq17pGZp28N7oy9PT2Jg-P-jlIzrYUaR6lwQXdjt0nkf76YP0Cnl1fdd2tE7SVhOO-yDckPAo3Rn5i1deAC0Q_GcFM1DALyZ2q0S6nzO29seSpM9r5PMLOD8F7pZqjfKkuXjDzGlMl07fy0gREQVDE9uKfrQLoBCke5js-klThTqpj8B1DyNTmGhykGHxURAp5fVSzZYKfAY=s64","userId":"12217843719772555429"}}},"source":["\n","!pip install tensorboardx\n","!pip install medicaltorch\n","\n","from collections import defaultdict\n","import time\n","import os\n","\n","import numpy as np\n","\n","from tqdm import tqdm\n","\n","from tensorboardX import SummaryWriter\n","\n","from medicaltorch import datasets as mt_datasets\n","from medicaltorch import models as mt_models\n","from medicaltorch import transforms as mt_transforms\n","from medicaltorch import losses as mt_losses\n","from medicaltorch import metrics as mt_metrics\n","from medicaltorch import filters as mt_filters\n","\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch import autograd, optim\n","import torch.backends.cudnn as cudnn\n","import torch.nn as nn\n","\n","import torchvision.utils as vutils\n","\n","cudnn.benchmark = True\n","\n","\n","def threshold_predictions(predictions, thr=0.999):\n","    thresholded_preds = predictions[:]\n","    low_values_indices = thresholded_preds < thr\n","    thresholded_preds[low_values_indices] = 0\n","    low_values_indices = thresholded_preds >= thr\n","    thresholded_preds[low_values_indices] = 1\n","    return thresholded_preds\n","\n","\n","def run_main():\n","    train_transform = transforms.Compose([\n","        mt_transforms.CenterCrop2D((200, 200)),\n","        mt_transforms.ElasticTransform(alpha_range=(28.0, 30.0),\n","                                       sigma_range=(3.5, 4.0),\n","                                       p=0.3),\n","        mt_transforms.RandomAffine(degrees=4.6,\n","                                   scale=(0.98, 1.02),\n","                                   translate=(0.03, 0.03)),\n","        mt_transforms.RandomTensorChannelShift((-0.10, 0.10)),\n","        mt_transforms.ToTensor(),\n","        mt_transforms.NormalizeInstance(),\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        mt_transforms.CenterCrop2D((200, 200)),\n","        mt_transforms.ToTensor(),\n","        mt_transforms.NormalizeInstance(),\n","    ])\n","\n","    # Here we assume that the SC GM Challenge data is inside the folder\n","    # \"../data\" and it was previously resampled.\n","    gmdataset_train = mt_datasets.SCGMChallenge2DTrain(root_dir=\"../data\",\n","                                                       subj_ids=range(1, 9),\n","                                                       transform=train_transform,\n","                                                       slice_filter_fn=mt_filters.SliceFilter())\n","\n","    # Here we assume that the SC GM Challenge data is inside the folder\n","    # \"../data\" and it was previously resampled.\n","    gmdataset_val = mt_datasets.SCGMChallenge2DTrain(root_dir=\"../data\",\n","                                                     subj_ids=range(9, 11),\n","                                                     transform=val_transform)\n","\n","    train_loader = DataLoader(gmdataset_train, batch_size=16,\n","                              shuffle=True, pin_memory=True,\n","                              collate_fn=mt_datasets.mt_collate,\n","                              num_workers=1)\n","\n","    val_loader = DataLoader(gmdataset_val, batch_size=16,\n","                            shuffle=True, pin_memory=True,\n","                            collate_fn=mt_datasets.mt_collate,\n","                            num_workers=1)\n","\n","    model = mt_models.Unet(drop_rate=0.4, bn_momentum=0.1)\n","    model.cuda()\n","\n","    num_epochs = 200\n","    initial_lr = 0.001\n","\n","    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n","\n","    writer = SummaryWriter(log_dir=\"log_exp\")\n","    for epoch in tqdm(range(1, num_epochs+1)):\n","        start_time = time.time()\n","\n","        scheduler.step()\n","\n","        lr = scheduler.get_lr()[0]\n","        writer.add_scalar('learning_rate', lr, epoch)\n","\n","        model.train()\n","        train_loss_total = 0.0\n","        num_steps = 0\n","        for i, batch in enumerate(train_loader):\n","            input_samples, gt_samples = batch[\"input\"], batch[\"gt\"]\n","\n","            var_input = input_samples.cuda()\n","            var_gt = gt_samples.cuda(non_blocking=True)\n","\n","            preds = model(var_input)\n","\n","            loss = mt_losses.dice_loss(preds, var_gt)\n","            train_loss_total += loss.item()\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            num_steps += 1\n","\n","            if epoch % 5 == 0:\n","                grid_img = vutils.make_grid(input_samples,\n","                                            normalize=True,\n","                                            scale_each=True)\n","                writer.add_image('Input', grid_img, epoch)\n","\n","                grid_img = vutils.make_grid(preds.data.cpu(),\n","                                            normalize=True,\n","                                            scale_each=True)\n","                writer.add_image('Predictions', grid_img, epoch)\n","\n","                grid_img = vutils.make_grid(gt_samples,\n","                                            normalize=True,\n","                                            scale_each=True)\n","                writer.add_image('Ground Truth', grid_img, epoch)\n","\n","        train_loss_total_avg = train_loss_total / num_steps\n","\n","        model.eval()\n","        val_loss_total = 0.0\n","        num_steps = 0\n","\n","        metric_fns = [mt_metrics.dice_score,\n","                      mt_metrics.hausdorff_score,\n","                      mt_metrics.precision_score,\n","                      mt_metrics.recall_score,\n","                      mt_metrics.specificity_score,\n","                      mt_metrics.intersection_over_union,\n","                      mt_metrics.accuracy_score]\n","\n","        metric_mgr = mt_metrics.MetricManager(metric_fns)\n","\n","        for i, batch in enumerate(val_loader):\n","            input_samples, gt_samples = batch[\"input\"], batch[\"gt\"]\n","\n","            with torch.no_grad():\n","                var_input = input_samples.cuda()\n","                var_gt = gt_samples.cuda(async=True)\n","\n","                preds = model(var_input)\n","                loss = mt_losses.dice_loss(preds, var_gt)\n","                val_loss_total += loss.item()\n","\n","            # Metrics computation\n","            gt_npy = gt_samples.numpy().astype(np.uint8)\n","            gt_npy = gt_npy.squeeze(axis=1)\n","\n","            preds = preds.data.cpu().numpy()\n","            preds = threshold_predictions(preds)\n","            preds = preds.astype(np.uint8)\n","            preds = preds.squeeze(axis=1)\n","\n","            metric_mgr(preds, gt_npy)\n","\n","            num_steps += 1\n","\n","        metrics_dict = metric_mgr.get_results()\n","        metric_mgr.reset()\n","\n","        writer.add_scalars('metrics', metrics_dict, epoch)\n","\n","        val_loss_total_avg = val_loss_total / num_steps\n","\n","        writer.add_scalars('losses', {\n","                                'val_loss': val_loss_total_avg,\n","                                'train_loss': train_loss_total_avg\n","                            }, epoch)\n","\n","        end_time = time.time()\n","        total_time = end_time - start_time\n","        tqdm.write(\"Epoch {} took {:.2f} seconds.\".format(epoch, total_time))\n","\n","        writer.add_scalars('losses', {\n","                                'train_loss': train_loss_total_avg\n","                            }, epoch)\n","\n","\n","if __name__ == '__main__':\n","    run_main()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (1.9)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.17.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.12.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx) (41.6.0)\n","Collecting medicaltorch\n","  Downloading https://files.pythonhosted.org/packages/5a/85/b3fa267c6cdec058c937a5046e357de61dda938179aeeca72485f13b1fa2/medicaltorch-0.2-py3-none-any.whl\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.2)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.4)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (4.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.2.1->medicaltorch) (0.46)\n","Installing collected packages: medicaltorch\n","Successfully installed medicaltorch-0.2\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/site1-sc01-image.nii.gz'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2177bada20a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mrun_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-2177bada20a4>\u001b[0m in \u001b[0;36mrun_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                                                        \u001b[0msubj_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                                                        \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                                                        slice_filter_fn=mt_filters.SliceFilter())\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Here we assume that the SC GM Challenge data is inside the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, slice_axis, site_ids, subj_ids, rater_ids, cache, transform, slice_filter_fn, canonical, labeled)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         super().__init__(self.filename_pairs, slice_axis, cache,\n\u001b[0;32m--> 401\u001b[0;31m                          transform, slice_filter_fn, canonical)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename_pairs, slice_axis, cache, transform, slice_filter_fn, canonical)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanonical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m_load_filenames\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             segpair = SegmentationPair2D(input_filename, gt_filename,\n\u001b[0;32m--> 219\u001b[0;31m                                          self.cache, self.canonical)\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/medicaltorch/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_filename, gt_filename, cache, canonical)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Unlabeled data (inference time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nibabel/loadsave.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mstat_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or no access: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstat_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImageFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '../data/site1-sc01-image.nii.gz'"]}]},{"cell_type":"code","metadata":{"id":"-MPFjAmrYgge","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}