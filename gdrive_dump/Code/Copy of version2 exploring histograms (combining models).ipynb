{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of version2 exploring histograms (combining models).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7RQQrFFtr1kC","colab_type":"code","outputId":"4676bafc-1bfe-4658-8848-0aec2a351ecb","executionInfo":{"status":"ok","timestamp":1582077342617,"user_tz":300,"elapsed":25659,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGagKYhu1qG1yM9u-FyidIF__o8pTCsx4sFN83bndp8pKxBjbPmYOxyUk80IJiIg57G6z9fvN0xZtqxlzq_C9vf9hxXYwblK0fSnKD4xePgv5McnzcjCM69eaicuXfV49EoRfgWeYSRzFmeamgllEZh2sFtmxnHoWZAOKOS25TQDDSas7ATeB34kHUWDBY7BlId6EHxNb0cxKhgbGVyn9NhBptDDfV1d2Dxzt3YteS7Yj1_s75gkB-9p5R5WhzJEYvSr1NR8Y22s6lWwLGfvGZ41fPvnkbCI7K4wpHjC6gkQdyP5EAePaoNTwYdRBwlu-ujNX0_mDMBHWOa2ZqzmwkC_7RF7G1r6DZKveMoKc2JvUCj75FoVlmIUWQtgOuaBiFy3APTK-ogQgfIEBulAYksLf9BOWqHbAQ-ubc4Ma37DXzsH_yI9h17oUXH0CT5iufCQ4fvv50wVx4b6sdBGNd17Jue7gN7ym_W7vwOPc61Azqoi3VeN6Az39U6UGp5FjZ_yLmTpRKnbrJnrygpHPRNZ9KJ6xQabkQpdSEuVkUBosooemIR1_hp3al-W4VcGW1ttxUwBnBeHBDXhvKehFP71Iv3Bsqe_2AWd-HvjW68JsT_kzR0hb-TybEhiz5viiwz15KdXyTGoXvMbUvE9QOXRfLX8i2VLrafMLIFORa-HjkjKdvWQtCe_LFGGLCCRkxrqFcEaQ9TZ9oB_REt-dkTYRs4JLz4RzF0qQhw6npkfWTQxbMAgFGSMGRGno=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ZaXWwCucA__","colab_type":"code","outputId":"f688343b-46fc-4f04-96b1-7a2bf1a35468","executionInfo":{"status":"ok","timestamp":1582078186773,"user_tz":300,"elapsed":373,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCGagKYhu1qG1yM9u-FyidIF__o8pTCsx4sFN83bndp8pKxBjbPmYOxyUk80IJiIg57G6z9fvN0xZtqxlzq_C9vf9hxXYwblK0fSnKD4xePgv5McnzcjCM69eaicuXfV49EoRfgWeYSRzFmeamgllEZh2sFtmxnHoWZAOKOS25TQDDSas7ATeB34kHUWDBY7BlId6EHxNb0cxKhgbGVyn9NhBptDDfV1d2Dxzt3YteS7Yj1_s75gkB-9p5R5WhzJEYvSr1NR8Y22s6lWwLGfvGZ41fPvnkbCI7K4wpHjC6gkQdyP5EAePaoNTwYdRBwlu-ujNX0_mDMBHWOa2ZqzmwkC_7RF7G1r6DZKveMoKc2JvUCj75FoVlmIUWQtgOuaBiFy3APTK-ogQgfIEBulAYksLf9BOWqHbAQ-ubc4Ma37DXzsH_yI9h17oUXH0CT5iufCQ4fvv50wVx4b6sdBGNd17Jue7gN7ym_W7vwOPc61Azqoi3VeN6Az39U6UGp5FjZ_yLmTpRKnbrJnrygpHPRNZ9KJ6xQabkQpdSEuVkUBosooemIR1_hp3al-W4VcGW1ttxUwBnBeHBDXhvKehFP71Iv3Bsqe_2AWd-HvjW68JsT_kzR0hb-TybEhiz5viiwz15KdXyTGoXvMbUvE9QOXRfLX8i2VLrafMLIFORa-HjkjKdvWQtCe_LFGGLCCRkxrqFcEaQ9TZ9oB_REt-dkTYRs4JLz4RzF0qQhw6npkfWTQxbMAgFGSMGRGno=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","%cd \"/content/gdrive/My Drive/thesis/Data\"\n","\n","#csv import labels\n","\n","train_ACL_labels = np.array(pd.read_csv(\"train-acl.csv\", header=None).iloc[:,1])\n","train_abnormal_labels = np.array(pd.read_csv(\"train-abnormal.csv\", header=None).iloc[:,1])\n","train_meniscus_labels = np.array(pd.read_csv(\"train-meniscus.csv\", header=None).iloc[:,1])\n","\n","valid_ACL_labels = np.array(pd.read_csv(\"valid-acl.csv\", header=None).iloc[:,1])\n","valid_abnormal_labels = np.array(pd.read_csv(\"valid-abnormal.csv\", header=None).iloc[:,1])\n","valid_meniscus_labels = np.array(pd.read_csv(\"valid-meniscus.csv\", header=None).iloc[:,1])\n","\n","test_ACL_labels = np.array(pd.read_csv(\"test-acl.csv\", header=None).iloc[:,1])\n","test_abnormal_labels = np.array(pd.read_csv(\"test-abnormal.csv\", header=None).iloc[:,1])\n","test_meniscus_labels = np.array(pd.read_csv(\"test-meniscus.csv\", header=None).iloc[:,1])\n","\n","#data path\n","train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","train_axial_path = \"/content/gdrive/My Drive/thesis/Data/train/coronal\"\n","\n","counter = 5\n","for filename in os.listdir(train_axial_path):\n","  if counter > 0:\n","    file0 = np.load(train_axial_path + '/' + filename)\n","    variancelist = []\n","    for slice in range(file0.shape[0]):\n","      variancelist.append(np.var(file0[slice,:,:]))\n","    #print(file0)\n","    #print('max', np.amax(file0))\n","    #print('mean', np.mean(file0))\n","    #print(filename, 'file shape', file0.shape, 'max_var_index', variancelist.index(max(variancelist)), max(variancelist))\n","    counter = counter - 1\n","\n","print(\"done!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/thesis/Data\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7jqvUXbEDHe0","colab_type":"code","colab":{}},"source":["# model.py\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import models\n","\n","class MRNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = models.alexnet(pretrained=True)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.classifier = nn.Linear(256, 1)\n","\n","    # change this to adapt to different networks\n","    def forward(self, x):\n","        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n","        x = self.model.features(x)\n","        # make sure that gap returns size 256\n","        x = self.gap(x).view(x.size(0), -1)\n","        x = torch.max(x, 0, keepdim=True)[0]\n","        x = self.classifier(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0SjKDlPZ7XP","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import numpy as np\n","import os\n","import torch\n","from datetime import datetime\n","from pathlib import Path\n","from sklearn import metrics\n","\n","def train(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu):\n","    \n","    val_auc_array = list()\n","    train_auc_array = list()\n","    test_auc_array = list()\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    \n","    model = MRNet()\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=.01)\n","\n","    # patience too low (after 5 epochs, if AUC hasnt improved, slash learning rate .3), which is why high learning rate seems to work better\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=.3, threshold=1e-4)\n","\n","    best_val_loss = float('inf')\n","\n","    start_time = datetime.now()\n","\n","    for epoch in range(epochs):\n","      change = datetime.now() - start_time\n","      print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n","\n","      train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer)\n","      #print(f'train loss: {train_loss:0.4f}')\n","      #print(f'train AUC: {train_auc:0.4f}')\n","\n","      val_loss, val_auc, _, _ = run_model(model, valid_loader)\n","      #print(f'valid loss: {val_loss:0.4f}')\n","      #print(f'valid AUC: {val_auc:0.4f}')\n","\n","      test_loss, test_auc, _, _ = run_model(model, test_loader)\n","\n","      val_auc_array.append(val_auc)\n","      train_auc_array.append(train_auc)\n","      test_auc_array.append(test_auc)\n","      \n","      scheduler.step(val_loss)\n","\n","      \"\"\"\n","      if val_loss < best_val_loss:\n","          best_val_loss = val_loss\n","\n","          file_name = f'val{val_loss:0.4f}_train{train_loss:0.4f}_epoch{epoch+1}'\n","          save_path = Path(rundir) / file_name\n","\n","          # dont need to save stuff for now, model is too shitty\n","          #torch.save(model.state_dict(), save_path)\n","          #if epoch == (epochs-1):\n","          #  print('model saved at', str(save_path))\n","          #  torch.save(model.state_dict(), save_path)\n","      \"\"\"\n","    return val_auc_array, train_auc_array, test_auc_array"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"9e9a14cc-4447-4d6e-ba96-06dd05a52fcb","executionInfo":{"status":"ok","timestamp":1582079770804,"user_tz":300,"elapsed":3337,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBbs-Dgg3BFwJMs6qgHg0I39enL0mUgCrOBVQS5MocnwQIxNk9jpMXA0kXPTkoRQwN9QlWtqWkpf6UidWvjTO1_2kAER171naEg4iit66iRpR3FR3O2WARLpQ-a0c34c_S18VcNk93RLWE5PLa017FwsB7ZQ7wf6SQY_LLKvI1Zn-NAlEkGI2bo1HVMgWGUfYKQyMBr8CVt9Hpv9esSaaflnKIzemcJed4R2yzT6sbW4piAMZVOYAmh3rErF1BqNXo10mtjNyijERm8yk526JozY-hQHfki3fYSeMRjktYMHJNg60fag_1PfMngP57e0aMLXnsE_R3JvCxpBJAwyqnk_bDiW2Hxo3NBnLSYo04Wz3Vv7fcsYPF0NQEJ-LUgTFNvztwwfO0nLtsN-wEi7ZddAJq3pqUD3iLjydNCrGaqC-JZMjLb22MjTDglElRHH8xsrZ0kfA8EEpRxOUcK7KHmleyC639fK3a9C07YZlMh4Dtu3Tmiek3XKQ8BXdTmpNS_jOGIqjWl7zRgPGY3JWW1t2jTXIj4tCFodKiED9wmdGqVYaq73nwzRLw6f5ZByO98jK5HS-FDxv5PkYDmqMGUzwi-HAkGFPB5Efd-f2vly7yCvcMxRsTRycI_Z9ZENkvH8V_nDb1JruKfq7zXXCsbw4aO5TgJDK78sEpi4JPrCmGBGZkDObtStKt1H7t7N7H38WNzKzyBs-IeIIr62S1eC13HVsMOGTW-wW09bRK-3T8o6cZ1vbFjnZ0EwDE=s64","userId":"12217843719772555429"}},"id":"2H9wZCt37K4H","colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-20, 20)\n","        uni_noise = np.random.rand(1)\n","\n","        print('randomangle', randomangle)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \"\"\"\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.8,1.2,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \"\"\"\n","\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomAffine((randomangle,randomangle + 1e-9), resample=PIL.Image.BILINEAR),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.5.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.0)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"06tlGPqT7LKR","colab":{}},"source":["# evaluate.py\n","\n","import argparse\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import torch\n","\n","from sklearn import metrics\n","from torch.autograd import Variable\n","\n","#from loader import load_data\n","#from model import MRNet\n","\n","def get_parser():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--model_path', type=str, required=True)\n","    parser.add_argument('--split', type=str, required=True)\n","    parser.add_argument('--diagnosis', type=int, required=True)\n","    parser.add_argument('--gpu', action='store_true')\n","    return parser\n","\n","def run_model(model, loader, train=False, optimizer=None):\n","    preds = []\n","    labels = []\n","\n","    if train:\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    total_loss = 0.\n","    num_batches = 0\n","\n","    for batch in loader:\n","        if train:\n","            optimizer.zero_grad()\n","\n","        vol, label = batch\n","        if loader.dataset.use_gpu:\n","            vol = vol.cuda()\n","            label = label.cuda()\n","        vol = Variable(vol)\n","        label = Variable(label)\n","\n","        logit = model.forward(vol)\n","\n","        loss = loader.dataset.weighted_loss(logit, label)\n","        total_loss += loss.item()\n","\n","        #\n","        pred = torch.sigmoid(logit)\n","        pred_npy = pred.data.cpu().numpy()[0][0]\n","        label_npy = label.data.cpu().numpy()[0][0]\n","\n","        preds.append(pred_npy)\n","        labels.append(label_npy)\n","\n","        if train:\n","            loss.backward()\n","            optimizer.step()\n","        num_batches += 1\n","\n","    avg_loss = total_loss / num_batches\n","\n","    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n","    auc = metrics.auc(fpr, tpr)\n","\n","    return avg_loss, auc, preds, labels\n","\n","def evaluate(split, model_path, diagnosis, orientation, use_gpu):\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    model = MRNet()\n","    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n","    model.load_state_dict(state_dict)\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    if split == 'train':\n","        loader = train_loader\n","    elif split == 'valid':\n","        loader = valid_loader\n","    elif split == 'test':\n","        loader = test_loader\n","    else:\n","        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n","\n","    loss, auc, preds, labels = run_model(model, loader)\n","\n","    print(f'{split} loss: {loss:0.4f}')\n","    print(f'{split} AUC: {auc:0.4f}')\n","\n","    return preds, labels\n","\n","#if __name__ == '__main__':\n","#    args = get_parser().parse_args()\n","#   evaluate(args.split, args.model_path, args.diagnosis, args.gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q7WHZv0b7L10","colab":{}},"source":["import matplotlib\n","matplotlib.use('Agg')\n","gpu = True\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","#learningrate = 5e-05\n","epochs = 100\n","#diagnosis = 'ACL'\n","rundir = \"/content/gdrive/My Drive/thesis/Data\"\n","#orientation = 'axial'\n","savedir = \"/content/gdrive/My Drive/thesis/Results/round2\"\n","\n","\n","if gpu:\n","  torch.cuda.manual_seed_all(seed)\n","\n","def display_single(x_length, lr1, varray, tarray, testarray, title, xlabel, ylabel, save_dir):\n","  plt.figure(0)\n","  plt.title(title)\n","  plt.plot(np.arange(x_length), varray, label='valid')\n","  plt.plot(np.arange(x_length), tarray, label='train')\n","  plt.plot(np.arange(x_length), testarray, label='test')\n","  plt.legend()\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.savefig(save_dir + '/' + title + '.eps', format='eps')\n","  plt.show()\n","  plt.close()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"1cb586b2-899a-4921-bf53-8ad1625e621c","executionInfo":{"status":"error","timestamp":1582079785896,"user_tz":300,"elapsed":10849,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBbs-Dgg3BFwJMs6qgHg0I39enL0mUgCrOBVQS5MocnwQIxNk9jpMXA0kXPTkoRQwN9QlWtqWkpf6UidWvjTO1_2kAER171naEg4iit66iRpR3FR3O2WARLpQ-a0c34c_S18VcNk93RLWE5PLa017FwsB7ZQ7wf6SQY_LLKvI1Zn-NAlEkGI2bo1HVMgWGUfYKQyMBr8CVt9Hpv9esSaaflnKIzemcJed4R2yzT6sbW4piAMZVOYAmh3rErF1BqNXo10mtjNyijERm8yk526JozY-hQHfki3fYSeMRjktYMHJNg60fag_1PfMngP57e0aMLXnsE_R3JvCxpBJAwyqnk_bDiW2Hxo3NBnLSYo04Wz3Vv7fcsYPF0NQEJ-LUgTFNvztwwfO0nLtsN-wEi7ZddAJq3pqUD3iLjydNCrGaqC-JZMjLb22MjTDglElRHH8xsrZ0kfA8EEpRxOUcK7KHmleyC639fK3a9C07YZlMh4Dtu3Tmiek3XKQ8BXdTmpNS_jOGIqjWl7zRgPGY3JWW1t2jTXIj4tCFodKiED9wmdGqVYaq73nwzRLw6f5ZByO98jK5HS-FDxv5PkYDmqMGUzwi-HAkGFPB5Efd-f2vly7yCvcMxRsTRycI_Z9ZENkvH8V_nDb1JruKfq7zXXCsbw4aO5TgJDK78sEpi4JPrCmGBGZkDObtStKt1H7t7N7H38WNzKzyBs-IeIIr62S1eC13HVsMOGTW-wW09bRK-3T8o6cZ1vbFjnZ0EwDE=s64","userId":"12217843719772555429"}},"id":"rPIcTC2F7Ooi","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/ aug\n","aug = True\n","epochs = 50\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet sgd ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n","starting epoch 1. time passed: 0:00:00.000047\n","randomangle -19.176620228167902\n","randomangle -19.176620228167902\n","randomangle -19.176620228167902\n","randomangle -19.176620228167902\n","randomangle -12.727001311715975\n","randomangle -12.727001311715975\n","randomangle -12.727001311715975\n","randomangle -12.727001311715975\n","randomangle -2.7221992543153704\n","randomangle -2.7221992543153704\n","randomangle -2.7221992543153704\n","randomangle -2.7221992543153704\n","randomangle -8.314214058591274\n","randomangle -8.314214058591274\n","randomangle -8.314214058591274\n","randomangle -8.314214058591274\n","randomangle -12.013048713665611\n","randomangle -12.013048713665611\n","randomangle -12.013048713665611\n","randomangle -12.013048713665611\n","randomangle 4.301794076057533\n","randomangle 4.301794076057533\n","randomangle 4.301794076057533\n","randomangle 4.301794076057533\n","randomangle 18.625281322982374\n","randomangle 18.625281322982374\n","randomangle 18.625281322982374\n","randomangle 7.369321060486275\n","randomangle 18.625281322982374\n","randomangle 7.369321060486275\n","randomangle 7.369321060486275\n","randomangle -18.624459155391264\n","randomangle -18.624459155391264\n","randomangle 7.369321060486275\n","randomangle -18.624459155391264\n","randomangle -7.531556956423561\n","randomangle -7.531556956423561\n","randomangle -7.531556956423561\n","randomangle -18.624459155391264\n","randomangle 18.783385110582344\n","randomangle 18.783385110582344\n","randomangle 18.783385110582344\n","randomangle -7.531556956423561\n","randomangle 3.915999152443405\n","randomangle 3.915999152443405\n","randomangle 3.915999152443405\n","randomangle 18.783385110582344\n","randomangle -18.19090844357848\n","randomangle -18.19090844357848\n","randomangle 3.915999152443405\n","randomangle -18.19090844357848\n","randomangle -18.19090844357848\n","randomangle 13.149500366077177\n","randomangle 13.149500366077177\n","randomangle 13.149500366077177\n","randomangle 13.149500366077177\n","randomangle -14.363031001009494\n","randomangle -14.363031001009494\n","randomangle -14.363031001009494\n","randomangle -14.363031001009494\n","randomangle 10.889790771866295\n","randomangle 10.889790771866295\n","randomangle 10.889790771866295\n","randomangle 8.274293753904686\n","randomangle 10.889790771866295\n","randomangle 8.274293753904686\n","randomangle 8.274293753904686\n","randomangle -5.661370858229095\n","randomangle 8.274293753904686\n","randomangle -5.661370858229095\n","randomangle -5.661370858229095\n","randomangle -6.7640790058940325\n","randomangle -5.661370858229095\n","randomangle -6.7640790058940325\n","randomangle -6.7640790058940325\n","randomangle 9.184247133522561\n","randomangle -6.7640790058940325\n","randomangle 9.184247133522561\n","randomangle 9.184247133522561\n","randomangle -15.216230162467932\n","randomangle -15.216230162467932\n","randomangle -15.216230162467932\n","randomangle 9.184247133522561\n","randomangle 10.838687198182441\n","randomangle 10.838687198182441\n","randomangle -15.216230162467932\n","randomangle 10.838687198182441\n","randomangle -18.983234930236193\n","randomangle 10.838687198182441\n","randomangle -18.983234930236193\n","randomangle -18.983234930236193\n","randomangle -7.425760756946932\n","randomangle -18.983234930236193\n","randomangle -7.425760756946932\n","randomangle -7.425760756946932\n","randomangle -3.5846830785748125\n","randomangle -7.425760756946932\n","randomangle -3.5846830785748125\n","randomangle -3.5846830785748125\n","randomangle -8.409941883449278\n","randomangle -8.409941883449278\n","randomangle -3.5846830785748125\n","randomangle -8.409941883449278\n","randomangle 5.3361502604169395\n","randomangle 5.3361502604169395\n","randomangle -8.409941883449278\n","randomangle 5.3361502604169395\n","randomangle 15.702359939599113\n","randomangle 15.702359939599113\n","randomangle 5.3361502604169395\n","randomangle 15.702359939599113\n","randomangle -7.279861001125445\n","randomangle -7.279861001125445\n","randomangle 15.702359939599113\n","randomangle -7.279861001125445\n","randomangle 12.720590636899722\n","randomangle -7.279861001125445\n","randomangle 12.720590636899722\n","randomangle 12.720590636899722\n","randomangle -3.3035598740488403\n","randomangle 12.720590636899722\n","randomangle -3.3035598740488403\n","randomangle 17.71638815650077\n","randomangle -3.3035598740488403\n","randomangle -3.3035598740488403\n","randomangle -5.454815904828241\n","randomangle 17.71638815650077\n","randomangle 17.71638815650077\n","randomangle 17.71638815650077\n","randomangle -0.1100597643045802\n","randomangle -5.454815904828241\n","randomangle -5.454815904828241\n","randomangle -5.454815904828241\n","randomangle 4.382573359195874\n","randomangle -0.1100597643045802\n","randomangle -0.1100597643045802\n","randomangle -0.1100597643045802\n","randomangle 16.33063543866615\n","randomangle 4.382573359195874\n","randomangle 4.382573359195874\n","randomangle 4.382573359195874\n","randomangle 19.42601816442403\n","randomangle 16.33063543866615\n","randomangle 16.33063543866615\n","randomangle 16.33063543866615\n","randomangle -10.494498240304013\n","randomangle 19.42601816442403\n","randomangle 19.42601816442403\n","randomangle 19.42601816442403\n","randomangle -10.494498240304013\n","randomangle 5.341188430435789\n","randomangle -10.494498240304013\n","randomangle -10.494498240304013\n","randomangle 5.341188430435789\n","randomangle 5.341188430435789\n","randomangle 5.341188430435789\n","randomangle -7.168797401130567\n","randomangle -7.168797401130567\n","randomangle -7.168797401130567\n","randomangle -7.168797401130567\n","randomangle 7.102574473691298\n","randomangle 7.102574473691298\n","randomangle 7.102574473691298\n","randomangle 7.102574473691298\n","randomangle 5.806911616377995\n","randomangle 5.806911616377995\n","randomangle 5.806911616377995\n","randomangle 5.806911616377995\n","randomangle 17.46919954946938\n","randomangle 17.46919954946938\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-13c4b7f7b3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sagittal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestarray1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrundir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnosis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alexnet sgd '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiagnosis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' lr = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' aug = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' + noise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AUC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-db64d065f415>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting epoch {}. time passed: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0;31m#print(f'train loss: {train_loss:0.4f}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0;31m#print(f'train AUC: {train_auc:0.4f}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-d5d6105dd2a7>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, loader, train, optimizer)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mvol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"yft-IRiDeW5s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}