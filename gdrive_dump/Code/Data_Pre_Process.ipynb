{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_Pre_Process.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9lUyiwqdRjAg","colab_type":"code","outputId":"070e6345-1a20-4ec9-fa6b-380cab7a128f","executionInfo":{"status":"ok","timestamp":1571355226750,"user_tz":240,"elapsed":34182,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive \n","drive.mount('/content/gdrive') "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_urCATm3YAtN","colab_type":"code","outputId":"44165da4-99ae-400d-9945-8b19fb7a4cd4","executionInfo":{"status":"ok","timestamp":1571355229553,"user_tz":240,"elapsed":36963,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import keras\n","from keras.layers import Layer\n","#from keras.datasets import cifar10, mnist\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import activations\n","from keras.models import Sequential\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras import optimizers\n","from keras.layers.core import Lambda\n","from keras import backend as K\n","from keras import regularizers\n","import os\n","\n","import sklearn\n","import torch\n","import torchvision"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gRC4YrDCYVEo","colab_type":"code","colab":{}},"source":["# loads data from folder under assumption each data is ####.npy format in folder\n","def load_data(pathname):\n","  #casenum = len(os.listdir(pathname))\n","  #for file in os.listdir(pathname):\n","  data = [np.load(pathname + \"/\" + file, allow_pickle=True) for file in sorted(os.listdir(pathname))]\n","  return data\n","\n","def load_data_shapes(pathname):\n","  data = [np.load(pathname + \"/\" + file, allow_pickle=True).shape for file in sorted(os.listdir(pathname))]\n","  return data\n","\n","# loads ground truths from CSV file assuming row1 is filename and row2 is ground truth\n","def groundtruths(pathname):\n","  csv_data = pd.read_csv(pathname, header=None)\n","  print(csv_data)\n","  ground_truths = np.array(csv_data.iloc[:,1])\n","  return ground_truths\n","\n","# depends on what clustering algorithm I want to use\n","def clustering(X_train, n_clusters):\n","  # k means from sklearn?\n","  \n","  pass\n","\n","def display_1d_histogram(x, title, xlabel, ylabel):\n","  plt.figure(0)\n","  # see if we can set axis later\n","  #ax = plt.axis()\n","  #ax.set(xlim = (np.min(x),np.max(x)), option='tight') \n","  plt.title(title)\n","  plt.hist(x)\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.show()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tBVbcCZYT-gZ","colab_type":"code","outputId":"976e90a9-1924-4f02-8278-110238db061e","executionInfo":{"status":"ok","timestamp":1570044862974,"user_tz":240,"elapsed":1781937,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# load in data \n","train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","\n","# load in the pictoral data for the 3 dimensions\n","axial_train_path = train_path + \"/axial\"\n","sagittal_train_path = train_path + \"/sagittal\"\n","coronal_train_path = train_path + \"/coronal\"\n","\n","print(\"Loading in Axial Data shapes...\")\n","axial_data_shapes = load_data_shapes(axial_train_path)\n","print(\"Done loading Axial!\")\n","print(\"Loading in Sagittal Data shapes...\")\n","sagittal_data_shapes = load_data_shapes(sagittal_train_path)\n","print(\"Done loading Sagittal!\")\n","print(\"Loading in Coronal Data shapes...\")\n","coronal_data_shapes = load_data_shapes(coronal_train_path)\n","print(\"Done loading Coronal!\")\n","\n","print(sagittal_data_shapes[1])\n","\n","# load in labels data\n","data_path = \"/content/gdrive/My Drive/thesis/Data\"\n","train_meniscus_csv_path = data_path + '/train-meniscus.csv'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading in Axial Data shapes...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bKsoqVIdG8XD","colab_type":"code","colab":{}},"source":["# investigate distribution of numpy array sizes\n","# datalist is an array of shape tuples\n","def size_info(data_list):\n","  size_list = np.zeros(len(data_list))\n","  ori_list = []\n","  for index in range(len(data_list)):\n","    (x, y, z) = data_list[index]\n","    if x != 256:\n","      size_list[index] = x\n","      ori_list.append('x')\n","    if y != 256:\n","      size_list[index] = y\n","      ori_list.append('y')\n","    if z != 256:\n","      size_list[index] = z\n","      ori_list.append('z')\n","  return size_list, ori_list\n","\n","axial_sizes, axial_oris = size_info(axial_data_shapes)\n","sagittal_sizes, sagittal_oris = size_info(sagittal_data_shapes)\n","coronal_sizes, coronal_oris = size_info(coronal_data_shapes)\n","\n","print(\"display axial histogram\")\n","display_1d_histogram(axial_sizes, \"Axial Slice Num Distribution\", \"Number of Slices per Patient\", \"Number of Cases\")\n","print(axial_oris)\n","\n","print(\"display sagittal histogram\")\n","display_1d_histogram(sagittal_sizes, \"Sagittal Slice Num Distribution\", \"Number of Slices per Patient\", \"Number of Cases\")\n","print(sagittal_oris)\n","\n","print(\"display coronal histogram\")\n","display_1d_histogram(coronal_sizes, \"Coronal Slice Num Distribution\", \"Number of Slices per Patient\", \"Number of Cases\")\n","print(coronal_oris)\n","\n","all_sizes = list()\n","all_sizes.append(axial_sizes)\n","all_sizes.append(sagittal_sizes)\n","all_sizes.append(coronal_sizes)\n","print(\"display all sizes histogram\")\n","display_1d_histogram(all_sizes, \"All Slice Num Distribution\", \"Number of Slices per Patient\", \"Number of Cases\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP2b9l6jGi-t","colab_type":"code","colab":{}},"source":["# try axial and meniscus, supervised clustering with 4 classes\n","\n","#axial_data = load_data(axial_train_path)\n","#print(len(axial_data))\n","\n","#train_meniscus_truths = groundtruths(train_meniscus_csv_path)\n","#print(train_meniscus_truths)\n","\n","# try to perform supervised clustering with 4 classes.\n","print(\"Splitting datasets into train and test for axial meniscal dataset ...\")\n","X_train = axial_data[:,-100]\n","Y_train = keras.utils.to_categorical(train_meniscus_truths[:,-100], 4)\n","X_test = axial_data[-100,:]\n","Y_test = keras.utils.to_categorical(train_meniscus_truths[-100,:], 4)\n","print(\"Splitting complete!\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BncRGgRk_wEZ","colab_type":"code","colab":{}},"source":["#display_1d_histogram([1,2,3], \"memes\", \"xmemes\", \"ymemes\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ReA7kwOp_08X","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}