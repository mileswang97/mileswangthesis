{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of version2 (visuals for poster).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"01d08196737a4244ad37e1b4b162666b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_312f0581a25b41c99e655b640eac25c8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3a04b5e58daa4a81a0a524210e7a3156","IPY_MODEL_036658835e0f447a8e27062ca7081ea1"]}},"312f0581a25b41c99e655b640eac25c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a04b5e58daa4a81a0a524210e7a3156":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_91882fb35b8646398413991e85e7ae81","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":244418560,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":244418560,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9168557d45354a238dcd5572977955f0"}},"036658835e0f447a8e27062ca7081ea1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8950702c4ba4ac4bd640b5babd50dd7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 233M/233M [00:05&lt;00:00, 46.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd52aebf09d747f6a24848bb69b11468"}},"91882fb35b8646398413991e85e7ae81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9168557d45354a238dcd5572977955f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8950702c4ba4ac4bd640b5babd50dd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cd52aebf09d747f6a24848bb69b11468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"7RQQrFFtr1kC","colab_type":"code","outputId":"90843cbf-0cef-4ade-8df4-5e0a55de29ab","executionInfo":{"status":"ok","timestamp":1581923562343,"user_tz":300,"elapsed":20573,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ZaXWwCucA__","colab_type":"code","outputId":"b1b59ab4-c055-4021-90ee-81e52ccd9bd0","executionInfo":{"status":"ok","timestamp":1581923578456,"user_tz":300,"elapsed":16095,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","%cd \"/content/gdrive/My Drive/thesis/Data\"\n","\n","#csv import labels\n","\n","train_ACL_labels = np.array(pd.read_csv(\"train-acl.csv\", header=None).iloc[:,1])\n","train_abnormal_labels = np.array(pd.read_csv(\"train-abnormal.csv\", header=None).iloc[:,1])\n","train_meniscus_labels = np.array(pd.read_csv(\"train-meniscus.csv\", header=None).iloc[:,1])\n","\n","valid_ACL_labels = np.array(pd.read_csv(\"valid-acl.csv\", header=None).iloc[:,1])\n","valid_abnormal_labels = np.array(pd.read_csv(\"valid-abnormal.csv\", header=None).iloc[:,1])\n","valid_meniscus_labels = np.array(pd.read_csv(\"valid-meniscus.csv\", header=None).iloc[:,1])\n","\n","test_ACL_labels = np.array(pd.read_csv(\"test-acl.csv\", header=None).iloc[:,1])\n","test_abnormal_labels = np.array(pd.read_csv(\"test-abnormal.csv\", header=None).iloc[:,1])\n","test_meniscus_labels = np.array(pd.read_csv(\"test-meniscus.csv\", header=None).iloc[:,1])\n","\n","#data path\n","train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","train_axial_path = \"/content/gdrive/My Drive/thesis/Data/train/coronal\"\n","\n","counter = 5\n","for filename in os.listdir(train_axial_path):\n","  if counter > 0:\n","    file0 = np.load(train_axial_path + '/' + filename)\n","    variancelist = []\n","    for slice in range(file0.shape[0]):\n","      variancelist.append(np.var(file0[slice,:,:]))\n","    #print(file0)\n","    #print('max', np.amax(file0))\n","    #print('mean', np.mean(file0))\n","    #print(filename, 'file shape', file0.shape, 'max_var_index', variancelist.index(max(variancelist)), max(variancelist))\n","    counter = counter - 1\n","\n","print(\"done!\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/thesis/Data\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7jqvUXbEDHe0","colab_type":"code","colab":{}},"source":["# model.py\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import models\n","\n","class MRNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = models.alexnet(pretrained=True)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.classifier = nn.Linear(256, 1)\n","\n","    # change this to adapt to different networks\n","    def forward(self, x):\n","        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n","        x = self.model.features(x)\n","        # make sure that gap returns size 256\n","        x = self.gap(x).view(x.size(0), -1)\n","        x = torch.max(x, 0, keepdim=True)[0]\n","        x = self.classifier(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0SjKDlPZ7XP","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import numpy as np\n","import os\n","import torch\n","from datetime import datetime\n","from pathlib import Path\n","from sklearn import metrics\n","\n","def train(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu):\n","    \n","    val_auc_array = list()\n","    train_auc_array = list()\n","    test_auc_array = list()\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    \n","    model = MRNet()\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=.01)\n","\n","    # patience too low (after 5 epochs, if AUC hasnt improved, slash learning rate .3), which is why high learning rate seems to work better\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=.3, threshold=1e-4)\n","\n","    best_val_loss = float('inf')\n","\n","    start_time = datetime.now()\n","\n","    for epoch in range(epochs):\n","        change = datetime.now() - start_time\n","        print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n","        \n","        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer)\n","        #print(f'train loss: {train_loss:0.4f}')\n","        #print(f'train AUC: {train_auc:0.4f}')\n","\n","        val_loss, val_auc, _, _ = run_model(model, valid_loader)\n","        #print(f'valid loss: {val_loss:0.4f}')\n","        #print(f'valid AUC: {val_auc:0.4f}')\n","\n","        test_loss, test_auc, _, _ = run_model(model, test_loader)\n","\n","        val_auc_array.append(val_auc)\n","        train_auc_array.append(train_auc)\n","        test_auc_array.append(test_auc)\n","        \n","        scheduler.step(val_loss)\n","\n","        \"\"\"\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","\n","            file_name = f'val{val_loss:0.4f}_train{train_loss:0.4f}_epoch{epoch+1}'\n","            save_path = Path(rundir) / file_name\n","\n","            # dont need to save stuff for now, model is too shitty\n","            #torch.save(model.state_dict(), save_path)\n","            #if epoch == (epochs-1):\n","            #  print('model saved at', str(save_path))\n","            #  torch.save(model.state_dict(), save_path)\n","        \"\"\"\n","    return val_auc_array, train_auc_array, test_auc_array"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNtBJxgjDWSi","colab_type":"code","outputId":"6ce1098f-3143-4ec0-edca-a9d8366cdbb8","executionInfo":{"status":"ok","timestamp":1581923585893,"user_tz":300,"elapsed":23508,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \"\"\"\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.8,1.2,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \"\"\"\n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting medicaltorch\n","  Downloading https://files.pythonhosted.org/packages/5a/85/b3fa267c6cdec058c937a5046e357de61dda938179aeeca72485f13b1fa2/medicaltorch-0.2-py3-none-any.whl\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.5.0)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.0)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Installing collected packages: medicaltorch\n","Successfully installed medicaltorch-0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M_Olw5OZDqFc","colab_type":"code","colab":{}},"source":["# evaluate.py\n","\n","import argparse\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import torch\n","\n","from sklearn import metrics\n","from torch.autograd import Variable\n","\n","#from loader import load_data\n","#from model import MRNet\n","\n","def get_parser():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--model_path', type=str, required=True)\n","    parser.add_argument('--split', type=str, required=True)\n","    parser.add_argument('--diagnosis', type=int, required=True)\n","    parser.add_argument('--gpu', action='store_true')\n","    return parser\n","\n","def run_model(model, loader, train=False, optimizer=None):\n","    preds = []\n","    labels = []\n","\n","    if train:\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    total_loss = 0.\n","    num_batches = 0\n","\n","    for batch in loader:\n","        if train:\n","            optimizer.zero_grad()\n","\n","        vol, label = batch\n","        if loader.dataset.use_gpu:\n","            vol = vol.cuda()\n","            label = label.cuda()\n","        vol = Variable(vol)\n","        label = Variable(label)\n","\n","        logit = model.forward(vol)\n","\n","        loss = loader.dataset.weighted_loss(logit, label)\n","        total_loss += loss.item()\n","\n","        #\n","        pred = torch.sigmoid(logit)\n","        pred_npy = pred.data.cpu().numpy()[0][0]\n","        label_npy = label.data.cpu().numpy()[0][0]\n","\n","        preds.append(pred_npy)\n","        labels.append(label_npy)\n","\n","        if train:\n","            loss.backward()\n","            optimizer.step()\n","        num_batches += 1\n","\n","    avg_loss = total_loss / num_batches\n","\n","    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n","    auc = metrics.auc(fpr, tpr)\n","\n","    return avg_loss, auc, preds, labels\n","\n","def evaluate(split, model_path, diagnosis, orientation, use_gpu):\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    model = MRNet()\n","    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n","    model.load_state_dict(state_dict)\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    if split == 'train':\n","        loader = train_loader\n","    elif split == 'valid':\n","        loader = valid_loader\n","    elif split == 'test':\n","        loader = test_loader\n","    else:\n","        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n","\n","    loss, auc, preds, labels = run_model(model, loader)\n","\n","    print(f'{split} loss: {loss:0.4f}')\n","    print(f'{split} AUC: {auc:0.4f}')\n","\n","    return preds, labels\n","\n","#if __name__ == '__main__':\n","#    args = get_parser().parse_args()\n","#   evaluate(args.split, args.model_path, args.diagnosis, args.gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDIZFy0IrqVs","colab_type":"code","colab":{}},"source":["import matplotlib\n","matplotlib.use('Agg')\n","gpu = True\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","#learningrate = 5e-05\n","epochs = 100\n","#diagnosis = 'ACL'\n","rundir = \"/content/gdrive/My Drive/thesis/Data\"\n","#orientation = 'axial'\n","savedir = \"/content/gdrive/My Drive/thesis/Results\"\n","\n","\n","if gpu:\n","  torch.cuda.manual_seed_all(seed)\n","\n","def display_single(x_length, lr1, varray, tarray, testarray, title, xlabel, ylabel, save_dir):\n","  plt.figure(0)\n","  plt.title(title)\n","  plt.plot(np.arange(x_length), varray, label='valid')\n","  plt.plot(np.arange(x_length), tarray, label='train')\n","  plt.plot(np.arange(x_length), testarray, label='test')\n","  plt.legend()\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.savefig(save_dir + '/' + title + '.eps', format='eps')\n","  plt.show()\n","  plt.close()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgpG9eChPNJQ","colab_type":"code","outputId":"61a8d31b-6aba-42ea-8fed-0b017c1b8e8e","executionInfo":{"status":"error","timestamp":1581370345831,"user_tz":300,"elapsed":121679,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA_aEkGH4gpijfLHJcvB6IMuR_A1RwjPjfM-RiV-7PKjuRm2QMgkbAqK1EkrM3xvOODqAwgs8TERPtCejFQ-4mlD5x-ryUFbixf1YM1UOUXPY55BIBMklTvPGyj9kjXypGW2qVNLZEkd-un0_Wpb96FVy65pGsE3_-mSW9rZKm2NvMMM0umF4ap9o7uF1LNvDx9Rsyni5xnN4upPYbhM-hamY7QsHp4dUh_TSeXrHcmEvNyvj-Q708wlU3Z5G5bhNSqjxDboodEuoFG3XMGHY2_do_7CEXUHYhpVVenQccwl7COqTe9eP2UXDEg3VIfZuQKNKcjaNjlHZHInP5uL6BshkTU7WIVND0iqlqGw5J8Xkc3q5xndFKUO_iwSk_p5TFAmIvBGf2Z7GGPgBagWl2xqGM5hQUiOhTwxZVC8O65ii5ZO1sYz49cXHQd6RdILKsw8ladTJcjoAxzgZwYcSAkHZGpB43NxgzMRLkcCfdf7KnOJvoIYPhXZIzfQsYyZlIWvoVD8iWmoAa0lDXtek6l2QQ91sjcIkLg1-TiX--dZJSIP50J5_bm2d201cwj2k-pWCFhaxrGce7NmbdqNaYypb4l3yhrAZDM2POa6fMqpcDTALXT9GlTA0VkkahFgG2lndKjk-I0XugQXaKJqZJWuWYkDRzMfwX29j53paoOxCDnyg2zW6dPhdimhPkVHsbsk5Za5fPTBuib778KY2ApEZh_1XaRjznivY1E9JhXrZD2a94fAiLNlzxbfuQ=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["01d08196737a4244ad37e1b4b162666b","312f0581a25b41c99e655b640eac25c8","3a04b5e58daa4a81a0a524210e7a3156","036658835e0f447a8e27062ca7081ea1","91882fb35b8646398413991e85e7ae81","9168557d45354a238dcd5572977955f0","e8950702c4ba4ac4bd640b5babd50dd7","cd52aebf09d747f6a24848bb69b11468"]}},"source":["#sag w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01d08196737a4244ad37e1b4b162666b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=244418560), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","starting epoch 1. time passed: 0:00:00.000013\n","starting epoch 2. time passed: 0:03:24.281156\n","starting epoch 3. time passed: 0:04:19.466737\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oaARnjSlujFc","colab_type":"code","outputId":"ce6de969-5576-4285-c241-54046121f9d4","executionInfo":{"status":"ok","timestamp":1580087723897,"user_tz":300,"elapsed":19,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDREWwL6-VZJ2HgnPoWL2ckE85cgaDnwG-zIqkKg5heqZGYhY_ukjy1GiZ7EDhlUaYHbESSb9hrlS2pgcBQNrPsoki1rLe1yVPAjqyX3CnP1rRutH-i6WHCfiETTwPvz2CMNjDBzGggNHkn0LFpOf_ILxXxwFgy04SgCBL8MhDw0unTj05k43pipOV8kVF0PlIzdETIE8e4NaLKnO-jusxTiE_enD_7x99RIpKp04rPJzCLc0KJrb1GUeWoWzBQHCiWYF8A5-nnyJETOgDOuPf_h89fY7SCJnHpU4AjanPVZeI5gksX_DDLPjs6XwFo8WmB7n8D5J5TL1cXBreP3oZRwnoUGSvYzbxulpVMjVY6y3SPFKmRSlKTNeeJZvF-0w4GC8e7uZT6Rw2uR-KdR5r_dpaqx7NM9w6Kk9cvhnuYht7Cp1w3nOEituXBwGb5tgVrAcQV9RkfuvZKy6ecsmtbjlD237R6VjK3RC7y_5pF0VzfD1Ii9NPksf6oFbcdpGNKdJRo7sT3DDPQXOfAItnDYekkjipGlGJyWebs7K7bXfSZ99c9qdxlNhnM3i3N50v0xys7lUXG8kGuleV3NwsiVz9H7mwpbRwTSj4qqhesSB7YLWx0eoh9kOco9B1_CqT3n8RGPI7eMQeH4xYT9AXQ0mVKEgoyZ_Y8pfW_4oOROwrNtrXahfBQ7D9FSGpbDVlmzl0YeZ_NEId2Knf-O0mJlUz7vNVKP0OXT-lK_4B3T-y8I8ggJPpIYj9PJuU=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":497}},"source":["#cor w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCcLMzAr9F7iPn9M2H+meAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Qf-14Dquu0aB","colab_type":"code","outputId":"d73ecc0f-dbe8-46dd-a33e-ea1202faf16f","executionInfo":{"status":"ok","timestamp":1580092545348,"user_tz":300,"elapsed":4821455,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDREWwL6-VZJ2HgnPoWL2ckE85cgaDnwG-zIqkKg5heqZGYhY_ukjy1GiZ7EDhlUaYHbESSb9hrlS2pgcBQNrPsoki1rLe1yVPAjqyX3CnP1rRutH-i6WHCfiETTwPvz2CMNjDBzGggNHkn0LFpOf_ILxXxwFgy04SgCBL8MhDw0unTj05k43pipOV8kVF0PlIzdETIE8e4NaLKnO-jusxTiE_enD_7x99RIpKp04rPJzCLc0KJrb1GUeWoWzBQHCiWYF8A5-nnyJETOgDOuPf_h89fY7SCJnHpU4AjanPVZeI5gksX_DDLPjs6XwFo8WmB7n8D5J5TL1cXBreP3oZRwnoUGSvYzbxulpVMjVY6y3SPFKmRSlKTNeeJZvF-0w4GC8e7uZT6Rw2uR-KdR5r_dpaqx7NM9w6Kk9cvhnuYht7Cp1w3nOEituXBwGb5tgVrAcQV9RkfuvZKy6ecsmtbjlD237R6VjK3RC7y_5pF0VzfD1Ii9NPksf6oFbcdpGNKdJRo7sT3DDPQXOfAItnDYekkjipGlGJyWebs7K7bXfSZ99c9qdxlNhnM3i3N50v0xys7lUXG8kGuleV3NwsiVz9H7mwpbRwTSj4qqhesSB7YLWx0eoh9kOco9B1_CqT3n8RGPI7eMQeH4xYT9AXQ0mVKEgoyZ_Y8pfW_4oOROwrNtrXahfBQ7D9FSGpbDVlmzl0YeZ_NEId2Knf-O0mJlUz7vNVKP0OXT-lK_4B3T-y8I8ggJPpIYj9PJuU=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":497}},"source":["#ax w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"qCa-o9Oovg1H","colab_type":"text"},"source":["# NOW w/augmentation, NO NOISE"]},{"cell_type":"code","metadata":{"id":"S09r2wj6vfqi","colab_type":"code","outputId":"8256eafb-e03b-4402-cfc6-74072976d7f2","executionInfo":{"status":"ok","timestamp":1580102326915,"user_tz":300,"elapsed":2326640,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDREWwL6-VZJ2HgnPoWL2ckE85cgaDnwG-zIqkKg5heqZGYhY_ukjy1GiZ7EDhlUaYHbESSb9hrlS2pgcBQNrPsoki1rLe1yVPAjqyX3CnP1rRutH-i6WHCfiETTwPvz2CMNjDBzGggNHkn0LFpOf_ILxXxwFgy04SgCBL8MhDw0unTj05k43pipOV8kVF0PlIzdETIE8e4NaLKnO-jusxTiE_enD_7x99RIpKp04rPJzCLc0KJrb1GUeWoWzBQHCiWYF8A5-nnyJETOgDOuPf_h89fY7SCJnHpU4AjanPVZeI5gksX_DDLPjs6XwFo8WmB7n8D5J5TL1cXBreP3oZRwnoUGSvYzbxulpVMjVY6y3SPFKmRSlKTNeeJZvF-0w4GC8e7uZT6Rw2uR-KdR5r_dpaqx7NM9w6Kk9cvhnuYht7Cp1w3nOEituXBwGb5tgVrAcQV9RkfuvZKy6ecsmtbjlD237R6VjK3RC7y_5pF0VzfD1Ii9NPksf6oFbcdpGNKdJRo7sT3DDPQXOfAItnDYekkjipGlGJyWebs7K7bXfSZ99c9qdxlNhnM3i3N50v0xys7lUXG8kGuleV3NwsiVz9H7mwpbRwTSj4qqhesSB7YLWx0eoh9kOco9B1_CqT3n8RGPI7eMQeH4xYT9AXQ0mVKEgoyZ_Y8pfW_4oOROwrNtrXahfBQ7D9FSGpbDVlmzl0YeZ_NEId2Knf-O0mJlUz7vNVKP0OXT-lK_4B3T-y8I8ggJPpIYj9PJuU=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":497}},"source":["#sag w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'ACL'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJCUlCBERSUkJQkREUvr/B2EIohFMZw4AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PPbtst1fv49D","colab_type":"code","outputId":"e62d0cbb-405e-4c18-c6ab-61f5f25f8e68","executionInfo":{"status":"ok","timestamp":1580164835504,"user_tz":300,"elapsed":10334170,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjbiKgwzANUrT0kJ1PcVZtBRQiuds5HOouGtBJfJJe9XMaxnKm8Gq6lEwdPyGV76qtErFytAlKDMR9WzDuQ7GHJPVi0Uk3hoxQxPGdu-Tj8TifLXXq3KtpF__oeNpl9xPJaen1rKEPJSW9Zya0skI_fIxdmkZUQ1lp-U1FxM0zGnrC-m83Nd-nJ5xlFKcrvlmjsXA1PR46AZsFfyUVZE7kZyqNj4GQDjxly_c17ZZlRNGMA1VRbzqy87CyUP4P6iQKd8B4OnoN-vz6SHIHHRFaogwUA2pXraiAE_j9E5OD7pVmasuRPA9JF5brBtsNGmiGFfk7y0cJGVOM1CDWH1WEAlMYd6tzjgzGb6Z87pzWP5RbP_z0XjNeC0lbLxqVt0twX-V_ydOMqapspmDQO0bIgG6cxBqOGyrntHlwU6GSfaRWnBVjn9VeD4TZsqTwXymokixcPtnMD8XpfQxSoBS9u3NwftZ97dzYGFdifksTHvP6ibIPTQhJ4OZZEv8EIuXXcP8QczArzGsQ-DMRPwYIMBMKr6uH88ro1uNReWC4QWP2U7fPX8flXw_bKvaMabHlrO8fmkyagdWRV0U5uHdWk6CvlTw_3D0UGJ2tzjnuYgo54yAfR8SceiF1asqAaJiBiVMYOfhKCTy6_rJ-fVvwgfe9PRxsg7Wes3qw-xcVQfukwbFru7KLZU-h7Xlux7BAGVf0IcAC_BDWW_mX65QUKZH6o9VytKIuJTBVNA9aG8c0VAzHlzm1mLdR5Sk=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["#cor w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:07<00:00, 34.0MB/s]\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vhrxLVzHwyUM","colab_type":"code","outputId":"4fcd9c7b-26b1-4979-8ead-72abfc2b624c","executionInfo":{"status":"ok","timestamp":1580180154006,"user_tz":300,"elapsed":11026696,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBjbiKgwzANUrT0kJ1PcVZtBRQiuds5HOouGtBJfJJe9XMaxnKm8Gq6lEwdPyGV76qtErFytAlKDMR9WzDuQ7GHJPVi0Uk3hoxQxPGdu-Tj8TifLXXq3KtpF__oeNpl9xPJaen1rKEPJSW9Zya0skI_fIxdmkZUQ1lp-U1FxM0zGnrC-m83Nd-nJ5xlFKcrvlmjsXA1PR46AZsFfyUVZE7kZyqNj4GQDjxly_c17ZZlRNGMA1VRbzqy87CyUP4P6iQKd8B4OnoN-vz6SHIHHRFaogwUA2pXraiAE_j9E5OD7pVmasuRPA9JF5brBtsNGmiGFfk7y0cJGVOM1CDWH1WEAlMYd6tzjgzGb6Z87pzWP5RbP_z0XjNeC0lbLxqVt0twX-V_ydOMqapspmDQO0bIgG6cxBqOGyrntHlwU6GSfaRWnBVjn9VeD4TZsqTwXymokixcPtnMD8XpfQxSoBS9u3NwftZ97dzYGFdifksTHvP6ibIPTQhJ4OZZEv8EIuXXcP8QczArzGsQ-DMRPwYIMBMKr6uH88ro1uNReWC4QWP2U7fPX8flXw_bKvaMabHlrO8fmkyagdWRV0U5uHdWk6CvlTw_3D0UGJ2tzjnuYgo54yAfR8SceiF1asqAaJiBiVMYOfhKCTy6_rJ-fVvwgfe9PRxsg7Wes3qw-xcVQfukwbFru7KLZU-h7Xlux7BAGVf0IcAC_BDWW_mX65QUKZH6o9VytKIuJTBVNA9aG8c0VAzHlzm1mLdR5Sk=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["#ax w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:01<00:00, 173MB/s]\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RDuyrrB2xIJC","colab_type":"text"},"source":["ADD NOISE TO TRANSFORMATION POLICY"]},{"cell_type":"code","metadata":{"id":"nmopOqtGyT0n","colab_type":"code","outputId":"9fc09905-1b45-4e20-e253-496d8f176130","executionInfo":{"status":"ok","timestamp":1580391114462,"user_tz":300,"elapsed":2959,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.95,1.05,256*256)\n","            noise_array.resize((256,256))\n","            \n","            for sliceindex in range(vol.shape[0]):\n","              vol[sliceindex] = np.multiply(vol[sliceindex], noise_array)\n","              vol[sliceindex] = np.clip(vol[sliceindex], 0, 255)\n","            vol = vol.astype(np.float32)\n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Hm6Sss1xibn","colab_type":"code","outputId":"f0a8ff79-720d-4330-c31d-9cbc93a8b65f","executionInfo":{"status":"ok","timestamp":1580251514386,"user_tz":300,"elapsed":10068710,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBvkoV5Czhw-kPY8IRbFEqQJdihIM9OvzHjL7ygFf2VajoeoXOKGuil7yGaDjz2g5bV3sxVA2Q7UMt2_59dhuks4Hcp-pOsBECPNWJPfMXzf_INkCAg85Vkmb2EcuI8FFkmqGgjEUabxK5dbBS-b0f4gYO9DYnxO0jHdon69v-GQ5n862dRg3ge8ITFoU4QJ9TaioiMRnDN8ggWEsDg1kCwo46PVzjCxOQzeYeEPBPhqm-bRXLd249mtymyijVZE4OekL-EOQyaHvwuHiFCRznyWI35cLgyy-mp8UXmpZhiYRZGBqsYjmaSpHxMwdyZ-nlWaAMhpu4Yz6qIwJFSG_416jsemNEkrPr7yCh_fR3b5kpQd8rBV-1jG2okGWryvzkI4dpARfgQyWUfUJR5ukKhBVCSyR7TPe9q_X37YZ7diYSEDMo2lcNcdmRxCwepnWIAsJMvzO-HWJ_owzyQzie_L97vEuuTPP_8qVnLuR9mtUUIaOHuZ58sdLJF4xij6k2m8q6OaTG2jQFn6SC9Fv8us2r9_LVKvAP5Kp2bNBdWNz6oRZHPdM2zA1ieOowTY2xjAa7vlvaQFU-imEXQpX01ZFL5UDs6-z9KkEHNcAQOcWI-LDOoxLXKTJ1RemN9w7WsVkiwVH2FABXhzYkV1h3o5bj0t_6Kwikueen34h4im29XHMy9s_cNoDc147stPItNbGoqVMZCNR788tLbpuSqWeYoNrjqr89dh83EbRhEBrfICDXAvI4N116wEWs=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:13<00:00, 18.7MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000012\n","starting epoch 2. time passed: 0:03:11.767365\n","starting epoch 3. time passed: 0:04:56.755396\n","starting epoch 4. time passed: 0:06:39.974385\n","starting epoch 5. time passed: 0:08:22.664290\n","starting epoch 6. time passed: 0:10:04.901926\n","starting epoch 7. time passed: 0:11:46.928587\n","starting epoch 8. time passed: 0:13:27.463554\n","starting epoch 9. time passed: 0:15:08.500947\n","starting epoch 10. time passed: 0:16:48.162514\n","starting epoch 11. time passed: 0:18:27.561812\n","starting epoch 12. time passed: 0:20:07.293625\n","starting epoch 13. time passed: 0:21:46.257810\n","starting epoch 14. time passed: 0:23:25.580877\n","starting epoch 15. time passed: 0:25:04.526201\n","starting epoch 16. time passed: 0:26:43.276800\n","starting epoch 17. time passed: 0:28:22.446349\n","starting epoch 18. time passed: 0:30:03.166128\n","starting epoch 19. time passed: 0:31:46.050198\n","starting epoch 20. time passed: 0:33:25.442285\n","starting epoch 21. time passed: 0:35:05.254784\n","starting epoch 22. time passed: 0:36:44.447594\n","starting epoch 23. time passed: 0:38:23.639845\n","starting epoch 24. time passed: 0:40:03.442863\n","starting epoch 25. time passed: 0:41:43.259657\n","starting epoch 26. time passed: 0:43:23.211756\n","starting epoch 27. time passed: 0:45:02.711607\n","starting epoch 28. time passed: 0:46:42.814285\n","starting epoch 29. time passed: 0:48:22.602984\n","starting epoch 30. time passed: 0:50:02.497371\n","starting epoch 31. time passed: 0:51:42.105172\n","starting epoch 32. time passed: 0:53:21.673930\n","starting epoch 33. time passed: 0:55:00.858244\n","starting epoch 34. time passed: 0:56:40.231618\n","starting epoch 35. time passed: 0:58:18.867973\n","starting epoch 36. time passed: 0:59:57.829810\n","starting epoch 37. time passed: 1:01:36.875169\n","starting epoch 38. time passed: 1:03:16.161020\n","starting epoch 39. time passed: 1:04:55.361814\n","starting epoch 40. time passed: 1:06:34.467620\n","starting epoch 41. time passed: 1:08:13.521784\n","starting epoch 42. time passed: 1:09:52.262427\n","starting epoch 43. time passed: 1:11:30.957239\n","starting epoch 44. time passed: 1:13:09.270189\n","starting epoch 45. time passed: 1:14:47.547839\n","starting epoch 46. time passed: 1:16:26.104083\n","starting epoch 47. time passed: 1:18:04.634164\n","starting epoch 48. time passed: 1:19:43.126051\n","starting epoch 49. time passed: 1:21:21.289078\n","starting epoch 50. time passed: 1:22:59.770515\n","starting epoch 51. time passed: 1:24:38.304920\n","starting epoch 52. time passed: 1:26:16.279485\n","starting epoch 53. time passed: 1:27:54.810638\n","starting epoch 54. time passed: 1:29:33.200094\n","starting epoch 55. time passed: 1:31:11.533299\n","starting epoch 56. time passed: 1:32:50.603481\n","starting epoch 57. time passed: 1:34:31.250831\n","starting epoch 58. time passed: 1:36:11.257813\n","starting epoch 59. time passed: 1:37:50.617945\n","starting epoch 60. time passed: 1:39:30.425236\n","starting epoch 61. time passed: 1:41:09.403501\n","starting epoch 62. time passed: 1:42:49.157548\n","starting epoch 63. time passed: 1:44:28.395135\n","starting epoch 64. time passed: 1:46:07.028448\n","starting epoch 65. time passed: 1:47:45.387887\n","starting epoch 66. time passed: 1:49:23.969110\n","starting epoch 67. time passed: 1:51:02.517067\n","starting epoch 68. time passed: 1:52:41.581595\n","starting epoch 69. time passed: 1:54:20.721155\n","starting epoch 70. time passed: 1:55:59.212600\n","starting epoch 71. time passed: 1:57:38.214702\n","starting epoch 72. time passed: 1:59:17.750047\n","starting epoch 73. time passed: 2:00:56.720845\n","starting epoch 74. time passed: 2:02:35.540910\n","starting epoch 75. time passed: 2:04:14.825201\n","starting epoch 76. time passed: 2:05:53.300361\n","starting epoch 77. time passed: 2:07:32.156451\n","starting epoch 78. time passed: 2:09:10.489033\n","starting epoch 79. time passed: 2:10:49.920185\n","starting epoch 80. time passed: 2:12:30.730055\n","starting epoch 81. time passed: 2:14:10.247679\n","starting epoch 82. time passed: 2:15:49.378565\n","starting epoch 83. time passed: 2:17:28.125781\n","starting epoch 84. time passed: 2:19:07.189601\n","starting epoch 85. time passed: 2:20:46.155633\n","starting epoch 86. time passed: 2:22:24.793732\n","starting epoch 87. time passed: 2:24:03.824717\n","starting epoch 88. time passed: 2:25:43.242623\n","starting epoch 89. time passed: 2:27:21.943095\n","starting epoch 90. time passed: 2:29:01.355824\n","starting epoch 91. time passed: 2:30:39.917667\n","starting epoch 92. time passed: 2:32:18.186130\n","starting epoch 93. time passed: 2:33:56.309198\n","starting epoch 94. time passed: 2:35:35.844087\n","starting epoch 95. time passed: 2:37:14.279661\n","starting epoch 96. time passed: 2:38:52.445737\n","starting epoch 97. time passed: 2:40:30.781367\n","starting epoch 98. time passed: 2:42:09.062976\n","starting epoch 99. time passed: 2:43:47.821312\n","starting epoch 100. time passed: 2:45:27.713798\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6yqfZsMTxiiR","colab_type":"code","outputId":"f49d9c58-ee8d-48d6-8ac8-ce4d6e72c4ac","executionInfo":{"status":"ok","timestamp":1580261365002,"user_tz":300,"elapsed":8012087,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBvkoV5Czhw-kPY8IRbFEqQJdihIM9OvzHjL7ygFf2VajoeoXOKGuil7yGaDjz2g5bV3sxVA2Q7UMt2_59dhuks4Hcp-pOsBECPNWJPfMXzf_INkCAg85Vkmb2EcuI8FFkmqGgjEUabxK5dbBS-b0f4gYO9DYnxO0jHdon69v-GQ5n862dRg3ge8ITFoU4QJ9TaioiMRnDN8ggWEsDg1kCwo46PVzjCxOQzeYeEPBPhqm-bRXLd249mtymyijVZE4OekL-EOQyaHvwuHiFCRznyWI35cLgyy-mp8UXmpZhiYRZGBqsYjmaSpHxMwdyZ-nlWaAMhpu4Yz6qIwJFSG_416jsemNEkrPr7yCh_fR3b5kpQd8rBV-1jG2okGWryvzkI4dpARfgQyWUfUJR5ukKhBVCSyR7TPe9q_X37YZ7diYSEDMo2lcNcdmRxCwepnWIAsJMvzO-HWJ_owzyQzie_L97vEuuTPP_8qVnLuR9mtUUIaOHuZ58sdLJF4xij6k2m8q6OaTG2jQFn6SC9Fv8us2r9_LVKvAP5Kp2bNBdWNz6oRZHPdM2zA1ieOowTY2xjAa7vlvaQFU-imEXQpX01ZFL5UDs6-z9KkEHNcAQOcWI-LDOoxLXKTJ1RemN9w7WsVkiwVH2FABXhzYkV1h3o5bj0t_6Kwikueen34h4im29XHMy9s_cNoDc147stPItNbGoqVMZCNR788tLbpuSqWeYoNrjqr89dh83EbRhEBrfICDXAvI4N116wEWs=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#cor w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n","starting epoch 1. time passed: 0:00:00.000011\n","starting epoch 2. time passed: 0:03:19.720205\n","starting epoch 3. time passed: 0:05:05.150878\n","starting epoch 4. time passed: 0:06:45.976709\n","starting epoch 5. time passed: 0:08:27.966848\n","starting epoch 6. time passed: 0:10:10.290772\n","starting epoch 7. time passed: 0:11:53.703555\n","starting epoch 8. time passed: 0:13:35.496343\n","starting epoch 9. time passed: 0:15:17.186898\n","starting epoch 10. time passed: 0:17:00.854860\n","starting epoch 11. time passed: 0:18:41.367856\n","starting epoch 12. time passed: 0:20:20.384556\n","starting epoch 13. time passed: 0:21:58.628439\n","starting epoch 14. time passed: 0:23:36.617223\n","starting epoch 15. time passed: 0:25:14.581870\n","starting epoch 16. time passed: 0:26:52.403404\n","starting epoch 17. time passed: 0:28:29.970705\n","starting epoch 18. time passed: 0:30:08.180106\n","starting epoch 19. time passed: 0:31:46.243396\n","starting epoch 20. time passed: 0:33:23.610377\n","starting epoch 21. time passed: 0:35:02.405051\n","starting epoch 22. time passed: 0:36:40.277074\n","starting epoch 23. time passed: 0:38:17.045919\n","starting epoch 24. time passed: 0:39:54.476251\n","starting epoch 25. time passed: 0:41:31.348202\n","starting epoch 26. time passed: 0:43:08.060447\n","starting epoch 27. time passed: 0:44:45.336862\n","starting epoch 28. time passed: 0:46:22.463504\n","starting epoch 29. time passed: 0:47:58.992998\n","starting epoch 30. time passed: 0:49:36.035244\n","starting epoch 31. time passed: 0:51:13.332966\n","starting epoch 32. time passed: 0:52:50.222085\n","starting epoch 33. time passed: 0:54:26.723954\n","starting epoch 34. time passed: 0:56:04.008267\n","starting epoch 35. time passed: 0:57:40.928094\n","starting epoch 36. time passed: 0:59:17.865392\n","starting epoch 37. time passed: 1:00:54.832328\n","starting epoch 38. time passed: 1:02:31.304822\n","starting epoch 39. time passed: 1:04:07.677994\n","starting epoch 40. time passed: 1:05:44.244829\n","starting epoch 41. time passed: 1:07:20.406481\n","starting epoch 42. time passed: 1:08:56.842262\n","starting epoch 43. time passed: 1:10:34.027191\n","starting epoch 44. time passed: 1:12:12.476879\n","starting epoch 45. time passed: 1:13:49.416812\n","starting epoch 46. time passed: 1:15:26.120516\n","starting epoch 47. time passed: 1:17:03.347916\n","starting epoch 48. time passed: 1:18:40.200118\n","starting epoch 49. time passed: 1:20:16.917421\n","starting epoch 50. time passed: 1:21:53.630841\n","starting epoch 51. time passed: 1:23:29.404706\n","starting epoch 52. time passed: 1:25:05.625811\n","starting epoch 53. time passed: 1:26:42.026739\n","starting epoch 54. time passed: 1:28:18.251392\n","starting epoch 55. time passed: 1:29:55.034631\n","starting epoch 56. time passed: 1:31:31.087510\n","starting epoch 57. time passed: 1:33:07.451687\n","starting epoch 58. time passed: 1:34:43.719355\n","starting epoch 59. time passed: 1:36:20.530027\n","starting epoch 60. time passed: 1:37:57.596361\n","starting epoch 61. time passed: 1:39:34.342456\n","starting epoch 62. time passed: 1:41:10.773700\n","starting epoch 63. time passed: 1:42:47.237044\n","starting epoch 64. time passed: 1:44:23.384335\n","starting epoch 65. time passed: 1:45:59.937944\n","starting epoch 66. time passed: 1:47:36.490467\n","starting epoch 67. time passed: 1:49:13.138683\n","starting epoch 68. time passed: 1:50:49.807013\n","starting epoch 69. time passed: 1:52:26.158790\n","starting epoch 70. time passed: 1:54:02.871875\n","starting epoch 71. time passed: 1:55:39.423933\n","starting epoch 72. time passed: 1:57:15.621271\n","starting epoch 73. time passed: 1:58:53.034836\n","starting epoch 74. time passed: 2:00:29.718293\n","starting epoch 75. time passed: 2:02:06.322807\n","starting epoch 76. time passed: 2:03:43.508668\n","starting epoch 77. time passed: 2:05:20.379489\n","starting epoch 78. time passed: 2:06:57.237930\n","starting epoch 79. time passed: 2:08:33.589306\n","starting epoch 80. time passed: 2:10:10.003416\n","starting epoch 81. time passed: 2:11:46.546100\n","starting epoch 82. time passed: 2:13:22.582423\n","starting epoch 83. time passed: 2:14:58.887305\n","starting epoch 84. time passed: 2:16:35.404215\n","starting epoch 85. time passed: 2:18:11.840385\n","starting epoch 86. time passed: 2:19:48.247828\n","starting epoch 87. time passed: 2:21:24.774586\n","starting epoch 88. time passed: 2:23:01.038273\n","starting epoch 89. time passed: 2:24:37.850683\n","starting epoch 90. time passed: 2:26:14.364988\n","starting epoch 91. time passed: 2:27:50.596365\n","starting epoch 92. time passed: 2:29:26.843915\n","starting epoch 93. time passed: 2:31:03.283336\n","starting epoch 94. time passed: 2:32:39.551932\n","starting epoch 95. time passed: 2:34:15.999110\n","starting epoch 96. time passed: 2:35:52.279140\n","starting epoch 97. time passed: 2:37:28.500732\n","starting epoch 98. time passed: 2:39:05.448912\n","starting epoch 99. time passed: 2:40:42.106269\n","starting epoch 100. time passed: 2:42:20.086911\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dwSwEwL-xiqT","colab_type":"code","outputId":"f5b51e40-b2d5-478d-e59e-e1efafbc7583","executionInfo":{"status":"ok","timestamp":1580272696294,"user_tz":300,"elapsed":11331313,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBvkoV5Czhw-kPY8IRbFEqQJdihIM9OvzHjL7ygFf2VajoeoXOKGuil7yGaDjz2g5bV3sxVA2Q7UMt2_59dhuks4Hcp-pOsBECPNWJPfMXzf_INkCAg85Vkmb2EcuI8FFkmqGgjEUabxK5dbBS-b0f4gYO9DYnxO0jHdon69v-GQ5n862dRg3ge8ITFoU4QJ9TaioiMRnDN8ggWEsDg1kCwo46PVzjCxOQzeYeEPBPhqm-bRXLd249mtymyijVZE4OekL-EOQyaHvwuHiFCRznyWI35cLgyy-mp8UXmpZhiYRZGBqsYjmaSpHxMwdyZ-nlWaAMhpu4Yz6qIwJFSG_416jsemNEkrPr7yCh_fR3b5kpQd8rBV-1jG2okGWryvzkI4dpARfgQyWUfUJR5ukKhBVCSyR7TPe9q_X37YZ7diYSEDMo2lcNcdmRxCwepnWIAsJMvzO-HWJ_owzyQzie_L97vEuuTPP_8qVnLuR9mtUUIaOHuZ58sdLJF4xij6k2m8q6OaTG2jQFn6SC9Fv8us2r9_LVKvAP5Kp2bNBdWNz6oRZHPdM2zA1ieOowTY2xjAa7vlvaQFU-imEXQpX01ZFL5UDs6-z9KkEHNcAQOcWI-LDOoxLXKTJ1RemN9w7WsVkiwVH2FABXhzYkV1h3o5bj0t_6Kwikueen34h4im29XHMy9s_cNoDc147stPItNbGoqVMZCNR788tLbpuSqWeYoNrjqr89dh83EbRhEBrfICDXAvI4N116wEWs=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#ax w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet adam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n","starting epoch 1. time passed: 0:00:00.000013\n","starting epoch 2. time passed: 0:03:07.880016\n","starting epoch 3. time passed: 0:05:06.831031\n","starting epoch 4. time passed: 0:06:59.762063\n","starting epoch 5. time passed: 0:08:57.526430\n","starting epoch 6. time passed: 0:10:53.901778\n","starting epoch 7. time passed: 0:12:47.371527\n","starting epoch 8. time passed: 0:14:39.663039\n","starting epoch 9. time passed: 0:16:31.445837\n","starting epoch 10. time passed: 0:18:23.261685\n","starting epoch 11. time passed: 0:20:15.036282\n","starting epoch 12. time passed: 0:22:09.800639\n","starting epoch 13. time passed: 0:24:03.648081\n","starting epoch 14. time passed: 0:25:56.725530\n","starting epoch 15. time passed: 0:27:50.307101\n","starting epoch 16. time passed: 0:29:42.790374\n","starting epoch 17. time passed: 0:31:35.509577\n","starting epoch 18. time passed: 0:33:28.609982\n","starting epoch 19. time passed: 0:35:20.477015\n","starting epoch 20. time passed: 0:37:12.359764\n","starting epoch 21. time passed: 0:39:05.885516\n","starting epoch 22. time passed: 0:41:01.741723\n","starting epoch 23. time passed: 0:42:58.226588\n","starting epoch 24. time passed: 0:44:53.427130\n","starting epoch 25. time passed: 0:46:48.716368\n","starting epoch 26. time passed: 0:48:43.455935\n","starting epoch 27. time passed: 0:50:37.812387\n","starting epoch 28. time passed: 0:52:33.587973\n","starting epoch 29. time passed: 0:54:27.836575\n","starting epoch 30. time passed: 0:56:20.478903\n","starting epoch 31. time passed: 0:58:10.830020\n","starting epoch 32. time passed: 1:00:01.217432\n","starting epoch 33. time passed: 1:01:51.643444\n","starting epoch 34. time passed: 1:03:41.624127\n","starting epoch 35. time passed: 1:05:31.887180\n","starting epoch 36. time passed: 1:07:26.025163\n","starting epoch 37. time passed: 1:09:21.549630\n","starting epoch 38. time passed: 1:11:14.697625\n","starting epoch 39. time passed: 1:13:08.059174\n","starting epoch 40. time passed: 1:15:00.144839\n","starting epoch 41. time passed: 1:16:52.132219\n","starting epoch 42. time passed: 1:18:43.275008\n","starting epoch 43. time passed: 1:20:33.240259\n","starting epoch 44. time passed: 1:22:24.138344\n","starting epoch 45. time passed: 1:24:16.230589\n","starting epoch 46. time passed: 1:26:08.105653\n","starting epoch 47. time passed: 1:28:01.111834\n","starting epoch 48. time passed: 1:29:52.974705\n","starting epoch 49. time passed: 1:31:43.612128\n","starting epoch 50. time passed: 1:33:34.136340\n","starting epoch 51. time passed: 1:35:24.575674\n","starting epoch 52. time passed: 1:37:15.373642\n","starting epoch 53. time passed: 1:39:05.814008\n","starting epoch 54. time passed: 1:40:56.007945\n","starting epoch 55. time passed: 1:42:46.192857\n","starting epoch 56. time passed: 1:44:36.471795\n","starting epoch 57. time passed: 1:46:27.033468\n","starting epoch 58. time passed: 1:48:17.025220\n","starting epoch 59. time passed: 1:50:06.951951\n","starting epoch 60. time passed: 1:51:57.085722\n","starting epoch 61. time passed: 1:53:47.964539\n","starting epoch 62. time passed: 1:55:38.209503\n","starting epoch 63. time passed: 1:57:28.423479\n","starting epoch 64. time passed: 1:59:18.638386\n","starting epoch 65. time passed: 2:01:08.949068\n","starting epoch 66. time passed: 2:02:58.929857\n","starting epoch 67. time passed: 2:04:49.350106\n","starting epoch 68. time passed: 2:06:39.456568\n","starting epoch 69. time passed: 2:08:29.381219\n","starting epoch 70. time passed: 2:10:19.710588\n","starting epoch 71. time passed: 2:12:09.573845\n","starting epoch 72. time passed: 2:13:59.589187\n","starting epoch 73. time passed: 2:15:49.931500\n","starting epoch 74. time passed: 2:17:39.828596\n","starting epoch 75. time passed: 2:19:30.358381\n","starting epoch 76. time passed: 2:21:21.554846\n","starting epoch 77. time passed: 2:23:15.457734\n","starting epoch 78. time passed: 2:25:10.230926\n","starting epoch 79. time passed: 2:27:05.374001\n","starting epoch 80. time passed: 2:28:59.028633\n","starting epoch 81. time passed: 2:30:52.467929\n","starting epoch 82. time passed: 2:32:45.555371\n","starting epoch 83. time passed: 2:34:39.120196\n","starting epoch 84. time passed: 2:36:33.868556\n","starting epoch 85. time passed: 2:38:29.077405\n","starting epoch 86. time passed: 2:40:24.114905\n","starting epoch 87. time passed: 2:42:18.182597\n","starting epoch 88. time passed: 2:44:12.128684\n","starting epoch 89. time passed: 2:46:06.384859\n","starting epoch 90. time passed: 2:48:00.814902\n","starting epoch 91. time passed: 2:49:54.497603\n","starting epoch 92. time passed: 2:51:46.273712\n","starting epoch 93. time passed: 2:53:37.309638\n","starting epoch 94. time passed: 2:55:27.404493\n","starting epoch 95. time passed: 2:57:17.509819\n","starting epoch 96. time passed: 2:59:07.994115\n","starting epoch 97. time passed: 3:00:58.898836\n","starting epoch 98. time passed: 3:02:50.008492\n","starting epoch 99. time passed: 3:04:41.419786\n","starting epoch 100. time passed: 3:06:32.941284\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"9RIgoOWtyPpD","colab_type":"text"},"source":["REMOVE NOISE AND R ADAM"]},{"cell_type":"code","metadata":{"id":"aKaozqT5xL2X","colab_type":"code","outputId":"5b3c0d56-270c-4d07-8acb-6d2e32a4ad43","executionInfo":{"status":"ok","timestamp":1580430909160,"user_tz":300,"elapsed":25041,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \"\"\"\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.8,1.2,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \"\"\"\n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XS6ujwACHxeN","colab_type":"code","colab":{}},"source":["import math\n","import torch\n","from torch.optim.optimizer import Optimizer, required\n","\n","class RAdam(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        \n","        self.degenerated_to_sgd = degenerated_to_sgd\n","        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n","            for param in params:\n","                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n","                    param['buffer'] = [[None, None, None] for _ in range(10)]\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n","        super(RAdam, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(RAdam, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('RAdam does not support sparse gradients')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                state['step'] += 1\n","                buffered = group['buffer'][int(state['step'] % 10)]\n","                if state['step'] == buffered[0]:\n","                    N_sma, step_size = buffered[1], buffered[2]\n","                else:\n","                    buffered[0] = state['step']\n","                    beta2_t = beta2 ** state['step']\n","                    N_sma_max = 2 / (1 - beta2) - 1\n","                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n","                    buffered[1] = N_sma\n","\n","                    # more conservative since it's an approximated value\n","                    if N_sma >= 5:\n","                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n","                    elif self.degenerated_to_sgd:\n","                        step_size = 1.0 / (1 - beta1 ** state['step'])\n","                    else:\n","                        step_size = -1\n","                    buffered[2] = step_size\n","\n","                # more conservative since it's an approximated value\n","                if N_sma >= 5:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n","                    p.data.copy_(p_data_fp32)\n","                elif step_size > 0:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n","                    p.data.copy_(p_data_fp32)\n","\n","        return loss\n","\n","class PlainRAdam(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","                    \n","        self.degenerated_to_sgd = degenerated_to_sgd\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n","\n","        super(PlainRAdam, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(PlainRAdam, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('RAdam does not support sparse gradients')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                state['step'] += 1\n","                beta2_t = beta2 ** state['step']\n","                N_sma_max = 2 / (1 - beta2) - 1\n","                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n","\n","\n","                # more conservative since it's an approximated value\n","                if N_sma >= 5:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n","                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n","                    p.data.copy_(p_data_fp32)\n","                elif self.degenerated_to_sgd:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n","                    p_data_fp32.add_(-step_size, exp_avg)\n","                    p.data.copy_(p_data_fp32)\n","\n","        return loss\n","\n","\n","class AdamW(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        \n","        defaults = dict(lr=lr, betas=betas, eps=eps,\n","                        weight_decay=weight_decay, warmup = warmup)\n","        super(AdamW, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(AdamW, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                state['step'] += 1\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","                \n","                if group['warmup'] > state['step']:\n","                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n","                else:\n","                    scheduled_lr = group['lr']\n","\n","                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n","                \n","                if group['weight_decay'] != 0:\n","                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n","\n","                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n","\n","                p.data.copy_(p_data_fp32)\n","\n","        return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtRWdqgOyqI4","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import numpy as np\n","import os\n","import torch\n","\n","from datetime import datetime\n","from pathlib import Path\n","from sklearn import metrics\n","\n","def train(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu):\n","    \n","    val_auc_array = list()\n","    train_auc_array = list()\n","    test_auc_array = list()\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    \n","    model = MRNet()\n","    \n","    if use_gpu:\n","        model = model.cuda()\n","\n","    optimizer = RAdam(model.parameters(), learning_rate, weight_decay=.01)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=.3, threshold=1e-4)\n","\n","    best_val_loss = float('inf')\n","\n","    start_time = datetime.now()\n","\n","    for epoch in range(epochs):\n","        change = datetime.now() - start_time\n","        print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n","        \n","        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer)\n","        val_loss, val_auc, _, _ = run_model(model, valid_loader)\n","        test_loss, test_auc, _, _ = run_model(model, test_loader)\n","\n","        val_auc_array.append(val_auc)\n","        train_auc_array.append(train_auc)\n","        test_auc_array.append(test_auc)\n","        \n","        scheduler.step(val_loss)\n","            \n","    return val_auc_array, train_auc_array, test_auc_array\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dP42V5lUzeBF","colab_type":"code","outputId":"98fabaa6-63fa-419a-8304-5d4a82945d5b","executionInfo":{"status":"ok","timestamp":1580284123221,"user_tz":300,"elapsed":4066709,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBvkoV5Czhw-kPY8IRbFEqQJdihIM9OvzHjL7ygFf2VajoeoXOKGuil7yGaDjz2g5bV3sxVA2Q7UMt2_59dhuks4Hcp-pOsBECPNWJPfMXzf_INkCAg85Vkmb2EcuI8FFkmqGgjEUabxK5dbBS-b0f4gYO9DYnxO0jHdon69v-GQ5n862dRg3ge8ITFoU4QJ9TaioiMRnDN8ggWEsDg1kCwo46PVzjCxOQzeYeEPBPhqm-bRXLd249mtymyijVZE4OekL-EOQyaHvwuHiFCRznyWI35cLgyy-mp8UXmpZhiYRZGBqsYjmaSpHxMwdyZ-nlWaAMhpu4Yz6qIwJFSG_416jsemNEkrPr7yCh_fR3b5kpQd8rBV-1jG2okGWryvzkI4dpARfgQyWUfUJR5ukKhBVCSyR7TPe9q_X37YZ7diYSEDMo2lcNcdmRxCwepnWIAsJMvzO-HWJ_owzyQzie_L97vEuuTPP_8qVnLuR9mtUUIaOHuZ58sdLJF4xij6k2m8q6OaTG2jQFn6SC9Fv8us2r9_LVKvAP5Kp2bNBdWNz6oRZHPdM2zA1ieOowTY2xjAa7vlvaQFU-imEXQpX01ZFL5UDs6-z9KkEHNcAQOcWI-LDOoxLXKTJ1RemN9w7WsVkiwVH2FABXhzYkV1h3o5bj0t_6Kwikueen34h4im29XHMy9s_cNoDc147stPItNbGoqVMZCNR788tLbpuSqWeYoNrjqr89dh83EbRhEBrfICDXAvI4N116wEWs=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:03<00:00, 71.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000010\n","starting epoch 2. time passed: 0:04:28.956961\n","starting epoch 3. time passed: 0:05:25.329265\n","starting epoch 4. time passed: 0:06:22.244604\n","starting epoch 5. time passed: 0:07:19.506946\n","starting epoch 6. time passed: 0:08:16.380846\n","starting epoch 7. time passed: 0:09:13.818389\n","starting epoch 8. time passed: 0:10:10.823981\n","starting epoch 9. time passed: 0:11:06.991406\n","starting epoch 10. time passed: 0:12:03.568380\n","starting epoch 11. time passed: 0:12:59.689827\n","starting epoch 12. time passed: 0:13:55.765788\n","starting epoch 13. time passed: 0:14:52.145300\n","starting epoch 14. time passed: 0:15:48.599045\n","starting epoch 15. time passed: 0:16:44.904264\n","starting epoch 16. time passed: 0:17:41.094900\n","starting epoch 17. time passed: 0:18:37.411970\n","starting epoch 18. time passed: 0:19:34.038947\n","starting epoch 19. time passed: 0:20:30.145855\n","starting epoch 20. time passed: 0:21:25.987512\n","starting epoch 21. time passed: 0:22:21.922422\n","starting epoch 22. time passed: 0:23:17.746759\n","starting epoch 23. time passed: 0:24:13.476503\n","starting epoch 24. time passed: 0:25:09.193276\n","starting epoch 25. time passed: 0:26:04.816073\n","starting epoch 26. time passed: 0:27:00.797690\n","starting epoch 27. time passed: 0:27:59.182733\n","starting epoch 28. time passed: 0:28:57.516475\n","starting epoch 29. time passed: 0:29:55.708906\n","starting epoch 30. time passed: 0:30:52.771869\n","starting epoch 31. time passed: 0:31:49.455807\n","starting epoch 32. time passed: 0:32:46.005338\n","starting epoch 33. time passed: 0:33:42.801519\n","starting epoch 34. time passed: 0:34:39.860831\n","starting epoch 35. time passed: 0:35:37.361717\n","starting epoch 36. time passed: 0:36:34.201256\n","starting epoch 37. time passed: 0:37:31.455906\n","starting epoch 38. time passed: 0:38:28.457374\n","starting epoch 39. time passed: 0:39:25.351742\n","starting epoch 40. time passed: 0:40:22.478865\n","starting epoch 41. time passed: 0:41:19.407332\n","starting epoch 42. time passed: 0:42:16.660749\n","starting epoch 43. time passed: 0:43:13.455350\n","starting epoch 44. time passed: 0:44:10.496001\n","starting epoch 45. time passed: 0:45:07.635218\n","starting epoch 46. time passed: 0:46:04.776238\n","starting epoch 47. time passed: 0:47:01.834109\n","starting epoch 48. time passed: 0:47:58.829265\n","starting epoch 49. time passed: 0:48:55.624683\n","starting epoch 50. time passed: 0:49:52.421782\n","starting epoch 51. time passed: 0:50:49.380396\n","starting epoch 52. time passed: 0:51:47.480101\n","starting epoch 53. time passed: 0:52:44.669850\n","starting epoch 54. time passed: 0:53:41.569885\n","starting epoch 55. time passed: 0:54:38.280327\n","starting epoch 56. time passed: 0:55:34.853150\n","starting epoch 57. time passed: 0:56:31.560477\n","starting epoch 58. time passed: 0:57:27.892677\n","starting epoch 59. time passed: 0:58:24.253728\n","starting epoch 60. time passed: 0:59:20.417310\n","starting epoch 61. time passed: 1:00:16.913019\n","starting epoch 62. time passed: 1:01:13.488606\n","starting epoch 63. time passed: 1:02:09.813266\n","starting epoch 64. time passed: 1:03:05.877509\n","starting epoch 65. time passed: 1:04:02.163603\n","starting epoch 66. time passed: 1:04:58.340574\n","starting epoch 67. time passed: 1:05:54.708933\n","starting epoch 68. time passed: 1:06:50.815747\n","starting epoch 69. time passed: 1:07:46.954575\n","starting epoch 70. time passed: 1:08:43.086054\n","starting epoch 71. time passed: 1:09:39.405119\n","starting epoch 72. time passed: 1:10:35.787954\n","starting epoch 73. time passed: 1:11:31.934874\n","starting epoch 74. time passed: 1:12:27.712131\n","starting epoch 75. time passed: 1:13:23.815436\n","starting epoch 76. time passed: 1:14:19.902763\n","starting epoch 77. time passed: 1:15:15.989117\n","starting epoch 78. time passed: 1:16:12.125317\n","starting epoch 79. time passed: 1:17:08.449043\n","starting epoch 80. time passed: 1:18:04.501790\n","starting epoch 81. time passed: 1:19:00.565861\n","starting epoch 82. time passed: 1:19:56.648321\n","starting epoch 83. time passed: 1:20:52.725254\n","starting epoch 84. time passed: 1:21:48.815890\n","starting epoch 85. time passed: 1:22:44.645855\n","starting epoch 86. time passed: 1:23:40.515502\n","starting epoch 87. time passed: 1:24:36.561178\n","starting epoch 88. time passed: 1:25:32.412762\n","starting epoch 89. time passed: 1:26:28.460635\n","starting epoch 90. time passed: 1:27:24.561484\n","starting epoch 91. time passed: 1:28:20.550740\n","starting epoch 92. time passed: 1:29:16.527442\n","starting epoch 93. time passed: 1:30:12.454740\n","starting epoch 94. time passed: 1:31:08.618853\n","starting epoch 95. time passed: 1:32:04.970283\n","starting epoch 96. time passed: 1:33:01.000994\n","starting epoch 97. time passed: 1:33:56.967015\n","starting epoch 98. time passed: 1:34:53.221906\n","starting epoch 99. time passed: 1:35:49.354093\n","starting epoch 100. time passed: 1:36:45.427450\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dkuoaqm9z_Zy","colab_type":"code","outputId":"f8ccb883-72cb-4827-91c0-abd806221644","executionInfo":{"status":"ok","timestamp":1580332554016,"user_tz":300,"elapsed":5702973,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3WmiXXvfN_GN5rq_w8vbn0k83zEv82VzHArvfojW-gHtkzYYgWA2it5NlAfqPweyyNWZqYB313Dy73h2lfHQMioHLYiyMJOFTPnMdKICgiomxtXFBPcYVAoZSxNUMPVaIrvmT2cGFRRMbJ8LaJv0TBeKy2tilfaTZW4xIZaNTX2osEpYNKjNDDQNBAXHdLW8_fKtbxC57Yvw9_p-Pcuhm5HaezSuWGm_t4BrV9EeLIi2wKK2OeBsOrdSNNlEeFO7Nut4esRuKKpBCqEkzm26fXWkZtSVhvZCfqsSb2AkXRjszzaI5jEPHwLor6UCVNwrFm55iu2XTyX2msZvXnDCky1qVomBEuHTXqbtXq6JhDgKDyWeMSgH0Of-a_QMUD2HG5s_MZEvGiGIqSGiiGSf5XQTnLuzCKDLADxjc-ZUM1qWxVO4zS-VmyENg2z0qyULxO2m3bFJatIZo8nm_dUUUAHINGSB04M2unCHNWjjH_OH1PjbM9yD3hcj_Y5J-l-RhI8AMelUj6OMUNtWbN0bdtU2h0QTm_xsj8cHlcExnMZ2FmrQzBmlnvrsLhS5249rOkBY6pEbTI8JcKMjzkQHU0tbIHkbueGTeGITaKrkXDPpx2fcCcIrIm05XsXUorxI2Jg4hsSGXu2ydES4aspNn8mWuT5gAoUEtUbOrpn1NpNg0sP962v-iFP1Rp0OWrZBLPG5aCuHOiNerPvKw-GHrJu2hBGZrgLJ6s7NEx7shIAaydw4ALOBrqPj2L_U=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#cor w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:02<00:00, 108MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000009\n","starting epoch 2. time passed: 0:02:39.364778\n","starting epoch 3. time passed: 0:03:36.845857\n","starting epoch 4. time passed: 0:04:34.065164\n","starting epoch 5. time passed: 0:05:30.941940\n","starting epoch 6. time passed: 0:06:28.095167\n","starting epoch 7. time passed: 0:07:25.297514\n","starting epoch 8. time passed: 0:08:21.940800\n","starting epoch 9. time passed: 0:09:18.734126\n","starting epoch 10. time passed: 0:10:15.192760\n","starting epoch 11. time passed: 0:11:11.853043\n","starting epoch 12. time passed: 0:12:08.702729\n","starting epoch 13. time passed: 0:13:05.133380\n","starting epoch 14. time passed: 0:14:01.207523\n","starting epoch 15. time passed: 0:14:57.365153\n","starting epoch 16. time passed: 0:15:53.248433\n","starting epoch 17. time passed: 0:16:49.281655\n","starting epoch 18. time passed: 0:17:44.798768\n","starting epoch 19. time passed: 0:18:40.737233\n","starting epoch 20. time passed: 0:19:36.550846\n","starting epoch 21. time passed: 0:20:31.923808\n","starting epoch 22. time passed: 0:21:27.457909\n","starting epoch 23. time passed: 0:22:22.808668\n","starting epoch 24. time passed: 0:23:18.162040\n","starting epoch 25. time passed: 0:24:13.653981\n","starting epoch 26. time passed: 0:25:09.251080\n","starting epoch 27. time passed: 0:26:04.455225\n","starting epoch 28. time passed: 0:26:59.405748\n","starting epoch 29. time passed: 0:27:54.687120\n","starting epoch 30. time passed: 0:28:50.339799\n","starting epoch 31. time passed: 0:29:45.956891\n","starting epoch 32. time passed: 0:30:41.838315\n","starting epoch 33. time passed: 0:31:37.569294\n","starting epoch 34. time passed: 0:32:33.134594\n","starting epoch 35. time passed: 0:33:28.982996\n","starting epoch 36. time passed: 0:34:24.659326\n","starting epoch 37. time passed: 0:35:20.230365\n","starting epoch 38. time passed: 0:36:15.648296\n","starting epoch 39. time passed: 0:37:11.301189\n","starting epoch 40. time passed: 0:38:07.154776\n","starting epoch 41. time passed: 0:39:03.511270\n","starting epoch 42. time passed: 0:39:59.606760\n","starting epoch 43. time passed: 0:40:55.172792\n","starting epoch 44. time passed: 0:41:50.452662\n","starting epoch 45. time passed: 0:42:45.832448\n","starting epoch 46. time passed: 0:43:41.370215\n","starting epoch 47. time passed: 0:44:36.468135\n","starting epoch 48. time passed: 0:45:32.078993\n","starting epoch 49. time passed: 0:46:27.661721\n","starting epoch 50. time passed: 0:47:23.075416\n","starting epoch 51. time passed: 0:48:18.554737\n","starting epoch 52. time passed: 0:49:13.837184\n","starting epoch 53. time passed: 0:50:09.414208\n","starting epoch 54. time passed: 0:51:04.761473\n","starting epoch 55. time passed: 0:52:00.533347\n","starting epoch 56. time passed: 0:52:56.273415\n","starting epoch 57. time passed: 0:53:51.758345\n","starting epoch 58. time passed: 0:54:46.888359\n","starting epoch 59. time passed: 0:55:42.337424\n","starting epoch 60. time passed: 0:56:37.981631\n","starting epoch 61. time passed: 0:57:33.833222\n","starting epoch 62. time passed: 0:58:29.597700\n","starting epoch 63. time passed: 0:59:24.869671\n","starting epoch 64. time passed: 1:00:20.517841\n","starting epoch 65. time passed: 1:01:16.023682\n","starting epoch 66. time passed: 1:02:11.443694\n","starting epoch 67. time passed: 1:03:06.871439\n","starting epoch 68. time passed: 1:04:02.598423\n","starting epoch 69. time passed: 1:04:58.009267\n","starting epoch 70. time passed: 1:05:53.273018\n","starting epoch 71. time passed: 1:06:48.532516\n","starting epoch 72. time passed: 1:07:44.106311\n","starting epoch 73. time passed: 1:08:39.477963\n","starting epoch 74. time passed: 1:09:36.030652\n","starting epoch 75. time passed: 1:10:31.827504\n","starting epoch 76. time passed: 1:11:27.681314\n","starting epoch 77. time passed: 1:12:23.153224\n","starting epoch 78. time passed: 1:13:18.816516\n","starting epoch 79. time passed: 1:14:14.661792\n","starting epoch 80. time passed: 1:15:10.205258\n","starting epoch 81. time passed: 1:16:05.970916\n","starting epoch 82. time passed: 1:17:01.991679\n","starting epoch 83. time passed: 1:17:57.954242\n","starting epoch 84. time passed: 1:18:53.754918\n","starting epoch 85. time passed: 1:19:49.396960\n","starting epoch 86. time passed: 1:20:45.038349\n","starting epoch 87. time passed: 1:21:41.060165\n","starting epoch 88. time passed: 1:22:37.104301\n","starting epoch 89. time passed: 1:23:33.010001\n","starting epoch 90. time passed: 1:24:28.825047\n","starting epoch 91. time passed: 1:25:24.778136\n","starting epoch 92. time passed: 1:26:20.622751\n","starting epoch 93. time passed: 1:27:16.389519\n","starting epoch 94. time passed: 1:28:12.244685\n","starting epoch 95. time passed: 1:29:08.326022\n","starting epoch 96. time passed: 1:30:03.965279\n","starting epoch 97. time passed: 1:30:59.615051\n","starting epoch 98. time passed: 1:31:55.549005\n","starting epoch 99. time passed: 1:32:51.816434\n","starting epoch 100. time passed: 1:33:47.484188\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Tw1wI3-G0AdZ","colab_type":"code","outputId":"31ff5cc3-f62b-4384-ca1b-abdb5a6daeee","executionInfo":{"status":"ok","timestamp":1580339039843,"user_tz":300,"elapsed":4628947,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3WmiXXvfN_GN5rq_w8vbn0k83zEv82VzHArvfojW-gHtkzYYgWA2it5NlAfqPweyyNWZqYB313Dy73h2lfHQMioHLYiyMJOFTPnMdKICgiomxtXFBPcYVAoZSxNUMPVaIrvmT2cGFRRMbJ8LaJv0TBeKy2tilfaTZW4xIZaNTX2osEpYNKjNDDQNBAXHdLW8_fKtbxC57Yvw9_p-Pcuhm5HaezSuWGm_t4BrV9EeLIi2wKK2OeBsOrdSNNlEeFO7Nut4esRuKKpBCqEkzm26fXWkZtSVhvZCfqsSb2AkXRjszzaI5jEPHwLor6UCVNwrFm55iu2XTyX2msZvXnDCky1qVomBEuHTXqbtXq6JhDgKDyWeMSgH0Of-a_QMUD2HG5s_MZEvGiGIqSGiiGSf5XQTnLuzCKDLADxjc-ZUM1qWxVO4zS-VmyENg2z0qyULxO2m3bFJatIZo8nm_dUUUAHINGSB04M2unCHNWjjH_OH1PjbM9yD3hcj_Y5J-l-RhI8AMelUj6OMUNtWbN0bdtU2h0QTm_xsj8cHlcExnMZ2FmrQzBmlnvrsLhS5249rOkBY6pEbTI8JcKMjzkQHU0tbIHkbueGTeGITaKrkXDPpx2fcCcIrIm05XsXUorxI2Jg4hsSGXu2ydES4aspNn8mWuT5gAoUEtUbOrpn1NpNg0sP962v-iFP1Rp0OWrZBLPG5aCuHOiNerPvKw-GHrJu2hBGZrgLJ6s7NEx7shIAaydw4ALOBrqPj2L_U=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#ax w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n","starting epoch 1. time passed: 0:00:00.000010\n","starting epoch 2. time passed: 0:03:11.696643\n","starting epoch 3. time passed: 0:04:25.403846\n","starting epoch 4. time passed: 0:05:28.607696\n","starting epoch 5. time passed: 0:06:31.798377\n","starting epoch 6. time passed: 0:07:35.277487\n","starting epoch 7. time passed: 0:08:38.554776\n","starting epoch 8. time passed: 0:09:42.332244\n","starting epoch 9. time passed: 0:10:46.280585\n","starting epoch 10. time passed: 0:11:49.887717\n","starting epoch 11. time passed: 0:12:53.852742\n","starting epoch 12. time passed: 0:13:57.315844\n","starting epoch 13. time passed: 0:15:00.359794\n","starting epoch 14. time passed: 0:16:03.586647\n","starting epoch 15. time passed: 0:17:07.325709\n","starting epoch 16. time passed: 0:18:11.056199\n","starting epoch 17. time passed: 0:19:14.681476\n","starting epoch 18. time passed: 0:20:18.051238\n","starting epoch 19. time passed: 0:21:21.596772\n","starting epoch 20. time passed: 0:22:25.200191\n","starting epoch 21. time passed: 0:23:28.650055\n","starting epoch 22. time passed: 0:24:31.985283\n","starting epoch 23. time passed: 0:25:35.914743\n","starting epoch 24. time passed: 0:26:39.569058\n","starting epoch 25. time passed: 0:27:43.152207\n","starting epoch 26. time passed: 0:28:46.901950\n","starting epoch 27. time passed: 0:29:51.007952\n","starting epoch 28. time passed: 0:30:55.182995\n","starting epoch 29. time passed: 0:31:59.140692\n","starting epoch 30. time passed: 0:33:03.071852\n","starting epoch 31. time passed: 0:34:06.772472\n","starting epoch 32. time passed: 0:35:09.919270\n","starting epoch 33. time passed: 0:36:12.800122\n","starting epoch 34. time passed: 0:37:16.188893\n","starting epoch 35. time passed: 0:38:19.329076\n","starting epoch 36. time passed: 0:39:22.308385\n","starting epoch 37. time passed: 0:40:25.110656\n","starting epoch 38. time passed: 0:41:27.809673\n","starting epoch 39. time passed: 0:42:30.652541\n","starting epoch 40. time passed: 0:43:33.561296\n","starting epoch 41. time passed: 0:44:36.743866\n","starting epoch 42. time passed: 0:45:39.582013\n","starting epoch 43. time passed: 0:46:42.842703\n","starting epoch 44. time passed: 0:47:45.716882\n","starting epoch 45. time passed: 0:48:49.210729\n","starting epoch 46. time passed: 0:49:52.588603\n","starting epoch 47. time passed: 0:50:55.778830\n","starting epoch 48. time passed: 0:51:59.359502\n","starting epoch 49. time passed: 0:53:02.341077\n","starting epoch 50. time passed: 0:54:05.633133\n","starting epoch 51. time passed: 0:55:08.285305\n","starting epoch 52. time passed: 0:56:11.183408\n","starting epoch 53. time passed: 0:57:13.842972\n","starting epoch 54. time passed: 0:58:16.474443\n","starting epoch 55. time passed: 0:59:19.398978\n","starting epoch 56. time passed: 1:00:21.830137\n","starting epoch 57. time passed: 1:01:24.302550\n","starting epoch 58. time passed: 1:02:26.717112\n","starting epoch 59. time passed: 1:03:29.261429\n","starting epoch 60. time passed: 1:04:31.687960\n","starting epoch 61. time passed: 1:05:33.975400\n","starting epoch 62. time passed: 1:06:36.478881\n","starting epoch 63. time passed: 1:07:38.611525\n","starting epoch 64. time passed: 1:08:40.702980\n","starting epoch 65. time passed: 1:09:42.807175\n","starting epoch 66. time passed: 1:10:44.953150\n","starting epoch 67. time passed: 1:11:47.161745\n","starting epoch 68. time passed: 1:12:49.370559\n","starting epoch 69. time passed: 1:13:51.647087\n","starting epoch 70. time passed: 1:14:54.506429\n","starting epoch 71. time passed: 1:15:56.738640\n","starting epoch 72. time passed: 1:16:58.932985\n","starting epoch 73. time passed: 1:18:00.891201\n","starting epoch 74. time passed: 1:19:03.032174\n","starting epoch 75. time passed: 1:20:05.304632\n","starting epoch 76. time passed: 1:21:07.758065\n","starting epoch 77. time passed: 1:22:10.399213\n","starting epoch 78. time passed: 1:23:13.189667\n","starting epoch 79. time passed: 1:24:15.687463\n","starting epoch 80. time passed: 1:25:18.352250\n","starting epoch 81. time passed: 1:26:20.639037\n","starting epoch 82. time passed: 1:27:22.597808\n","starting epoch 83. time passed: 1:28:24.768195\n","starting epoch 84. time passed: 1:29:27.165805\n","starting epoch 85. time passed: 1:30:29.499386\n","starting epoch 86. time passed: 1:31:32.193067\n","starting epoch 87. time passed: 1:32:34.572276\n","starting epoch 88. time passed: 1:33:36.840207\n","starting epoch 89. time passed: 1:34:39.425706\n","starting epoch 90. time passed: 1:35:42.206378\n","starting epoch 91. time passed: 1:36:45.241796\n","starting epoch 92. time passed: 1:37:48.691367\n","starting epoch 93. time passed: 1:38:53.062888\n","starting epoch 94. time passed: 1:39:57.705893\n","starting epoch 95. time passed: 1:41:02.778403\n","starting epoch 96. time passed: 1:42:08.254091\n","starting epoch 97. time passed: 1:43:14.080798\n","starting epoch 98. time passed: 1:44:19.889800\n","starting epoch 99. time passed: 1:45:25.718710\n","starting epoch 100. time passed: 1:46:31.570403\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2AsbaCOo0BEw","colab_type":"text"},"source":["add rotation"]},{"cell_type":"code","metadata":{"id":"b9ZbXd6u0C04","colab_type":"code","outputId":"c7510863-a508-47a7-aef7-78aeadf36bdd","executionInfo":{"status":"ok","timestamp":1580349366811,"user_tz":300,"elapsed":14166665,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3WmiXXvfN_GN5rq_w8vbn0k83zEv82VzHArvfojW-gHtkzYYgWA2it5NlAfqPweyyNWZqYB313Dy73h2lfHQMioHLYiyMJOFTPnMdKICgiomxtXFBPcYVAoZSxNUMPVaIrvmT2cGFRRMbJ8LaJv0TBeKy2tilfaTZW4xIZaNTX2osEpYNKjNDDQNBAXHdLW8_fKtbxC57Yvw9_p-Pcuhm5HaezSuWGm_t4BrV9EeLIi2wKK2OeBsOrdSNNlEeFO7Nut4esRuKKpBCqEkzm26fXWkZtSVhvZCfqsSb2AkXRjszzaI5jEPHwLor6UCVNwrFm55iu2XTyX2msZvXnDCky1qVomBEuHTXqbtXq6JhDgKDyWeMSgH0Of-a_QMUD2HG5s_MZEvGiGIqSGiiGSf5XQTnLuzCKDLADxjc-ZUM1qWxVO4zS-VmyENg2z0qyULxO2m3bFJatIZo8nm_dUUUAHINGSB04M2unCHNWjjH_OH1PjbM9yD3hcj_Y5J-l-RhI8AMelUj6OMUNtWbN0bdtU2h0QTm_xsj8cHlcExnMZ2FmrQzBmlnvrsLhS5249rOkBY6pEbTI8JcKMjzkQHU0tbIHkbueGTeGITaKrkXDPpx2fcCcIrIm05XsXUorxI2Jg4hsSGXu2ydES4aspNn8mWuT5gAoUEtUbOrpn1NpNg0sP962v-iFP1Rp0OWrZBLPG5aCuHOiNerPvKw-GHrJu2hBGZrgLJ6s7NEx7shIAaydw4ALOBrqPj2L_U=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n","starting epoch 1. time passed: 0:00:00.000009\n","starting epoch 2. time passed: 0:02:58.222731\n","starting epoch 3. time passed: 0:04:44.193748\n","starting epoch 4. time passed: 0:06:25.014733\n","starting epoch 5. time passed: 0:08:06.601822\n","starting epoch 6. time passed: 0:09:48.999818\n","starting epoch 7. time passed: 0:11:31.351559\n","starting epoch 8. time passed: 0:13:13.968526\n","starting epoch 9. time passed: 0:14:56.976449\n","starting epoch 10. time passed: 0:16:39.154027\n","starting epoch 11. time passed: 0:18:21.816929\n","starting epoch 12. time passed: 0:20:04.560071\n","starting epoch 13. time passed: 0:21:47.660442\n","starting epoch 14. time passed: 0:23:30.673571\n","starting epoch 15. time passed: 0:25:13.256366\n","starting epoch 16. time passed: 0:26:55.860442\n","starting epoch 17. time passed: 0:28:38.514448\n","starting epoch 18. time passed: 0:30:21.423806\n","starting epoch 19. time passed: 0:32:04.406160\n","starting epoch 20. time passed: 0:33:47.888411\n","starting epoch 21. time passed: 0:35:30.957155\n","starting epoch 22. time passed: 0:37:14.030376\n","starting epoch 23. time passed: 0:38:57.323149\n","starting epoch 24. time passed: 0:40:40.480730\n","starting epoch 25. time passed: 0:42:23.801070\n","starting epoch 26. time passed: 0:44:07.157478\n","starting epoch 27. time passed: 0:45:50.003235\n","starting epoch 28. time passed: 0:47:32.699760\n","starting epoch 29. time passed: 0:49:15.770901\n","starting epoch 30. time passed: 0:50:58.836327\n","starting epoch 31. time passed: 0:52:42.295923\n","starting epoch 32. time passed: 0:54:25.506435\n","starting epoch 33. time passed: 0:56:07.911575\n","starting epoch 34. time passed: 0:57:51.078165\n","starting epoch 35. time passed: 0:59:34.338400\n","starting epoch 36. time passed: 1:01:17.250949\n","starting epoch 37. time passed: 1:02:59.602026\n","starting epoch 38. time passed: 1:04:42.360526\n","starting epoch 39. time passed: 1:06:25.041457\n","starting epoch 40. time passed: 1:08:08.133805\n","starting epoch 41. time passed: 1:09:51.568409\n","starting epoch 42. time passed: 1:11:34.387949\n","starting epoch 43. time passed: 1:13:17.257796\n","starting epoch 44. time passed: 1:14:59.844401\n","starting epoch 45. time passed: 1:16:42.927593\n","starting epoch 46. time passed: 1:18:25.568535\n","starting epoch 47. time passed: 1:20:08.100795\n","starting epoch 48. time passed: 1:21:50.883459\n","starting epoch 49. time passed: 1:23:33.231867\n","starting epoch 50. time passed: 1:25:15.718109\n","starting epoch 51. time passed: 1:26:56.341543\n","starting epoch 52. time passed: 1:28:37.868740\n","starting epoch 53. time passed: 1:30:20.534360\n","starting epoch 54. time passed: 1:32:02.971469\n","starting epoch 55. time passed: 1:33:45.533934\n","starting epoch 56. time passed: 1:35:27.280106\n","starting epoch 57. time passed: 1:37:08.165692\n","starting epoch 58. time passed: 1:38:49.380891\n","starting epoch 59. time passed: 1:40:31.302904\n","starting epoch 60. time passed: 1:42:11.604807\n","starting epoch 61. time passed: 1:43:52.127943\n","starting epoch 62. time passed: 1:45:30.938546\n","starting epoch 63. time passed: 1:47:08.146426\n","starting epoch 64. time passed: 1:48:45.060575\n","starting epoch 65. time passed: 1:50:25.478236\n","starting epoch 66. time passed: 1:52:06.567150\n","starting epoch 67. time passed: 1:53:47.408012\n","starting epoch 68. time passed: 1:55:26.206967\n","starting epoch 69. time passed: 1:57:06.249256\n","starting epoch 70. time passed: 1:58:46.966332\n","starting epoch 71. time passed: 2:00:28.414470\n","starting epoch 72. time passed: 2:02:09.393633\n","starting epoch 73. time passed: 2:03:51.129963\n","starting epoch 74. time passed: 2:05:32.389547\n","starting epoch 75. time passed: 2:07:13.880338\n","starting epoch 76. time passed: 2:08:55.814074\n","starting epoch 77. time passed: 2:10:37.565710\n","starting epoch 78. time passed: 2:12:19.779755\n","starting epoch 79. time passed: 2:14:01.091449\n","starting epoch 80. time passed: 2:15:42.946630\n","starting epoch 81. time passed: 2:17:24.924791\n","starting epoch 82. time passed: 2:19:07.323328\n","starting epoch 83. time passed: 2:20:49.819688\n","starting epoch 84. time passed: 2:22:32.026365\n","starting epoch 85. time passed: 2:24:14.294867\n","starting epoch 86. time passed: 2:25:56.956313\n","starting epoch 87. time passed: 2:27:39.326651\n","starting epoch 88. time passed: 2:29:21.984740\n","starting epoch 89. time passed: 2:31:04.552170\n","starting epoch 90. time passed: 2:32:46.123197\n","starting epoch 91. time passed: 2:34:28.045319\n","starting epoch 92. time passed: 2:36:09.978686\n","starting epoch 93. time passed: 2:37:52.715252\n","starting epoch 94. time passed: 2:39:34.776920\n","starting epoch 95. time passed: 2:41:17.652048\n","starting epoch 96. time passed: 2:43:00.396677\n","starting epoch 97. time passed: 2:44:43.222798\n","starting epoch 98. time passed: 2:46:25.806463\n","starting epoch 99. time passed: 2:48:08.629064\n","starting epoch 100. time passed: 2:49:51.625439\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lPvr0TVw0PWy","colab_type":"code","outputId":"bb21541a-c594-4ec2-ec6e-9a3e6282547e","executionInfo":{"status":"ok","timestamp":1580359278616,"user_tz":300,"elapsed":8067098,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA3WmiXXvfN_GN5rq_w8vbn0k83zEv82VzHArvfojW-gHtkzYYgWA2it5NlAfqPweyyNWZqYB313Dy73h2lfHQMioHLYiyMJOFTPnMdKICgiomxtXFBPcYVAoZSxNUMPVaIrvmT2cGFRRMbJ8LaJv0TBeKy2tilfaTZW4xIZaNTX2osEpYNKjNDDQNBAXHdLW8_fKtbxC57Yvw9_p-Pcuhm5HaezSuWGm_t4BrV9EeLIi2wKK2OeBsOrdSNNlEeFO7Nut4esRuKKpBCqEkzm26fXWkZtSVhvZCfqsSb2AkXRjszzaI5jEPHwLor6UCVNwrFm55iu2XTyX2msZvXnDCky1qVomBEuHTXqbtXq6JhDgKDyWeMSgH0Of-a_QMUD2HG5s_MZEvGiGIqSGiiGSf5XQTnLuzCKDLADxjc-ZUM1qWxVO4zS-VmyENg2z0qyULxO2m3bFJatIZo8nm_dUUUAHINGSB04M2unCHNWjjH_OH1PjbM9yD3hcj_Y5J-l-RhI8AMelUj6OMUNtWbN0bdtU2h0QTm_xsj8cHlcExnMZ2FmrQzBmlnvrsLhS5249rOkBY6pEbTI8JcKMjzkQHU0tbIHkbueGTeGITaKrkXDPpx2fcCcIrIm05XsXUorxI2Jg4hsSGXu2ydES4aspNn8mWuT5gAoUEtUbOrpn1NpNg0sP962v-iFP1Rp0OWrZBLPG5aCuHOiNerPvKw-GHrJu2hBGZrgLJ6s7NEx7shIAaydw4ALOBrqPj2L_U=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#cor w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n","starting epoch 1. time passed: 0:00:00.000011\n","starting epoch 2. time passed: 0:02:07.562602\n","starting epoch 3. time passed: 0:03:52.957192\n","starting epoch 4. time passed: 0:05:35.347347\n","starting epoch 5. time passed: 0:07:17.736836\n","starting epoch 6. time passed: 0:08:59.741335\n","starting epoch 7. time passed: 0:10:41.738853\n","starting epoch 8. time passed: 0:12:23.350433\n","starting epoch 9. time passed: 0:14:05.260165\n","starting epoch 10. time passed: 0:15:46.640465\n","starting epoch 11. time passed: 0:17:26.945626\n","starting epoch 12. time passed: 0:19:06.081243\n","starting epoch 13. time passed: 0:20:46.602229\n","starting epoch 14. time passed: 0:22:27.417832\n","starting epoch 15. time passed: 0:24:08.742951\n","starting epoch 16. time passed: 0:25:49.995037\n","starting epoch 17. time passed: 0:27:31.480087\n","starting epoch 18. time passed: 0:29:12.797242\n","starting epoch 19. time passed: 0:30:54.080149\n","starting epoch 20. time passed: 0:32:35.940965\n","starting epoch 21. time passed: 0:34:17.384706\n","starting epoch 22. time passed: 0:35:58.813926\n","starting epoch 23. time passed: 0:37:40.144513\n","starting epoch 24. time passed: 0:39:21.840846\n","starting epoch 25. time passed: 0:41:03.523195\n","starting epoch 26. time passed: 0:42:44.939352\n","starting epoch 27. time passed: 0:44:26.237261\n","starting epoch 28. time passed: 0:46:07.382197\n","starting epoch 29. time passed: 0:47:48.355339\n","starting epoch 30. time passed: 0:49:29.788986\n","starting epoch 31. time passed: 0:51:09.851565\n","starting epoch 32. time passed: 0:52:50.347277\n","starting epoch 33. time passed: 0:54:30.970286\n","starting epoch 34. time passed: 0:56:11.486324\n","starting epoch 35. time passed: 0:57:52.845301\n","starting epoch 36. time passed: 0:59:33.809442\n","starting epoch 37. time passed: 1:01:14.804596\n","starting epoch 38. time passed: 1:02:55.724036\n","starting epoch 39. time passed: 1:04:37.089449\n","starting epoch 40. time passed: 1:06:18.288697\n","starting epoch 41. time passed: 1:07:59.266906\n","starting epoch 42. time passed: 1:09:39.891934\n","starting epoch 43. time passed: 1:11:18.865079\n","starting epoch 44. time passed: 1:12:56.050648\n","starting epoch 45. time passed: 1:14:33.192964\n","starting epoch 46. time passed: 1:16:08.459169\n","starting epoch 47. time passed: 1:17:43.297260\n","starting epoch 48. time passed: 1:19:17.899309\n","starting epoch 49. time passed: 1:20:51.676917\n","starting epoch 50. time passed: 1:22:24.538464\n","starting epoch 51. time passed: 1:23:57.845210\n","starting epoch 52. time passed: 1:25:31.143430\n","starting epoch 53. time passed: 1:27:04.039292\n","starting epoch 54. time passed: 1:28:36.528813\n","starting epoch 55. time passed: 1:30:09.075768\n","starting epoch 56. time passed: 1:31:41.286576\n","starting epoch 57. time passed: 1:33:14.131425\n","starting epoch 58. time passed: 1:34:48.596106\n","starting epoch 59. time passed: 1:36:21.276207\n","starting epoch 60. time passed: 1:37:53.872805\n","starting epoch 61. time passed: 1:39:29.456946\n","starting epoch 62. time passed: 1:41:08.017658\n","starting epoch 63. time passed: 1:42:45.414611\n","starting epoch 64. time passed: 1:44:23.652541\n","starting epoch 65. time passed: 1:46:02.305964\n","starting epoch 66. time passed: 1:47:40.743336\n","starting epoch 67. time passed: 1:49:17.994166\n","starting epoch 68. time passed: 1:50:57.832267\n","starting epoch 69. time passed: 1:52:38.958621\n","starting epoch 70. time passed: 1:54:19.832153\n","starting epoch 71. time passed: 1:56:00.688083\n","starting epoch 72. time passed: 1:57:39.844245\n","starting epoch 73. time passed: 1:59:18.995478\n","starting epoch 74. time passed: 2:00:58.385476\n","starting epoch 75. time passed: 2:02:37.973911\n","starting epoch 76. time passed: 2:04:17.455586\n","starting epoch 77. time passed: 2:05:57.620886\n","starting epoch 78. time passed: 2:07:37.085587\n","starting epoch 79. time passed: 2:09:17.396565\n","starting epoch 80. time passed: 2:10:57.424508\n","starting epoch 81. time passed: 2:12:38.043259\n","starting epoch 82. time passed: 2:14:18.618459\n","starting epoch 83. time passed: 2:15:58.542108\n","starting epoch 84. time passed: 2:17:38.696073\n","starting epoch 85. time passed: 2:19:19.427111\n","starting epoch 86. time passed: 2:21:00.387860\n","starting epoch 87. time passed: 2:22:40.784429\n","starting epoch 88. time passed: 2:24:21.406549\n","starting epoch 89. time passed: 2:26:01.532359\n","starting epoch 90. time passed: 2:27:41.459488\n","starting epoch 91. time passed: 2:29:21.281892\n","starting epoch 92. time passed: 2:31:01.337660\n","starting epoch 93. time passed: 2:32:39.610972\n","starting epoch 94. time passed: 2:34:14.477221\n","starting epoch 95. time passed: 2:35:47.665080\n","starting epoch 96. time passed: 2:37:21.350789\n","starting epoch 97. time passed: 2:38:53.801354\n","starting epoch 98. time passed: 2:40:26.483003\n","starting epoch 99. time passed: 2:41:59.077956\n","starting epoch 100. time passed: 2:43:31.378253\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_uwwQ9600P21","colab_type":"code","outputId":"9359c1a6-cc8d-49fd-c947-1ce4611228d6","executionInfo":{"status":"ok","timestamp":1580402430154,"user_tz":300,"elapsed":11259341,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#ax w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:04<00:00, 54.7MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000011\n","starting epoch 2. time passed: 0:03:22.346896\n","starting epoch 3. time passed: 0:05:09.435827\n","starting epoch 4. time passed: 0:06:55.638924\n","starting epoch 5. time passed: 0:08:42.849357\n","starting epoch 6. time passed: 0:10:31.607278\n","starting epoch 7. time passed: 0:12:20.637537\n","starting epoch 8. time passed: 0:14:10.505699\n","starting epoch 9. time passed: 0:15:59.697676\n","starting epoch 10. time passed: 0:17:48.849293\n","starting epoch 11. time passed: 0:19:37.432959\n","starting epoch 12. time passed: 0:21:26.724887\n","starting epoch 13. time passed: 0:23:16.714600\n","starting epoch 14. time passed: 0:25:05.425132\n","starting epoch 15. time passed: 0:26:52.712524\n","starting epoch 16. time passed: 0:28:41.630071\n","starting epoch 17. time passed: 0:30:31.044652\n","starting epoch 18. time passed: 0:32:19.072484\n","starting epoch 19. time passed: 0:34:06.440656\n","starting epoch 20. time passed: 0:35:53.624674\n","starting epoch 21. time passed: 0:37:40.821626\n","starting epoch 22. time passed: 0:39:29.441311\n","starting epoch 23. time passed: 0:41:16.669965\n","starting epoch 24. time passed: 0:43:03.790895\n","starting epoch 25. time passed: 0:44:52.255672\n","starting epoch 26. time passed: 0:46:39.285033\n","starting epoch 27. time passed: 0:48:27.974278\n","starting epoch 28. time passed: 0:50:16.476888\n","starting epoch 29. time passed: 0:52:05.460734\n","starting epoch 30. time passed: 0:53:54.125956\n","starting epoch 31. time passed: 0:55:42.685652\n","starting epoch 32. time passed: 0:57:31.813853\n","starting epoch 33. time passed: 0:59:22.131219\n","starting epoch 34. time passed: 1:01:11.939036\n","starting epoch 35. time passed: 1:03:01.269649\n","starting epoch 36. time passed: 1:04:52.534545\n","starting epoch 37. time passed: 1:06:42.964323\n","starting epoch 38. time passed: 1:08:33.507881\n","starting epoch 39. time passed: 1:10:24.189025\n","starting epoch 40. time passed: 1:12:13.672188\n","starting epoch 41. time passed: 1:14:02.564731\n","starting epoch 42. time passed: 1:15:49.924483\n","starting epoch 43. time passed: 1:17:37.058249\n","starting epoch 44. time passed: 1:19:23.216885\n","starting epoch 45. time passed: 1:21:09.515849\n","starting epoch 46. time passed: 1:22:57.913820\n","starting epoch 47. time passed: 1:24:45.321549\n","starting epoch 48. time passed: 1:26:36.647872\n","starting epoch 49. time passed: 1:28:30.065775\n","starting epoch 50. time passed: 1:30:21.271546\n","starting epoch 51. time passed: 1:32:10.299326\n","starting epoch 52. time passed: 1:33:58.843541\n","starting epoch 53. time passed: 1:35:47.427282\n","starting epoch 54. time passed: 1:37:35.566663\n","starting epoch 55. time passed: 1:39:22.602401\n","starting epoch 56. time passed: 1:41:11.052055\n","starting epoch 57. time passed: 1:43:01.150066\n","starting epoch 58. time passed: 1:44:53.589831\n","starting epoch 59. time passed: 1:46:46.996140\n","starting epoch 60. time passed: 1:48:41.018992\n","starting epoch 61. time passed: 1:50:34.650477\n","starting epoch 62. time passed: 1:52:27.640038\n","starting epoch 63. time passed: 1:54:21.164658\n","starting epoch 64. time passed: 1:56:15.403965\n","starting epoch 65. time passed: 1:58:09.275032\n","starting epoch 66. time passed: 2:00:03.972524\n","starting epoch 67. time passed: 2:01:58.428554\n","starting epoch 68. time passed: 2:03:52.848668\n","starting epoch 69. time passed: 2:05:47.096021\n","starting epoch 70. time passed: 2:07:41.629206\n","starting epoch 71. time passed: 2:09:36.482367\n","starting epoch 72. time passed: 2:11:31.703152\n","starting epoch 73. time passed: 2:13:26.210278\n","starting epoch 74. time passed: 2:15:21.074424\n","starting epoch 75. time passed: 2:17:16.016954\n","starting epoch 76. time passed: 2:19:10.685924\n","starting epoch 77. time passed: 2:21:05.306186\n","starting epoch 78. time passed: 2:23:01.328580\n","starting epoch 79. time passed: 2:24:56.664027\n","starting epoch 80. time passed: 2:26:51.850318\n","starting epoch 81. time passed: 2:28:46.369977\n","starting epoch 82. time passed: 2:30:41.255088\n","starting epoch 83. time passed: 2:32:36.386257\n","starting epoch 84. time passed: 2:34:31.014431\n","starting epoch 85. time passed: 2:36:25.642649\n","starting epoch 86. time passed: 2:38:19.793694\n","starting epoch 87. time passed: 2:40:14.473617\n","starting epoch 88. time passed: 2:42:08.879085\n","starting epoch 89. time passed: 2:44:03.622753\n","starting epoch 90. time passed: 2:45:58.052629\n","starting epoch 91. time passed: 2:47:52.944848\n","starting epoch 92. time passed: 2:49:47.533219\n","starting epoch 93. time passed: 2:51:42.339961\n","starting epoch 94. time passed: 2:53:37.437456\n","starting epoch 95. time passed: 2:55:32.305176\n","starting epoch 96. time passed: 2:57:27.157805\n","starting epoch 97. time passed: 2:59:22.126563\n","starting epoch 98. time passed: 3:01:17.063082\n","starting epoch 99. time passed: 3:03:12.301378\n","starting epoch 100. time passed: 3:05:07.343702\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BeEcycP00rv3","colab_type":"text"},"source":["add noise"]},{"cell_type":"code","metadata":{"id":"x1B1w6H30sn3","colab_type":"code","outputId":"385ae854-f72b-4542-b58c-ac3749e0bce1","executionInfo":{"status":"ok","timestamp":1580430912502,"user_tz":300,"elapsed":13209,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.9,1.1,256*256)\n","            noise_array.resize((256,256))\n","            \n","            for sliceindex in range(vol.shape[0]):\n","              vol[sliceindex] = np.multiply(vol[sliceindex], noise_array)\n","              vol[sliceindex] = np.clip(vol[sliceindex], 0, 255)\n","            vol = vol.astype(np.float32)\n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VGMyCnrJ1COs","colab_type":"code","outputId":"41301b0a-6956-4a0e-f06f-810f9631de42","executionInfo":{"status":"ok","timestamp":1580413304627,"user_tz":300,"elapsed":8813620,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n","starting epoch 1. time passed: 0:00:00.000011\n","starting epoch 2. time passed: 0:03:43.019072\n","starting epoch 3. time passed: 0:05:35.751808\n","starting epoch 4. time passed: 0:07:24.228748\n","starting epoch 5. time passed: 0:09:12.053457\n","starting epoch 6. time passed: 0:10:59.405438\n","starting epoch 7. time passed: 0:12:46.372116\n","starting epoch 8. time passed: 0:14:31.909330\n","starting epoch 9. time passed: 0:16:16.896548\n","starting epoch 10. time passed: 0:18:01.948734\n","starting epoch 11. time passed: 0:19:46.718606\n","starting epoch 12. time passed: 0:21:30.705863\n","starting epoch 13. time passed: 0:23:14.539396\n","starting epoch 14. time passed: 0:24:58.616248\n","starting epoch 15. time passed: 0:26:42.225695\n","starting epoch 16. time passed: 0:28:25.552601\n","starting epoch 17. time passed: 0:30:09.455586\n","starting epoch 18. time passed: 0:31:53.782502\n","starting epoch 19. time passed: 0:33:36.762829\n","starting epoch 20. time passed: 0:35:19.220319\n","starting epoch 21. time passed: 0:37:01.206401\n","starting epoch 22. time passed: 0:38:43.450878\n","starting epoch 23. time passed: 0:40:28.358576\n","starting epoch 24. time passed: 0:42:11.222261\n","starting epoch 25. time passed: 0:43:55.001246\n","starting epoch 26. time passed: 0:45:38.646276\n","starting epoch 27. time passed: 0:47:23.145889\n","starting epoch 28. time passed: 0:49:07.191380\n","starting epoch 29. time passed: 0:50:50.978127\n","starting epoch 30. time passed: 0:52:34.933120\n","starting epoch 31. time passed: 0:54:18.333845\n","starting epoch 32. time passed: 0:56:01.966939\n","starting epoch 33. time passed: 0:57:45.284762\n","starting epoch 34. time passed: 0:59:27.953547\n","starting epoch 35. time passed: 1:01:10.489462\n","starting epoch 36. time passed: 1:02:53.598401\n","starting epoch 37. time passed: 1:04:35.767600\n","starting epoch 38. time passed: 1:06:20.286221\n","starting epoch 39. time passed: 1:08:05.676773\n","starting epoch 40. time passed: 1:09:54.905819\n","starting epoch 41. time passed: 1:11:45.646499\n","starting epoch 42. time passed: 1:13:35.492743\n","starting epoch 43. time passed: 1:15:23.462574\n","starting epoch 44. time passed: 1:17:12.040444\n","starting epoch 45. time passed: 1:19:01.474290\n","starting epoch 46. time passed: 1:20:50.542169\n","starting epoch 47. time passed: 1:22:40.012547\n","starting epoch 48. time passed: 1:24:29.601836\n","starting epoch 49. time passed: 1:26:19.330779\n","starting epoch 50. time passed: 1:28:08.858261\n","starting epoch 51. time passed: 1:29:58.275667\n","starting epoch 52. time passed: 1:31:47.578993\n","starting epoch 53. time passed: 1:33:36.833011\n","starting epoch 54. time passed: 1:35:25.936883\n","starting epoch 55. time passed: 1:37:13.936574\n","starting epoch 56. time passed: 1:39:01.119983\n","starting epoch 57. time passed: 1:40:48.046828\n","starting epoch 58. time passed: 1:42:35.565481\n","starting epoch 59. time passed: 1:44:23.223062\n","starting epoch 60. time passed: 1:46:10.468128\n","starting epoch 61. time passed: 1:47:58.303691\n","starting epoch 62. time passed: 1:49:45.939512\n","starting epoch 63. time passed: 1:51:35.984048\n","starting epoch 64. time passed: 1:53:25.441489\n","starting epoch 65. time passed: 1:55:13.625340\n","starting epoch 66. time passed: 1:57:01.623554\n","starting epoch 67. time passed: 1:58:50.179532\n","starting epoch 68. time passed: 2:00:38.233845\n","starting epoch 69. time passed: 2:02:25.847188\n","starting epoch 70. time passed: 2:04:13.466756\n","starting epoch 71. time passed: 2:06:01.452889\n","starting epoch 72. time passed: 2:07:49.861409\n","starting epoch 73. time passed: 2:09:38.481097\n","starting epoch 74. time passed: 2:11:27.506476\n","starting epoch 75. time passed: 2:13:16.264747\n","starting epoch 76. time passed: 2:15:05.207895\n","starting epoch 77. time passed: 2:16:53.763471\n","starting epoch 78. time passed: 2:18:42.894713\n","starting epoch 79. time passed: 2:20:32.049039\n","starting epoch 80. time passed: 2:22:20.231222\n","starting epoch 81. time passed: 2:24:08.876974\n","starting epoch 82. time passed: 2:25:57.278274\n","starting epoch 83. time passed: 2:27:46.794840\n","starting epoch 84. time passed: 2:29:36.284266\n","starting epoch 85. time passed: 2:31:25.838297\n","starting epoch 86. time passed: 2:33:14.858975\n","starting epoch 87. time passed: 2:35:03.224684\n","starting epoch 88. time passed: 2:36:52.170137\n","starting epoch 89. time passed: 2:38:41.353001\n","starting epoch 90. time passed: 2:40:30.407952\n","starting epoch 91. time passed: 2:42:19.227950\n","starting epoch 92. time passed: 2:44:08.234825\n","starting epoch 93. time passed: 2:45:57.221625\n","starting epoch 94. time passed: 2:47:46.967981\n","starting epoch 95. time passed: 2:49:36.662864\n","starting epoch 96. time passed: 2:51:26.104631\n","starting epoch 97. time passed: 2:53:15.932881\n","starting epoch 98. time passed: 2:55:05.492282\n","starting epoch 99. time passed: 2:56:55.363628\n","starting epoch 100. time passed: 2:58:45.092015\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BSAZAgdY1HRu","colab_type":"code","outputId":"64f9ca7b-02bb-4f12-da8b-f492b3ab1414","executionInfo":{"status":"ok","timestamp":1580424062246,"user_tz":300,"elapsed":10626381,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#cor w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n","starting epoch 1. time passed: 0:00:00.000010\n","starting epoch 2. time passed: 0:03:16.848648\n","starting epoch 3. time passed: 0:05:08.142213\n","starting epoch 4. time passed: 0:06:54.405748\n","starting epoch 5. time passed: 0:08:41.101316\n","starting epoch 6. time passed: 0:10:27.338116\n","starting epoch 7. time passed: 0:12:13.350510\n","starting epoch 8. time passed: 0:13:59.154821\n","starting epoch 9. time passed: 0:15:45.115916\n","starting epoch 10. time passed: 0:17:32.366221\n","starting epoch 11. time passed: 0:19:18.365368\n","starting epoch 12. time passed: 0:21:04.607869\n","starting epoch 13. time passed: 0:22:51.222123\n","starting epoch 14. time passed: 0:24:37.429429\n","starting epoch 15. time passed: 0:26:23.257290\n","starting epoch 16. time passed: 0:28:08.246352\n","starting epoch 17. time passed: 0:29:52.908630\n","starting epoch 18. time passed: 0:31:38.541997\n","starting epoch 19. time passed: 0:33:23.207100\n","starting epoch 20. time passed: 0:35:07.664964\n","starting epoch 21. time passed: 0:36:54.388755\n","starting epoch 22. time passed: 0:38:40.450703\n","starting epoch 23. time passed: 0:40:27.134371\n","starting epoch 24. time passed: 0:42:12.724818\n","starting epoch 25. time passed: 0:43:57.873627\n","starting epoch 26. time passed: 0:45:44.044255\n","starting epoch 27. time passed: 0:47:28.874049\n","starting epoch 28. time passed: 0:49:13.247756\n","starting epoch 29. time passed: 0:50:58.387258\n","starting epoch 30. time passed: 0:52:43.240716\n","starting epoch 31. time passed: 0:54:30.060346\n","starting epoch 32. time passed: 0:56:15.889300\n","starting epoch 33. time passed: 0:58:01.304305\n","starting epoch 34. time passed: 0:59:46.401207\n","starting epoch 35. time passed: 1:01:32.109062\n","starting epoch 36. time passed: 1:03:16.560637\n","starting epoch 37. time passed: 1:05:00.737263\n","starting epoch 38. time passed: 1:06:44.732435\n","starting epoch 39. time passed: 1:08:28.479495\n","starting epoch 40. time passed: 1:10:12.276489\n","starting epoch 41. time passed: 1:12:01.903256\n","starting epoch 42. time passed: 1:13:48.661181\n","starting epoch 43. time passed: 1:15:32.772589\n","starting epoch 44. time passed: 1:17:16.773369\n","starting epoch 45. time passed: 1:18:59.680742\n","starting epoch 46. time passed: 1:20:42.797574\n","starting epoch 47. time passed: 1:22:28.167794\n","starting epoch 48. time passed: 1:24:13.177548\n","starting epoch 49. time passed: 1:25:57.984195\n","starting epoch 50. time passed: 1:27:41.654521\n","starting epoch 51. time passed: 1:29:25.465173\n","starting epoch 52. time passed: 1:31:10.538456\n","starting epoch 53. time passed: 1:32:54.590183\n","starting epoch 54. time passed: 1:34:37.851833\n","starting epoch 55. time passed: 1:36:21.621821\n","starting epoch 56. time passed: 1:38:06.401333\n","starting epoch 57. time passed: 1:39:51.070737\n","starting epoch 58. time passed: 1:41:35.580858\n","starting epoch 59. time passed: 1:43:19.730541\n","starting epoch 60. time passed: 1:45:04.215750\n","starting epoch 61. time passed: 1:46:49.862306\n","starting epoch 62. time passed: 1:48:34.391511\n","starting epoch 63. time passed: 1:50:18.546893\n","starting epoch 64. time passed: 1:52:01.782778\n","starting epoch 65. time passed: 1:53:45.796896\n","starting epoch 66. time passed: 1:55:29.580933\n","starting epoch 67. time passed: 1:57:13.754262\n","starting epoch 68. time passed: 1:58:59.156821\n","starting epoch 69. time passed: 2:00:43.428320\n","starting epoch 70. time passed: 2:02:28.019943\n","starting epoch 71. time passed: 2:04:13.031784\n","starting epoch 72. time passed: 2:05:57.216896\n","starting epoch 73. time passed: 2:07:43.194356\n","starting epoch 74. time passed: 2:09:29.717785\n","starting epoch 75. time passed: 2:11:17.317100\n","starting epoch 76. time passed: 2:13:04.685178\n","starting epoch 77. time passed: 2:14:51.291747\n","starting epoch 78. time passed: 2:16:37.709694\n","starting epoch 79. time passed: 2:18:23.732458\n","starting epoch 80. time passed: 2:20:09.314252\n","starting epoch 81. time passed: 2:21:54.367668\n","starting epoch 82. time passed: 2:23:39.594623\n","starting epoch 83. time passed: 2:25:24.326050\n","starting epoch 84. time passed: 2:27:08.611647\n","starting epoch 85. time passed: 2:28:53.392583\n","starting epoch 86. time passed: 2:30:38.943712\n","starting epoch 87. time passed: 2:32:23.848461\n","starting epoch 88. time passed: 2:34:08.471638\n","starting epoch 89. time passed: 2:35:52.817660\n","starting epoch 90. time passed: 2:37:37.250838\n","starting epoch 91. time passed: 2:39:21.704165\n","starting epoch 92. time passed: 2:41:05.526130\n","starting epoch 93. time passed: 2:42:51.006363\n","starting epoch 94. time passed: 2:44:36.279093\n","starting epoch 95. time passed: 2:46:20.407905\n","starting epoch 96. time passed: 2:48:05.458596\n","starting epoch 97. time passed: 2:49:50.810785\n","starting epoch 98. time passed: 2:51:36.858933\n","starting epoch 99. time passed: 2:53:22.081305\n","starting epoch 100. time passed: 2:55:06.715999\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gYoIA4hd1HVM","colab_type":"code","outputId":"e1e06e07-6da0-492a-e7cb-af4870bc981b","executionInfo":{"status":"ok","timestamp":1580442817207,"user_tz":300,"elapsed":11904578,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#ax w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:04<00:00, 55.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000011\n","starting epoch 2. time passed: 0:04:23.686557\n","starting epoch 3. time passed: 0:06:20.648991\n","starting epoch 4. time passed: 0:08:19.572472\n","starting epoch 5. time passed: 0:10:19.606409\n","starting epoch 6. time passed: 0:12:17.734918\n","starting epoch 7. time passed: 0:14:16.865256\n","starting epoch 8. time passed: 0:16:13.764976\n","starting epoch 9. time passed: 0:18:11.788088\n","starting epoch 10. time passed: 0:20:08.798667\n","starting epoch 11. time passed: 0:22:04.526502\n","starting epoch 12. time passed: 0:24:00.760807\n","starting epoch 13. time passed: 0:25:55.749261\n","starting epoch 14. time passed: 0:27:50.942239\n","starting epoch 15. time passed: 0:29:46.288503\n","starting epoch 16. time passed: 0:31:45.190381\n","starting epoch 17. time passed: 0:33:41.927670\n","starting epoch 18. time passed: 0:35:37.817819\n","starting epoch 19. time passed: 0:37:35.654117\n","starting epoch 20. time passed: 0:39:38.207628\n","starting epoch 21. time passed: 0:41:41.135471\n","starting epoch 22. time passed: 0:43:46.375348\n","starting epoch 23. time passed: 0:45:51.340252\n","starting epoch 24. time passed: 0:47:52.564739\n","starting epoch 25. time passed: 0:49:51.910030\n","starting epoch 26. time passed: 0:51:50.651412\n","starting epoch 27. time passed: 0:53:50.754460\n","starting epoch 28. time passed: 0:55:48.957044\n","starting epoch 29. time passed: 0:57:49.204346\n","starting epoch 30. time passed: 0:59:47.428251\n","starting epoch 31. time passed: 1:01:44.991794\n","starting epoch 32. time passed: 1:03:42.451216\n","starting epoch 33. time passed: 1:05:39.395569\n","starting epoch 34. time passed: 1:07:37.993615\n","starting epoch 35. time passed: 1:09:35.642299\n","starting epoch 36. time passed: 1:11:32.486174\n","starting epoch 37. time passed: 1:13:28.618253\n","starting epoch 38. time passed: 1:15:23.889559\n","starting epoch 39. time passed: 1:17:17.191135\n","starting epoch 40. time passed: 1:19:11.723361\n","starting epoch 41. time passed: 1:21:12.057109\n","starting epoch 42. time passed: 1:23:09.697221\n","starting epoch 43. time passed: 1:25:03.359149\n","starting epoch 44. time passed: 1:26:57.040075\n","starting epoch 45. time passed: 1:28:49.858772\n","starting epoch 46. time passed: 1:30:41.905241\n","starting epoch 47. time passed: 1:32:33.844257\n","starting epoch 48. time passed: 1:34:26.146047\n","starting epoch 49. time passed: 1:36:17.436260\n","starting epoch 50. time passed: 1:38:08.421212\n","starting epoch 51. time passed: 1:40:04.364285\n","starting epoch 52. time passed: 1:42:01.520898\n","starting epoch 53. time passed: 1:44:00.200963\n","starting epoch 54. time passed: 1:46:02.701233\n","starting epoch 55. time passed: 1:48:05.100633\n","starting epoch 56. time passed: 1:50:08.378328\n","starting epoch 57. time passed: 1:52:13.384948\n","starting epoch 58. time passed: 1:54:17.258007\n","starting epoch 59. time passed: 1:56:20.461867\n","starting epoch 60. time passed: 1:58:25.688342\n","starting epoch 61. time passed: 2:00:29.462476\n","starting epoch 62. time passed: 2:02:30.453026\n","starting epoch 63. time passed: 2:04:32.482939\n","starting epoch 64. time passed: 2:06:35.402634\n","starting epoch 65. time passed: 2:08:39.609330\n","starting epoch 66. time passed: 2:10:40.279604\n","starting epoch 67. time passed: 2:12:36.369427\n","starting epoch 68. time passed: 2:14:31.852819\n","starting epoch 69. time passed: 2:16:27.309410\n","starting epoch 70. time passed: 2:18:25.799154\n","starting epoch 71. time passed: 2:20:23.780709\n","starting epoch 72. time passed: 2:22:23.075020\n","starting epoch 73. time passed: 2:24:22.309251\n","starting epoch 74. time passed: 2:26:18.591097\n","starting epoch 75. time passed: 2:28:13.564790\n","starting epoch 76. time passed: 2:30:10.739257\n","starting epoch 77. time passed: 2:32:05.150233\n","starting epoch 78. time passed: 2:33:58.820746\n","starting epoch 79. time passed: 2:35:57.043074\n","starting epoch 80. time passed: 2:37:50.951344\n","starting epoch 81. time passed: 2:39:45.631260\n","starting epoch 82. time passed: 2:41:42.814113\n","starting epoch 83. time passed: 2:43:38.484023\n","starting epoch 84. time passed: 2:45:33.963046\n","starting epoch 85. time passed: 2:47:29.144799\n","starting epoch 86. time passed: 2:49:25.353432\n","starting epoch 87. time passed: 2:51:19.435992\n","starting epoch 88. time passed: 2:53:12.508149\n","starting epoch 89. time passed: 2:55:05.487158\n","starting epoch 90. time passed: 2:57:01.443591\n","starting epoch 91. time passed: 2:58:54.990681\n","starting epoch 92. time passed: 3:00:48.496613\n","starting epoch 93. time passed: 3:02:42.762114\n","starting epoch 94. time passed: 3:04:35.736831\n","starting epoch 95. time passed: 3:06:27.806840\n","starting epoch 96. time passed: 3:08:22.192837\n","starting epoch 97. time passed: 3:10:15.731252\n","starting epoch 98. time passed: 3:12:09.987335\n","starting epoch 99. time passed: 3:14:03.379481\n","starting epoch 100. time passed: 3:15:56.138519\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"u-e3QWAp1W8o","colab_type":"text"},"source":["change model to VGG11_bn, remove noise"]},{"cell_type":"code","metadata":{"id":"tXk1HNzH1aSa","colab_type":"code","colab":{}},"source":["# model.py\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import models\n","\n","class MRNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = models.vgg11_bn(pretrained=True)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        #self.classifier = nn.Linear(1024, 1)\n","        self.classifier = nn.Linear(512, 1)\n","\n","    # change this to adapt to different networks\n","    def forward(self, x):\n","        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n","        x = self.model.features(x)\n","        # make sure that gap returns size 256\n","        x = self.gap(x).view(x.size(0), -1)\n","        x = torch.max(x, 0, keepdim=True)[0]\n","        x = self.classifier(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZ-zp-fb1j5I","colab_type":"code","outputId":"0e84231f-56ba-4b2d-a3fc-12ff1bcffe77","executionInfo":{"status":"ok","timestamp":1580614519407,"user_tz":300,"elapsed":17078,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \"\"\"\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.8,1.2,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \"\"\"\n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ne4zsU8d2E_M","colab_type":"code","outputId":"e550a8e7-efce-4915-ac7a-26a48d7774c9","executionInfo":{"status":"ok","timestamp":1580495381962,"user_tz":300,"elapsed":14201298,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["#sag w/o aug\n","aug = False\n","epochs = 40\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/checkpoints/vgg11_bn-6002323d.pth\n","100%|██████████| 507M/507M [00:07<00:00, 69.1MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000009\n","starting epoch 2. time passed: 0:06:05.122865\n","starting epoch 3. time passed: 0:11:58.960910\n","starting epoch 4. time passed: 0:17:51.947448\n","starting epoch 5. time passed: 0:23:45.195556\n","starting epoch 6. time passed: 0:29:38.411693\n","starting epoch 7. time passed: 0:35:32.123016\n","starting epoch 8. time passed: 0:41:26.102156\n","starting epoch 9. time passed: 0:47:20.467376\n","starting epoch 10. time passed: 0:53:14.460419\n","starting epoch 11. time passed: 0:59:08.575021\n","starting epoch 12. time passed: 1:05:02.332800\n","starting epoch 13. time passed: 1:10:55.850516\n","starting epoch 14. time passed: 1:16:49.821179\n","starting epoch 15. time passed: 1:22:43.360666\n","starting epoch 16. time passed: 1:28:37.454565\n","starting epoch 17. time passed: 1:34:30.973592\n","starting epoch 18. time passed: 1:40:24.646378\n","starting epoch 19. time passed: 1:46:18.575516\n","starting epoch 20. time passed: 1:52:12.679883\n","starting epoch 21. time passed: 1:58:06.404650\n","starting epoch 22. time passed: 2:04:00.009501\n","starting epoch 23. time passed: 2:09:53.933953\n","starting epoch 24. time passed: 2:15:47.856640\n","starting epoch 25. time passed: 2:21:41.415436\n","starting epoch 26. time passed: 2:27:35.020622\n","starting epoch 27. time passed: 2:33:29.067685\n","starting epoch 28. time passed: 2:39:22.824001\n","starting epoch 29. time passed: 2:45:16.591319\n","starting epoch 30. time passed: 2:51:09.968311\n","starting epoch 31. time passed: 2:57:03.646502\n","starting epoch 32. time passed: 3:02:56.788652\n","starting epoch 33. time passed: 3:08:50.376601\n","starting epoch 34. time passed: 3:14:43.718287\n","starting epoch 35. time passed: 3:20:37.578770\n","starting epoch 36. time passed: 3:26:31.269247\n","starting epoch 37. time passed: 3:32:24.717931\n","starting epoch 38. time passed: 3:38:18.256777\n","starting epoch 39. time passed: 3:44:11.652359\n","starting epoch 40. time passed: 3:50:05.065127\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PuOaiAD_2O8y","colab_type":"code","outputId":"8e85c627-672d-4f25-d2fd-42ca4b7c1917","executionInfo":{"status":"ok","timestamp":1580547718616,"user_tz":300,"elapsed":14249408,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBTLXbXtROP-MF9doZMIQXa0KZGZOsiIi06-ES-leN91AEJybTswJLc6KuuTjb1tdVkyfLynYwBcozT9_6k7xe5E488EwHtmzxzlk0sTFPihVbgeU7TqDImwxEy39RF0lhLo4tX4OojzhLlsPGNkXnit8IXKczDz94Y13VYOEKh693SSRmGf6vhQi2iZ4MrZeqnUeEZc8CHVNQJk04tE9zceZ178k5oBMS-gYZhQs0K7iYRm1XhOGTHTpihCtpDoQPQZqcqYJvKlgxkdHQowXLUHPNWJ1ztxKckbdqe_GLI9WivA2zJN0WrEqSKalmsd5lbNF4FQ7b8OwnxrTNVa3V3_DgGytO84ryZZOR80ZcQnxMxe42yWuNo6x5xblAPBpHFSo2Hu7JErhkoVv1kbiyQGr4PgvRh5XTalTS04hIdFYW_KxDvV4zt6DBWUa3N8dCzsEd0sK765HqhR1lbOXz_PbZ3FN0S1mXlQyQyJODqDGIO3ckZ8dAqVDko5Gj0eK1kisKQB3CcGXZR-h2X-1rHDPGUQUkgY41QzWFib1_PvUnAAiu3TM_oF-x2NVhGuMwl7yjinSE3GpQyjjFQLO4t8Yn1FSy7RngnZ8Z6Rm_GX4xoGh4cYUrn9HmBtT3FERAw7hZiy35XF2TYuiEjVpRdb-yheiiEuBeXdvLhFaqfUrNzQSmPr92NQ48l9EslN418wgHg2KXRqPOJloz-uIJKjl35GkzEE_0aRPK408OY8N7JLsY9kaLfz7goex0=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["#cor w/o aug\n","aug = False\n","epochs = 40\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data meniscus coronal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.355, 0.645]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.43333333333333335, 0.5666666666666667]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.3230769230769231, 0.676923076923077]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/checkpoints/vgg11_bn-6002323d.pth\n","100%|██████████| 507M/507M [00:05<00:00, 103MB/s] \n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000010\n","starting epoch 2. time passed: 0:05:58.337767\n","starting epoch 3. time passed: 0:11:54.324386\n","starting epoch 4. time passed: 0:17:50.545838\n","starting epoch 5. time passed: 0:23:46.761566\n","starting epoch 6. time passed: 0:29:43.193457\n","starting epoch 7. time passed: 0:35:39.567528\n","starting epoch 8. time passed: 0:41:36.176964\n","starting epoch 9. time passed: 0:47:32.496253\n","starting epoch 10. time passed: 0:53:28.399810\n","starting epoch 11. time passed: 0:59:24.394419\n","starting epoch 12. time passed: 1:05:20.370144\n","starting epoch 13. time passed: 1:11:16.510633\n","starting epoch 14. time passed: 1:17:11.990080\n","starting epoch 15. time passed: 1:23:07.294058\n","starting epoch 16. time passed: 1:29:03.157191\n","starting epoch 17. time passed: 1:34:58.474258\n","starting epoch 18. time passed: 1:40:53.807669\n","starting epoch 19. time passed: 1:46:49.442916\n","starting epoch 20. time passed: 1:52:45.081209\n","starting epoch 21. time passed: 1:58:40.594854\n","starting epoch 22. time passed: 2:04:36.383977\n","starting epoch 23. time passed: 2:10:31.812685\n","starting epoch 24. time passed: 2:16:27.216230\n","starting epoch 25. time passed: 2:22:22.603506\n","starting epoch 26. time passed: 2:28:18.014872\n","starting epoch 27. time passed: 2:34:13.289732\n","starting epoch 28. time passed: 2:40:08.646249\n","starting epoch 29. time passed: 2:46:04.075677\n","starting epoch 30. time passed: 2:51:59.529548\n","starting epoch 31. time passed: 2:57:54.524244\n","starting epoch 32. time passed: 3:03:50.084092\n","starting epoch 33. time passed: 3:09:45.794846\n","starting epoch 34. time passed: 3:15:41.155322\n","starting epoch 35. time passed: 3:21:36.262104\n","starting epoch 36. time passed: 3:27:31.378884\n","starting epoch 37. time passed: 3:33:26.524377\n","starting epoch 38. time passed: 3:39:21.493240\n","starting epoch 39. time passed: 3:45:16.199758\n","starting epoch 40. time passed: 3:51:11.600982\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CsNpNMLP2PAI","colab_type":"code","outputId":"21643e18-120b-4a8c-8433-da160587e9d5","colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["#axial w/o aug\n","aug = False\n","epochs = 40\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data abnormal axial\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.812, 0.18799999999999994]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.7916666666666666, 0.20833333333333337]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.7769230769230769, 0.22307692307692306]\n","starting epoch 1. time passed: 0:00:00.000018\n","starting epoch 2. time passed: 0:06:47.843023\n","starting epoch 3. time passed: 0:13:29.000707\n","starting epoch 4. time passed: 0:20:10.006576\n","starting epoch 5. time passed: 0:26:51.085904\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bl9fnKh62ceA","colab_type":"text"},"source":["add rotation"]},{"cell_type":"code","metadata":{"id":"7bisaRYI2e-r","colab_type":"code","outputId":"2ddffd82-0826-4686-b1ed-c8307b38c5d7","executionInfo":{"status":"ok","timestamp":1580509562664,"user_tz":300,"elapsed":14180677,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["#sag w/o aug\n","aug = True\n","epochs = 40\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n","starting epoch 1. time passed: 0:00:00.000011\n","starting epoch 2. time passed: 0:05:54.505761\n","starting epoch 3. time passed: 0:11:48.506779\n","starting epoch 4. time passed: 0:17:42.415792\n","starting epoch 5. time passed: 0:23:36.717618\n","starting epoch 6. time passed: 0:29:30.435966\n","starting epoch 7. time passed: 0:35:24.263167\n","starting epoch 8. time passed: 0:41:18.369445\n","starting epoch 9. time passed: 0:47:12.426248\n","starting epoch 10. time passed: 0:53:06.515235\n","starting epoch 11. time passed: 0:59:00.568680\n","starting epoch 12. time passed: 1:04:54.904797\n","starting epoch 13. time passed: 1:10:49.013598\n","starting epoch 14. time passed: 1:16:43.752379\n","starting epoch 15. time passed: 1:22:38.390139\n","starting epoch 16. time passed: 1:28:32.795739\n","starting epoch 17. time passed: 1:34:27.300583\n","starting epoch 18. time passed: 1:40:21.444153\n","starting epoch 19. time passed: 1:46:15.492182\n","starting epoch 20. time passed: 1:52:09.592940\n","starting epoch 21. time passed: 1:58:03.918388\n","starting epoch 22. time passed: 2:03:58.065273\n","starting epoch 23. time passed: 2:09:52.298756\n","starting epoch 24. time passed: 2:15:46.205759\n","starting epoch 25. time passed: 2:21:40.146433\n","starting epoch 26. time passed: 2:27:34.277619\n","starting epoch 27. time passed: 2:33:28.268615\n","starting epoch 28. time passed: 2:39:21.713177\n","starting epoch 29. time passed: 2:45:15.863364\n","starting epoch 30. time passed: 2:51:09.344602\n","starting epoch 31. time passed: 2:57:02.895517\n","starting epoch 32. time passed: 3:02:56.919537\n","starting epoch 33. time passed: 3:08:50.809287\n","starting epoch 34. time passed: 3:14:44.632159\n","starting epoch 35. time passed: 3:20:38.765805\n","starting epoch 36. time passed: 3:26:32.737473\n","starting epoch 37. time passed: 3:32:26.644535\n","starting epoch 38. time passed: 3:38:20.465068\n","starting epoch 39. time passed: 3:44:14.622970\n","starting epoch 40. time passed: 3:50:08.997992\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8H4jJHVS2fBp","colab_type":"code","colab":{}},"source":["#cor w/o aug\n","aug = True\n","epochs = 40\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQKgooF92fEt","colab_type":"code","colab":{}},"source":["#axial w/o aug\n","aug = True\n","epochs = 40\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KYTdpzsF2w92","colab_type":"text"},"source":["add noise "]},{"cell_type":"code","metadata":{"id":"htYZc5Lw2x8B","colab_type":"code","outputId":"61b3be93-582f-4512-af17-ba056557e3b1","executionInfo":{"status":"ok","timestamp":1580614522263,"user_tz":300,"elapsed":10768,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.85,1.15,256*256)\n","            noise_array.resize((256,256))\n","            \n","            for sliceindex in range(vol.shape[0]):\n","              vol[sliceindex] = np.multiply(vol[sliceindex], noise_array)\n","              vol[sliceindex] = np.clip(vol[sliceindex], 0, 255)\n","            vol = vol.astype(np.float32)\n","          \n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.4.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.3.1)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SQKJs_HS23eM","colab_type":"code","outputId":"4d420be2-44a8-4707-d8d3-a1daef0f65ff","executionInfo":{"status":"ok","timestamp":1580629330062,"user_tz":300,"elapsed":12998380,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["#sag w/ aug\n","aug = True\n","epochs = 40\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/checkpoints/vgg11_bn-6002323d.pth\n","100%|██████████| 507M/507M [00:09<00:00, 58.5MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000012\n","starting epoch 2. time passed: 0:06:10.724716\n","starting epoch 3. time passed: 0:12:20.212773\n","starting epoch 4. time passed: 0:18:29.660866\n","starting epoch 5. time passed: 0:24:39.441739\n","starting epoch 6. time passed: 0:30:48.669827\n","starting epoch 7. time passed: 0:36:57.559722\n","starting epoch 8. time passed: 0:43:06.900992\n","starting epoch 9. time passed: 0:49:16.021148\n","starting epoch 10. time passed: 0:55:24.256466\n","starting epoch 11. time passed: 1:01:33.399504\n","starting epoch 12. time passed: 1:07:42.617247\n","starting epoch 13. time passed: 1:13:51.833329\n","starting epoch 14. time passed: 1:20:00.910765\n","starting epoch 15. time passed: 1:26:10.278674\n","starting epoch 16. time passed: 1:32:19.094358\n","starting epoch 17. time passed: 1:38:27.430727\n","starting epoch 18. time passed: 1:44:36.827998\n","starting epoch 19. time passed: 1:50:46.323804\n","starting epoch 20. time passed: 1:56:55.570093\n","starting epoch 21. time passed: 2:03:04.748714\n","starting epoch 22. time passed: 2:09:14.551834\n","starting epoch 23. time passed: 2:15:23.689077\n","starting epoch 24. time passed: 2:21:33.131056\n","starting epoch 25. time passed: 2:27:42.196165\n","starting epoch 26. time passed: 2:33:50.757200\n","starting epoch 27. time passed: 2:39:59.612319\n","starting epoch 28. time passed: 2:46:08.899613\n","starting epoch 29. time passed: 2:52:18.273917\n","starting epoch 30. time passed: 2:58:27.944871\n","starting epoch 31. time passed: 3:04:37.166200\n","starting epoch 32. time passed: 3:10:46.317281\n","starting epoch 33. time passed: 3:16:55.800960\n","starting epoch 34. time passed: 3:23:05.021288\n","starting epoch 35. time passed: 3:29:14.012580\n","starting epoch 36. time passed: 3:35:23.567539\n","starting epoch 37. time passed: 3:41:32.446096\n","starting epoch 38. time passed: 3:47:41.167163\n","starting epoch 39. time passed: 3:53:50.516796\n","starting epoch 40. time passed: 3:59:59.745579\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1Vf5PkD42-7b","colab_type":"code","colab":{}},"source":["#cor w/ aug\n","aug = True\n","epochs = 40\n","diagnosis = 'meniscus'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"udqf8Lwb2--0","colab_type":"code","colab":{}},"source":["#ax w/ aug\n","aug = True\n","epochs = 40\n","diagnosis = 'abnormal'\n","orientation = 'axial'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'vgg11_bn RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0oL7WBd0-DR","colab_type":"text"},"source":["changed optimizer to sgd + momentum, back to alexnet"]},{"cell_type":"code","metadata":{"id":"VDuVPxr11Ejd","colab_type":"code","colab":{}},"source":["# model.py\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import models\n","\n","class MRNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = models.alexnet(pretrained=True)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.classifier = nn.Linear(256, 1)\n","\n","    # change this to adapt to different networks\n","    def forward(self, x):\n","        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n","        x = self.model.features(x)\n","        # make sure that gap returns size 256\n","        x = self.gap(x).view(x.size(0), -1)\n","        x = torch.max(x, 0, keepdim=True)[0]\n","        x = self.classifier(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJb7Rog-1MeQ","colab_type":"code","outputId":"c3d883fc-021e-41d4-dc22-5a5b328cb976","executionInfo":{"status":"ok","timestamp":1581370379086,"user_tz":300,"elapsed":2403,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA_aEkGH4gpijfLHJcvB6IMuR_A1RwjPjfM-RiV-7PKjuRm2QMgkbAqK1EkrM3xvOODqAwgs8TERPtCejFQ-4mlD5x-ryUFbixf1YM1UOUXPY55BIBMklTvPGyj9kjXypGW2qVNLZEkd-un0_Wpb96FVy65pGsE3_-mSW9rZKm2NvMMM0umF4ap9o7uF1LNvDx9Rsyni5xnN4upPYbhM-hamY7QsHp4dUh_TSeXrHcmEvNyvj-Q708wlU3Z5G5bhNSqjxDboodEuoFG3XMGHY2_do_7CEXUHYhpVVenQccwl7COqTe9eP2UXDEg3VIfZuQKNKcjaNjlHZHInP5uL6BshkTU7WIVND0iqlqGw5J8Xkc3q5xndFKUO_iwSk_p5TFAmIvBGf2Z7GGPgBagWl2xqGM5hQUiOhTwxZVC8O65ii5ZO1sYz49cXHQd6RdILKsw8ladTJcjoAxzgZwYcSAkHZGpB43NxgzMRLkcCfdf7KnOJvoIYPhXZIzfQsYyZlIWvoVD8iWmoAa0lDXtek6l2QQ91sjcIkLg1-TiX--dZJSIP50J5_bm2d201cwj2k-pWCFhaxrGce7NmbdqNaYypb4l3yhrAZDM2POa6fMqpcDTALXT9GlTA0VkkahFgG2lndKjk-I0XugQXaKJqZJWuWYkDRzMfwX29j53paoOxCDnyg2zW6dPhdimhPkVHsbsk5Za5fPTBuib778KY2ApEZh_1XaRjznivY1E9JhXrZD2a94fAiLNlzxbfuQ=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \"\"\"\n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.8,1.2,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \"\"\"\n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.0)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.5.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CFdFIQabEmLD","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import numpy as np\n","import os\n","import torch\n","\n","from datetime import datetime\n","from pathlib import Path\n","from sklearn import metrics\n","\n","def train(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu):\n","    \n","    val_auc_array = list()\n","    train_auc_array = list()\n","    test_auc_array = list()\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    \n","    model = MRNet()\n","    \n","    if use_gpu:\n","        model = model.cuda()\n","\n","    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=.3, threshold=1e-4)\n","\n","    best_val_loss = float('inf')\n","\n","    start_time = datetime.now()\n","\n","    for epoch in range(epochs):\n","        change = datetime.now() - start_time\n","        print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n","        \n","        train_loss, train_auc, _, _ = run_model(model, train_loader, train=True, optimizer=optimizer)\n","        val_loss, val_auc, _, _ = run_model(model, valid_loader)\n","        test_loss, test_auc, _, _ = run_model(model, test_loader)\n","\n","        val_auc_array.append(val_auc)\n","        train_auc_array.append(train_auc)\n","        test_auc_array.append(test_auc)\n","        \n","        scheduler.step(val_loss)\n","            \n","    return val_auc_array, train_auc_array, test_auc_array\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y20Hco7h1aYa","colab_type":"code","outputId":"91325ca9-9367-4a6e-900b-e7abbcb7f907","executionInfo":{"status":"ok","timestamp":1580635610463,"user_tz":300,"elapsed":4454687,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/o aug\n","aug = False\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet sgd ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n","100%|██████████| 233M/233M [00:02<00:00, 85.5MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000015\n","starting epoch 2. time passed: 0:01:02.290805\n","starting epoch 3. time passed: 0:02:04.824263\n","starting epoch 4. time passed: 0:03:07.276236\n","starting epoch 5. time passed: 0:04:09.926885\n","starting epoch 6. time passed: 0:05:12.263895\n","starting epoch 7. time passed: 0:06:14.805055\n","starting epoch 8. time passed: 0:07:16.982160\n","starting epoch 9. time passed: 0:08:19.358303\n","starting epoch 10. time passed: 0:09:22.552203\n","starting epoch 11. time passed: 0:10:25.748993\n","starting epoch 12. time passed: 0:11:29.091396\n","starting epoch 13. time passed: 0:12:31.933913\n","starting epoch 14. time passed: 0:13:34.986460\n","starting epoch 15. time passed: 0:14:37.908916\n","starting epoch 16. time passed: 0:15:40.932016\n","starting epoch 17. time passed: 0:16:43.638046\n","starting epoch 18. time passed: 0:17:46.485129\n","starting epoch 19. time passed: 0:18:49.220347\n","starting epoch 20. time passed: 0:19:51.664867\n","starting epoch 21. time passed: 0:20:53.992440\n","starting epoch 22. time passed: 0:21:56.491676\n","starting epoch 23. time passed: 0:22:58.759411\n","starting epoch 24. time passed: 0:24:01.156020\n","starting epoch 25. time passed: 0:25:03.536270\n","starting epoch 26. time passed: 0:26:05.838116\n","starting epoch 27. time passed: 0:27:07.811117\n","starting epoch 28. time passed: 0:28:09.766294\n","starting epoch 29. time passed: 0:29:11.742054\n","starting epoch 30. time passed: 0:30:13.945912\n","starting epoch 31. time passed: 0:31:16.406841\n","starting epoch 32. time passed: 0:32:18.988889\n","starting epoch 33. time passed: 0:33:21.542216\n","starting epoch 34. time passed: 0:34:24.339567\n","starting epoch 35. time passed: 0:35:27.483632\n","starting epoch 36. time passed: 0:36:30.357017\n","starting epoch 37. time passed: 0:37:33.133915\n","starting epoch 38. time passed: 0:38:36.046114\n","starting epoch 39. time passed: 0:39:38.951642\n","starting epoch 40. time passed: 0:40:41.819376\n","starting epoch 41. time passed: 0:41:44.460054\n","starting epoch 42. time passed: 0:42:46.810715\n","starting epoch 43. time passed: 0:43:49.182376\n","starting epoch 44. time passed: 0:44:51.429987\n","starting epoch 45. time passed: 0:45:53.991079\n","starting epoch 46. time passed: 0:46:56.067640\n","starting epoch 47. time passed: 0:47:58.069634\n","starting epoch 48. time passed: 0:49:00.401270\n","starting epoch 49. time passed: 0:50:02.315025\n","starting epoch 50. time passed: 0:51:04.462237\n","starting epoch 51. time passed: 0:52:06.088215\n","starting epoch 52. time passed: 0:53:07.836890\n","starting epoch 53. time passed: 0:54:09.593223\n","starting epoch 54. time passed: 0:55:11.313324\n","starting epoch 55. time passed: 0:56:12.991491\n","starting epoch 56. time passed: 0:57:14.544782\n","starting epoch 57. time passed: 0:58:16.226983\n","starting epoch 58. time passed: 0:59:18.104748\n","starting epoch 59. time passed: 1:00:20.755343\n","starting epoch 60. time passed: 1:01:23.457388\n","starting epoch 61. time passed: 1:02:25.770663\n","starting epoch 62. time passed: 1:03:28.394302\n","starting epoch 63. time passed: 1:04:31.003126\n","starting epoch 64. time passed: 1:05:33.486629\n","starting epoch 65. time passed: 1:06:36.418057\n","starting epoch 66. time passed: 1:07:39.001929\n","starting epoch 67. time passed: 1:08:42.164816\n","starting epoch 68. time passed: 1:09:45.183572\n","starting epoch 69. time passed: 1:10:48.185898\n","starting epoch 70. time passed: 1:11:51.250721\n","starting epoch 71. time passed: 1:12:54.489545\n","starting epoch 72. time passed: 1:13:57.728566\n","starting epoch 73. time passed: 1:15:00.901393\n","starting epoch 74. time passed: 1:16:04.041412\n","starting epoch 75. time passed: 1:17:07.209124\n","starting epoch 76. time passed: 1:18:10.362400\n","starting epoch 77. time passed: 1:19:13.514710\n","starting epoch 78. time passed: 1:20:16.357070\n","starting epoch 79. time passed: 1:21:19.322131\n","starting epoch 80. time passed: 1:22:22.381025\n","starting epoch 81. time passed: 1:23:25.229497\n","starting epoch 82. time passed: 1:24:28.641379\n","starting epoch 83. time passed: 1:25:32.469341\n","starting epoch 84. time passed: 1:26:35.367986\n","starting epoch 85. time passed: 1:27:38.561126\n","starting epoch 86. time passed: 1:28:41.751311\n","starting epoch 87. time passed: 1:29:45.111994\n","starting epoch 88. time passed: 1:30:48.220699\n","starting epoch 89. time passed: 1:31:51.559620\n","starting epoch 90. time passed: 1:32:54.768542\n","starting epoch 91. time passed: 1:33:57.995909\n","starting epoch 92. time passed: 1:35:01.201661\n","starting epoch 93. time passed: 1:36:04.253492\n","starting epoch 94. time passed: 1:37:08.387010\n","starting epoch 95. time passed: 1:38:11.798792\n","starting epoch 96. time passed: 1:39:15.036260\n","starting epoch 97. time passed: 1:40:18.459667\n","starting epoch 98. time passed: 1:41:21.732358\n","starting epoch 99. time passed: 1:42:25.194209\n","starting epoch 100. time passed: 1:43:28.520573\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"b-lb-Pyw1ewx","colab_type":"code","outputId":"2098b145-5b29-40ca-b4a4-9264406ba743","executionInfo":{"status":"ok","timestamp":1580645591809,"user_tz":300,"elapsed":9981361,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet sgd ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug), 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n","starting epoch 1. time passed: 0:00:00.000012\n","starting epoch 2. time passed: 0:01:42.967463\n","starting epoch 3. time passed: 0:03:26.406034\n","starting epoch 4. time passed: 0:05:09.363268\n","starting epoch 5. time passed: 0:06:53.162308\n","starting epoch 6. time passed: 0:08:36.873752\n","starting epoch 7. time passed: 0:10:20.419893\n","starting epoch 8. time passed: 0:12:03.888124\n","starting epoch 9. time passed: 0:13:47.656506\n","starting epoch 10. time passed: 0:15:30.783305\n","starting epoch 11. time passed: 0:17:13.430584\n","starting epoch 12. time passed: 0:18:56.503997\n","starting epoch 13. time passed: 0:20:39.646757\n","starting epoch 14. time passed: 0:22:22.859199\n","starting epoch 15. time passed: 0:24:06.145509\n","starting epoch 16. time passed: 0:25:49.492780\n","starting epoch 17. time passed: 0:27:32.302819\n","starting epoch 18. time passed: 0:29:15.817511\n","starting epoch 19. time passed: 0:30:59.042628\n","starting epoch 20. time passed: 0:32:42.618998\n","starting epoch 21. time passed: 0:34:26.128918\n","starting epoch 22. time passed: 0:36:09.154896\n","starting epoch 23. time passed: 0:37:52.210847\n","starting epoch 24. time passed: 0:39:34.062199\n","starting epoch 25. time passed: 0:41:16.760661\n","starting epoch 26. time passed: 0:42:58.488712\n","starting epoch 27. time passed: 0:44:41.554522\n","starting epoch 28. time passed: 0:46:22.880751\n","starting epoch 29. time passed: 0:48:02.442197\n","starting epoch 30. time passed: 0:49:41.784539\n","starting epoch 31. time passed: 0:51:20.917608\n","starting epoch 32. time passed: 0:52:59.313023\n","starting epoch 33. time passed: 0:54:38.434702\n","starting epoch 34. time passed: 0:56:17.398165\n","starting epoch 35. time passed: 0:57:56.163234\n","starting epoch 36. time passed: 0:59:35.376860\n","starting epoch 37. time passed: 1:01:15.052615\n","starting epoch 38. time passed: 1:02:54.016285\n","starting epoch 39. time passed: 1:04:32.887743\n","starting epoch 40. time passed: 1:06:11.984185\n","starting epoch 41. time passed: 1:07:50.629330\n","starting epoch 42. time passed: 1:09:29.256341\n","starting epoch 43. time passed: 1:11:08.008728\n","starting epoch 44. time passed: 1:12:46.493738\n","starting epoch 45. time passed: 1:14:25.364719\n","starting epoch 46. time passed: 1:16:04.711112\n","starting epoch 47. time passed: 1:17:43.035387\n","starting epoch 48. time passed: 1:19:21.603773\n","starting epoch 49. time passed: 1:21:00.218153\n","starting epoch 50. time passed: 1:22:38.451127\n","starting epoch 51. time passed: 1:24:16.790051\n","starting epoch 52. time passed: 1:25:55.648471\n","starting epoch 53. time passed: 1:27:34.577190\n","starting epoch 54. time passed: 1:29:12.969120\n","starting epoch 55. time passed: 1:30:51.441988\n","starting epoch 56. time passed: 1:32:29.907355\n","starting epoch 57. time passed: 1:34:08.404788\n","starting epoch 58. time passed: 1:35:46.841813\n","starting epoch 59. time passed: 1:37:24.922112\n","starting epoch 60. time passed: 1:39:02.811049\n","starting epoch 61. time passed: 1:40:40.608542\n","starting epoch 62. time passed: 1:42:19.547693\n","starting epoch 63. time passed: 1:43:58.523149\n","starting epoch 64. time passed: 1:45:37.484131\n","starting epoch 65. time passed: 1:47:16.519456\n","starting epoch 66. time passed: 1:48:55.872207\n","starting epoch 67. time passed: 1:50:35.141227\n","starting epoch 68. time passed: 1:52:13.517181\n","starting epoch 69. time passed: 1:53:51.706175\n","starting epoch 70. time passed: 1:55:29.923840\n","starting epoch 71. time passed: 1:57:09.156542\n","starting epoch 72. time passed: 1:58:47.506044\n","starting epoch 73. time passed: 2:00:26.057056\n","starting epoch 74. time passed: 2:02:04.382003\n","starting epoch 75. time passed: 2:03:42.621622\n","starting epoch 76. time passed: 2:05:21.625677\n","starting epoch 77. time passed: 2:06:59.851486\n","starting epoch 78. time passed: 2:08:38.184428\n","starting epoch 79. time passed: 2:10:16.413670\n","starting epoch 80. time passed: 2:11:54.048740\n","starting epoch 81. time passed: 2:13:32.611231\n","starting epoch 82. time passed: 2:15:10.224313\n","starting epoch 83. time passed: 2:16:48.294489\n","starting epoch 84. time passed: 2:18:26.713329\n","starting epoch 85. time passed: 2:20:04.654201\n","starting epoch 86. time passed: 2:21:42.424471\n","starting epoch 87. time passed: 2:23:20.779101\n","starting epoch 88. time passed: 2:24:58.530757\n","starting epoch 89. time passed: 2:26:36.564645\n","starting epoch 90. time passed: 2:28:14.610769\n","starting epoch 91. time passed: 2:29:52.420512\n","starting epoch 92. time passed: 2:31:30.386349\n","starting epoch 93. time passed: 2:33:08.265092\n","starting epoch 94. time passed: 2:34:45.760090\n","starting epoch 95. time passed: 2:36:24.450040\n","starting epoch 96. time passed: 2:38:02.961624\n","starting epoch 97. time passed: 2:39:42.360198\n","starting epoch 98. time passed: 2:41:21.596254\n","starting epoch 99. time passed: 2:43:01.206282\n","starting epoch 100. time passed: 2:44:39.990080\n"],"name":"stdout"},{"output_type":"stream","text":["The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n","The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7gLEFn-s1lV_","colab_type":"code","outputId":"eb5e09f5-fa88-44f9-8a32-d780abc4d523","executionInfo":{"status":"ok","timestamp":1581370393122,"user_tz":300,"elapsed":2921,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA_aEkGH4gpijfLHJcvB6IMuR_A1RwjPjfM-RiV-7PKjuRm2QMgkbAqK1EkrM3xvOODqAwgs8TERPtCejFQ-4mlD5x-ryUFbixf1YM1UOUXPY55BIBMklTvPGyj9kjXypGW2qVNLZEkd-un0_Wpb96FVy65pGsE3_-mSW9rZKm2NvMMM0umF4ap9o7uF1LNvDx9Rsyni5xnN4upPYbhM-hamY7QsHp4dUh_TSeXrHcmEvNyvj-Q708wlU3Z5G5bhNSqjxDboodEuoFG3XMGHY2_do_7CEXUHYhpVVenQccwl7COqTe9eP2UXDEg3VIfZuQKNKcjaNjlHZHInP5uL6BshkTU7WIVND0iqlqGw5J8Xkc3q5xndFKUO_iwSk_p5TFAmIvBGf2Z7GGPgBagWl2xqGM5hQUiOhTwxZVC8O65ii5ZO1sYz49cXHQd6RdILKsw8ladTJcjoAxzgZwYcSAkHZGpB43NxgzMRLkcCfdf7KnOJvoIYPhXZIzfQsYyZlIWvoVD8iWmoAa0lDXtek6l2QQ91sjcIkLg1-TiX--dZJSIP50J5_bm2d201cwj2k-pWCFhaxrGce7NmbdqNaYypb4l3yhrAZDM2POa6fMqpcDTALXT9GlTA0VkkahFgG2lndKjk-I0XugQXaKJqZJWuWYkDRzMfwX29j53paoOxCDnyg2zW6dPhdimhPkVHsbsk5Za5fPTBuib778KY2ApEZh_1XaRjznivY1E9JhXrZD2a94fAiLNlzxbfuQ=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","MEAN = 58.09\n","STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        \"\"\"\n","        for i, line in enumerate(open('metadata.csv').readlines()):\n","            if i == 0:\n","                continue\n","            line = line.strip().split(',')\n","            path = line[10]\n","            label = line[2]\n","            label_dict[path] = int(int(label) > diagnosis)\n","        for dir in datadirs:\n","            for file in os.listdir(dir):\n","                self.paths.append(dir+'/'+file)\n","\n","        self.labels = [label_dict[path[6:]] for path in self.paths]\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","        \"\"\"\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        print(self.labels.shape)\n","        print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        #print('paths', self.paths)\n","        path = self.paths[index]\n","\n","        # with open(path, 'rb') as file_handler: # Must use 'rb' as the data is binary\n","        #    vol = pickle.load(file_handler).astype(np.int32)\n","        \n","        vol = np.load(path)\n","\n","        \"\"\"\n","        # crop middle\n","        pad = int((vol.shape[2] - INPUT_DIM)/2)\n","        #print('pad', pad)\n","        vol = vol[:,pad:-pad,pad:-pad]\n","        #vol = vol[pad:-pad,pad:-pad,:]\n","  \n","        # see if theres a way to reformat an image from 196 to 224 \n","        # something called interpolate, scikit image. \n","        # consider scipy zoom too?\n","\n","\n","        problemflag = False\n","\n","        if not(vol.shape[1] == 224) or not(vol.shape[2] == 224):\n","          #print('problem vol shape', vol.shape)\n","          delta_1 = (INPUT_DIM - vol.shape[1]) // 2\n","          delta_2 = (INPUT_DIM - vol.shape[2]) // 2\n","          padding = (delta_1, delta_2)\n","          new_vol = np.zeros((vol.shape[0], 224, 224), dtype=np.int32)\n","          for slice in range(vol.shape[0]):\n","            vol_slice = vol[slice,:,:]\n","            img_slice = PIL.Image.fromarray(vol_slice)\n","            new_vol[slice,:,:] = np.array(PIL.ImageOps.fit(img_slice, [224, 224]), dtype='i')\n","          vol = new_vol  \n","          vol.astype(np.int32)\n","          problemflag = True\n","          #print('vol shape', vol.shape)\n","          #print('vol type', vol.dtype)\n","\n","        \"\"\"\n","        #MEAN = np.mean(vol)\n","        #STDDEV = np.std(vol)\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-30, 30)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","\n","          \n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.9,1.1,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \n","\n","            #randomangle = np.random.uniform(-20,20)\n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            #torchvision.transforms.Resize((224,224)),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomRotation((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            #torchvision.transforms.RandomCrop((224,224),pad_if_needed=True),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 4\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=True)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: medicaltorch in /usr/local/lib/python3.6/dist-packages (0.2)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.0)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.28.1)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (2.3.3)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.5.0)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.17.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (1.12.0)\n","Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.2.1->medicaltorch) (0.98)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (6.2.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cWVvTxnu1qM0","colab_type":"code","outputId":"db252bdc-12e0-48b2-f93e-50e9d70ee056","executionInfo":{"status":"error","timestamp":1580755368892,"user_tz":300,"elapsed":54949,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#sag w/ aug\n","aug = True\n","epochs = 100\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet sgd ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7effeafbd908>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n","    w.join()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n","    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n","  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n","    pid, sts = os.waitpid(self.pid, flag)\n","KeyboardInterrupt: \n"],"name":"stderr"},{"output_type":"stream","text":["starting epoch 1. time passed: 0:00:00.000013\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-348f6b448b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sagittal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestarray1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrundir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnosis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alexnet sgd '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiagnosis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' lr = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' aug = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' + noise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AUC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-514dedb736c4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting epoch {}. time passed: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d5d6105dd2a7>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, loader, train, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-11-f48964149543>\", line 190, in __getitem__\n    vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 70, in __call__\n    img = t(img)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 1003, in __call__\n    return F.rotate(img, angle, self.resample, self.expand, self.center, self.fill)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 729, in rotate\n    return img.rotate(angle, resample, expand, center, fillcolor=fill)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2005, in rotate\n    return self.transform((w, h), AFFINE, matrix, resample, fillcolor=fillcolor)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2299, in transform\n    im = new(self.mode, size, fillcolor)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2505, in new\n    return im._new(core.fill(mode, size, color))\nTypeError: must be real number, not tuple\n"]}]},{"cell_type":"code","metadata":{"id":"9wKJf2Q5kWLm","colab_type":"code","outputId":"16598f5f-1caa-4fb7-88f8-7e79f09b7878","executionInfo":{"status":"error","timestamp":1580755404348,"user_tz":300,"elapsed":2217,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":902}},"source":["#sag w/ aug\n","aug = True\n","epochs = 250\n","diagnosis = 'ACL'\n","orientation = 'sagittal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet sgd ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + ' + noise', 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["load_data ACL sagittal\n","/content/gdrive/My Drive/thesis/Data/train\n","(1000,)\n","[0.188, 0.812]\n","/content/gdrive/My Drive/thesis/Data/valid\n","(120,)\n","[0.45, 0.55]\n","/content/gdrive/My Drive/thesis/Data/test\n","(130,)\n","[0.15384615384615385, 0.8461538461538461]\n","starting epoch 1. time passed: 0:00:00.000016\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0ef35db8410c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sagittal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestarray1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrundir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnosis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alexnet sgd '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiagnosis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' lr = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestarray1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' aug = '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' + noise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AUC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-514dedb736c4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting epoch {}. time passed: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d5d6105dd2a7>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, loader, train, optimizer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-16-f48964149543>\", line 190, in __getitem__\n    vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 70, in __call__\n    img = t(img)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 1003, in __call__\n    return F.rotate(img, angle, self.resample, self.expand, self.center, self.fill)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 729, in rotate\n    return img.rotate(angle, resample, expand, center, fillcolor=fill)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2005, in rotate\n    return self.transform((w, h), AFFINE, matrix, resample, fillcolor=fillcolor)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2299, in transform\n    im = new(self.mode, size, fillcolor)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2505, in new\n    return im._new(core.fill(mode, size, color))\nTypeError: must be real number, not tuple\n"]}]},{"cell_type":"code","metadata":{"id":"77FZsicB2Mke","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}