{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"version4 (combining orientations, features).ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ee65357b46cd43c5bb60b667f6a07edc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6267ba9c298645e2817dd07305dca4a0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_68c5fd2386214fb5bc9aed8a853e6fb8","IPY_MODEL_9a20fa284bae4cd2aee93f4c7226453e"]}},"6267ba9c298645e2817dd07305dca4a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68c5fd2386214fb5bc9aed8a853e6fb8":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f3af8063d1184a0da7bf67c8ad9be7ab","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":244418560,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":244418560,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8fa70a8bc0043398999cddc2f2a295b"}},"9a20fa284bae4cd2aee93f4c7226453e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e247f6e8d9a94e1697a16a6b0d37649d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 233M/233M [05:55&lt;00:00, 687kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bfbb76fafb14806b9d90479814bca11"}},"f3af8063d1184a0da7bf67c8ad9be7ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e8fa70a8bc0043398999cddc2f2a295b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e247f6e8d9a94e1697a16a6b0d37649d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3bfbb76fafb14806b9d90479814bca11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"7RQQrFFtr1kC","colab_type":"code","outputId":"d7ace020-5e40-4aec-e8af-ec7f11cffeca","executionInfo":{"status":"ok","timestamp":1585786309207,"user_tz":240,"elapsed":25006,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7zAvwmd3w_EKlRuAOOuoSH8_kdtQX1tz43cWl5SVdU6dCMn8cX3z35xgy95QuD1A1OIWDaTjeeZhx0T69oQhXp0Nq-t9hMfKAImV5pdf0H1_Afdk3VufRCHCF6QnPnGCG-mgtk9fC_OoAzOB3NyaUZUCdAl2gXAYcC5apMTkyzDdSOi5vMnaLM7_06aiQVJVPXMs3LGGYuh--FAtukgq6WAR4ucCiSLcB76BZiDFTCKKifOGwxdtIF4nVl-d9A4RES5JDedEHhv2635gzuJzQn7jMNo-Whg8OUlzcAQKAXF2lOxPS68CAvOe4svKmW-0HiwBLSFZaRpb4F3iwx3xkasd2z601pptp94QeCdoy06Oy6yaBgy-IVq-MgUn1XR7okqxIOtrCaP5nDrsr5hjFprJWnwtu10IceeUwPw0pzYa6ADqRRdOXtIdcM8pCBcoLmdfRvBqF0YUPEYGs4w1Gi2uEC-XOjsYQ3Rfv3x6Fd66f5qWcFGBEXhBt17WeEBVWGyzknko9HIcrBeSpYMqsS-wxDadnir_3Iu0pswvcw4FszJ6WdL1r6TvKlX4XP34UwBlqhLUtDKmfqA84WwlowfK72RjpJuccphdJrO5RAuMYHKbd1l5yrn0zFus-I0VgF6UCFyqceteBl0pQNZhRFLOI8lCoIzjbqJn3xoSq3TTao-BOWllMUrzBgPTuGytiSNcfQphMhW7CBPwCQqqLlNHueJhuWDe0kwNHUE1hyhM7BNbkt4bv7eeyHBMl91fZ2g=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ZaXWwCucA__","colab_type":"code","outputId":"9f892f29-d3ae-4522-fc62-9559fca0a973","executionInfo":{"status":"ok","timestamp":1585786427057,"user_tz":240,"elapsed":17896,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7zAvwmd3w_EKlRuAOOuoSH8_kdtQX1tz43cWl5SVdU6dCMn8cX3z35xgy95QuD1A1OIWDaTjeeZhx0T69oQhXp0Nq-t9hMfKAImV5pdf0H1_Afdk3VufRCHCF6QnPnGCG-mgtk9fC_OoAzOB3NyaUZUCdAl2gXAYcC5apMTkyzDdSOi5vMnaLM7_06aiQVJVPXMs3LGGYuh--FAtukgq6WAR4ucCiSLcB76BZiDFTCKKifOGwxdtIF4nVl-d9A4RES5JDedEHhv2635gzuJzQn7jMNo-Whg8OUlzcAQKAXF2lOxPS68CAvOe4svKmW-0HiwBLSFZaRpb4F3iwx3xkasd2z601pptp94QeCdoy06Oy6yaBgy-IVq-MgUn1XR7okqxIOtrCaP5nDrsr5hjFprJWnwtu10IceeUwPw0pzYa6ADqRRdOXtIdcM8pCBcoLmdfRvBqF0YUPEYGs4w1Gi2uEC-XOjsYQ3Rfv3x6Fd66f5qWcFGBEXhBt17WeEBVWGyzknko9HIcrBeSpYMqsS-wxDadnir_3Iu0pswvcw4FszJ6WdL1r6TvKlX4XP34UwBlqhLUtDKmfqA84WwlowfK72RjpJuccphdJrO5RAuMYHKbd1l5yrn0zFus-I0VgF6UCFyqceteBl0pQNZhRFLOI8lCoIzjbqJn3xoSq3TTao-BOWllMUrzBgPTuGytiSNcfQphMhW7CBPwCQqqLlNHueJhuWDe0kwNHUE1hyhM7BNbkt4bv7eeyHBMl91fZ2g=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","%cd \"/content/gdrive/My Drive/thesis/Data\"\n","\n","#csv import labels\n","\n","train_ACL_labels = np.array(pd.read_csv(\"train-acl.csv\", header=None).iloc[:,1])\n","train_abnormal_labels = np.array(pd.read_csv(\"train-abnormal.csv\", header=None).iloc[:,1])\n","train_meniscus_labels = np.array(pd.read_csv(\"train-meniscus.csv\", header=None).iloc[:,1])\n","\n","valid_ACL_labels = np.array(pd.read_csv(\"valid-acl.csv\", header=None).iloc[:,1])\n","valid_abnormal_labels = np.array(pd.read_csv(\"valid-abnormal.csv\", header=None).iloc[:,1])\n","valid_meniscus_labels = np.array(pd.read_csv(\"valid-meniscus.csv\", header=None).iloc[:,1])\n","\n","test_ACL_labels = np.array(pd.read_csv(\"test-acl.csv\", header=None).iloc[:,1])\n","test_abnormal_labels = np.array(pd.read_csv(\"test-abnormal.csv\", header=None).iloc[:,1])\n","test_meniscus_labels = np.array(pd.read_csv(\"test-meniscus.csv\", header=None).iloc[:,1])\n","\n","#data path\n","train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","train_axial_path = \"/content/gdrive/My Drive/thesis/Data/train/coronal\"\n","\n","counter = 5\n","for filename in os.listdir(train_axial_path):\n","  if counter > 0:\n","    file0 = np.load(train_axial_path + '/' + filename)\n","    variancelist = []\n","    for slice in range(file0.shape[0]):\n","      variancelist.append(np.var(file0[slice,:,:]))\n","    #print(file0)\n","    #print('max', np.amax(file0))\n","    #print('mean', np.mean(file0))\n","    #print(filename, 'file shape', file0.shape, 'max_var_index', variancelist.index(max(variancelist)), max(variancelist))\n","    counter = counter - 1\n","\n","print(valid_ACL_labels)\n","print(\"done!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/thesis/Data\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 0 0 1 1 0 1 0]\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7jqvUXbEDHe0","colab_type":"code","colab":{}},"source":["# model.py\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","from torchvision import models\n","\n","torch.set_printoptions(precision=10)\n","\n","class MRNet(nn.Module):\n","    def __init__(self, custommodel='alexnet'):\n","        super().__init__()\n","        if custommodel == 'alexnet':\n","          self.model = models.alexnet(pretrained=True)\n","          self.classifier = nn.Linear(256,1)\n","        if custommodel == 'vgg11_bn':\n","          self.model = models.vgg11_bn(pretrained=True)\n","          self.classifier = nn.Linear(512,1)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","\n","    # change this to adapt to different networks\n","    def forward(self, x, savedir='None'):\n","        x = torch.squeeze(x, dim=0) # only batch size 1 supported\n","        x = self.model.features(x)\n","        # make sure that gap returns size 256\n","        x = self.gap(x).view(x.size(0), -1)\n","        x = torch.max(x, 0, keepdim=True)[0]\n","        #features3 = (x.cpu()).detach().numpy()\n","        x = self.classifier(x)\n","        #print('x name', x)\n","        #print('x torch sigmoid', torch.sigmoid(x))\n","        #if savedir != 'None':\n","        #  np.save(savedir + str(x), features3)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zm9tvg40oRq","colab_type":"code","colab":{}},"source":["import math\n","import torch\n","from torch.optim.optimizer import Optimizer, required\n","\n","class RAdam(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        \n","        self.degenerated_to_sgd = degenerated_to_sgd\n","        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n","            for param in params:\n","                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n","                    param['buffer'] = [[None, None, None] for _ in range(10)]\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n","        super(RAdam, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(RAdam, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('RAdam does not support sparse gradients')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                state['step'] += 1\n","                buffered = group['buffer'][int(state['step'] % 10)]\n","                if state['step'] == buffered[0]:\n","                    N_sma, step_size = buffered[1], buffered[2]\n","                else:\n","                    buffered[0] = state['step']\n","                    beta2_t = beta2 ** state['step']\n","                    N_sma_max = 2 / (1 - beta2) - 1\n","                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n","                    buffered[1] = N_sma\n","\n","                    # more conservative since it's an approximated value\n","                    if N_sma >= 5:\n","                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n","                    elif self.degenerated_to_sgd:\n","                        step_size = 1.0 / (1 - beta1 ** state['step'])\n","                    else:\n","                        step_size = -1\n","                    buffered[2] = step_size\n","\n","                # more conservative since it's an approximated value\n","                if N_sma >= 5:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n","                    p.data.copy_(p_data_fp32)\n","                elif step_size > 0:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n","                    p.data.copy_(p_data_fp32)\n","\n","        return loss\n","\n","class PlainRAdam(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","                    \n","        self.degenerated_to_sgd = degenerated_to_sgd\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n","\n","        super(PlainRAdam, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(PlainRAdam, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('RAdam does not support sparse gradients')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                state['step'] += 1\n","                beta2_t = beta2 ** state['step']\n","                N_sma_max = 2 / (1 - beta2) - 1\n","                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n","\n","\n","                # more conservative since it's an approximated value\n","                if N_sma >= 5:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n","                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n","                    p.data.copy_(p_data_fp32)\n","                elif self.degenerated_to_sgd:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n","                    p_data_fp32.add_(-step_size, exp_avg)\n","                    p.data.copy_(p_data_fp32)\n","\n","        return loss\n","\n","\n","class AdamW(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        \n","        defaults = dict(lr=lr, betas=betas, eps=eps,\n","                        weight_decay=weight_decay, warmup = warmup)\n","        super(AdamW, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(AdamW, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                state['step'] += 1\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","                \n","                if group['warmup'] > state['step']:\n","                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n","                else:\n","                    scheduled_lr = group['lr']\n","\n","                step_size = scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n","                \n","                if group['weight_decay'] != 0:\n","                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n","\n","                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n","\n","                p.data.copy_(p_data_fp32)\n","\n","        return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0SjKDlPZ7XP","colab_type":"code","colab":{}},"source":["import argparse\n","import json\n","import numpy as np\n","import os\n","import torch\n","from datetime import datetime\n","from pathlib import Path\n","from sklearn import metrics\n","\n","def train(rundir, diagnosis, orientation, epochs, learning_rate, transformbool, use_gpu):\n","    \n","    val_auc_array = list()\n","    train_auc_array = list()\n","    test_auc_array = list()\n","\n","    train_fpr_array = list()\n","    train_tpr_array = list()\n","    val_fpr_array = list()\n","    val_tpr_array = list()\n","    test_fpr_array = list()\n","    test_tpr_array = list()\n","\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    \n","    model = MRNet()\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    optimizer = RAdam(model.parameters(), learning_rate, weight_decay=.01)\n","\n","    # patience too low (after 5 epochs, if AUC hasnt improved, slash learning rate .3), which is why high learning rate seems to work better\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=.3, threshold=1e-4)\n","\n","    best_val_loss = float('inf')\n","\n","    start_time = datetime.now()\n","\n","    for epoch in range(epochs):\n","        change = datetime.now() - start_time\n","        print('starting epoch {}. time passed: {}'.format(epoch+1, str(change)))\n","        \n","        train_loss, train_auc, _, _, tra_fpr, tra_tpr = run_model(model, train_loader, train=True, optimizer=optimizer)\n","        #print(f'train loss: {train_loss:0.4f}')\n","        #print(f'train AUC: {train_auc:0.4f}')\n","\n","        val_loss, val_auc, _, _, val_fpr, val_tpr = run_model(model, valid_loader)\n","        #print(f'valid loss: {val_loss:0.4f}')\n","        #print(f'valid AUC: {val_auc:0.4f}')\n","\n","        test_loss, test_auc, _, _, te_fpr, te_tpr = run_model(model, test_loader)\n","\n","        val_auc_array.append(val_auc)\n","        train_auc_array.append(train_auc)\n","        test_auc_array.append(test_auc)\n","        train_fpr_array.append(tra_fpr)\n","        train_tpr_array.append(tra_tpr)\n","        val_fpr_array.append(val_fpr)\n","        val_tpr_array.append(val_tpr)\n","        test_fpr_array.append(te_fpr)\n","        test_tpr_array.append(te_tpr)\n","        \n","        scheduler.step(val_loss)\n","  \n","    \n","    file_name = f'val{val_auc:0.4f}_train{train_auc:0.4f}_test{test_auc:0.4f}_epoch{epoch+1}'\n","    save_path = \"/content/gdrive/My Drive/thesis/Results/models\" + '/' + str(diagnosis) + '/' + str(orientation) + \"/\" + file_name\n","    torch.save(model.state_dict(), save_path)\n","    print('model saved at', str(save_path))\n","        \n","    return val_auc_array, train_auc_array, test_auc_array, train_fpr_array, train_tpr_array, val_fpr_array, val_tpr_array, test_fpr_array, test_tpr_array"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a9acbfeb-6df9-47f7-ea4e-f1163d4854ef","executionInfo":{"status":"ok","timestamp":1585786466801,"user_tz":240,"elapsed":3645,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7zAvwmd3w_EKlRuAOOuoSH8_kdtQX1tz43cWl5SVdU6dCMn8cX3z35xgy95QuD1A1OIWDaTjeeZhx0T69oQhXp0Nq-t9hMfKAImV5pdf0H1_Afdk3VufRCHCF6QnPnGCG-mgtk9fC_OoAzOB3NyaUZUCdAl2gXAYcC5apMTkyzDdSOi5vMnaLM7_06aiQVJVPXMs3LGGYuh--FAtukgq6WAR4ucCiSLcB76BZiDFTCKKifOGwxdtIF4nVl-d9A4RES5JDedEHhv2635gzuJzQn7jMNo-Whg8OUlzcAQKAXF2lOxPS68CAvOe4svKmW-0HiwBLSFZaRpb4F3iwx3xkasd2z601pptp94QeCdoy06Oy6yaBgy-IVq-MgUn1XR7okqxIOtrCaP5nDrsr5hjFprJWnwtu10IceeUwPw0pzYa6ADqRRdOXtIdcM8pCBcoLmdfRvBqF0YUPEYGs4w1Gi2uEC-XOjsYQ3Rfv3x6Fd66f5qWcFGBEXhBt17WeEBVWGyzknko9HIcrBeSpYMqsS-wxDadnir_3Iu0pswvcw4FszJ6WdL1r6TvKlX4XP34UwBlqhLUtDKmfqA84WwlowfK72RjpJuccphdJrO5RAuMYHKbd1l5yrn0zFus-I0VgF6UCFyqceteBl0pQNZhRFLOI8lCoIzjbqJn3xoSq3TTao-BOWllMUrzBgPTuGytiSNcfQphMhW7CBPwCQqqLlNHueJhuWDe0kwNHUE1hyhM7BNbkt4bv7eeyHBMl91fZ2g=s64","userId":"12217843719772555429"}},"id":"2H9wZCt37K4H","colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# loader.py\n","\n","!pip install medicaltorch\n","\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import torchvision\n","from medicaltorch import transforms as mt_transforms\n","import PIL\n","from random import sample\n","\n","from torch.autograd import Variable\n","\n","INPUT_DIM = 224\n","MAX_PIXEL_VAL = 255\n","#MEAN = 58.09\n","#STDDEV = 49.73\n","\n","class Dataset(data.Dataset):\n","    def __init__(self, datadirs, diagnosis, orientation, use_gpu, transformbool):\n","        super().__init__()\n","        self.use_gpu = use_gpu\n","        self.transformbool = transformbool\n","        label_dict = {}\n","        self.paths = []\n","        #print(datadirs)\n","        \n","        self.orientation = orientation\n","        self.diagnosis = diagnosis\n","\n","        train_string = \"/content/gdrive/My Drive/thesis/Data/train\"\n","        valid_string = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","        test_string = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","        if datadirs == train_string:\n","          if diagnosis == 'ACL':\n","            self.labels = train_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = train_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = train_abnormal_labels\n","        if datadirs == valid_string:\n","          if diagnosis == 'ACL':\n","            self.labels = valid_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = valid_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = valid_abnormal_labels\n","        if datadirs == test_string:\n","          if diagnosis == 'ACL':\n","            self.labels = test_ACL_labels\n","          if diagnosis == 'meniscus':\n","            self.labels = test_meniscus_labels\n","          if diagnosis == 'abnormal':\n","            self.labels = test_abnormal_labels\n","\n","        direct = datadirs + '/' + self.orientation\n","        for file in os.listdir(direct):\n","          self.paths.append(direct + '/' + file)\n","        self.paths.sort()\n","\n","        #print(\"paths\", self.paths[0:10])\n","\n","        neg_weight = np.mean(self.labels)\n","        self.weights = [neg_weight, 1 - neg_weight]\n","\n","        #print(self.labels.shape)\n","        #print(self.weights)\n","\n","    def weighted_loss(self, prediction, target):\n","        weights_npy = np.array([self.weights[int(t[0])] for t in target.data])\n","        weights_tensor = torch.FloatTensor(weights_npy)\n","        if self.use_gpu:\n","            weights_tensor = weights_tensor.cuda()\n","        loss = F.binary_cross_entropy_with_logits(prediction, target, weight=Variable(weights_tensor))\n","        return loss\n","\n","    # Data augmentation section\n","    # can go through each cases, looking at the histogram of 3T vs 1.5T (naive distribution of contrast data?)\n","    def __getitem__(self, index):\n","        path = self.paths[index]\n","        vol = np.load(path)\n","\n","        ax_mean = 63.16\n","        ax_std = 60.46\n","        cor_mean = 59.27\n","        cor_std = 64.00\n","        sag_mean = 58.25\n","        sag_std = 48.15\n","\n","        # standardize\n","        vol = (vol - np.min(vol)) / (np.max(vol) - np.min(vol) + 1.0e-6) * MAX_PIXEL_VAL\n","        \n","        if self.orientation == 'axial':\n","          MEAN = ax_mean\n","          STDDEV = ax_std\n","        if self.orientation == 'coronal':\n","          MEAN = cor_mean\n","          STDDEV = cor_std\n","        if self.orientation == 'sagittal':\n","          MEAN = sag_mean\n","          STDDEV = sag_std\n","        \n","        vol = (vol - MEAN) / STDDEV\n","\n","        vol = vol.astype(np.float32)\n","\n","        flag = False\n","        randomangle = 0\n","\n","        # define transform policy\n","        hor_flip = np.random.rand(1)\n","        ran_rot = np.random.rand(1)\n","        randomangle = np.random.uniform(-20, 20)\n","        uni_noise = np.random.rand(1)\n","\n","        \"\"\"\n","        if ran_rot < 0.5:\n","          randomangle = 0\n","        \"\"\"\n","        if self.transformbool:\n","          #if np.random.rand(1) < 0.5:\n","          flag = True\n","          \n","          if uni_noise < 0.5:\n","            noise_array = np.random.uniform(0.95,1.05,256*256)\n","            noise_array.resize((256,256))\n","            \n","            vol = np.multiply(vol, noise_array)\n","            vol = np.clip(vol, 0, 255)\n","            vol = vol.astype(np.float32)\n","          \n","          self.transforms = torchvision.transforms.Compose([\n","            torchvision.transforms.ToPILImage(),\n","            torchvision.transforms.RandomHorizontalFlip(p=(hor_flip < 0.5)), \n","            torchvision.transforms.RandomAffine((randomangle,randomangle), resample=PIL.Image.BILINEAR),\n","            torchvision.transforms.ToTensor()\n","        ])\n","\n","        if flag:\n","          for sliceindex in range(vol.shape[0]):\n","            vol[sliceindex] = self.transforms(np.array(vol[sliceindex]))\n","\n","        vol = np.stack((vol,)*3, axis=1)\n","        vol_tensor = torch.FloatTensor(vol)\n","        label_tensor = torch.FloatTensor([self.labels[index]])\n","\n","        return vol_tensor, label_tensor\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","def load_data(diagnosis, orientation, transformbool, use_gpu=True):\n","\n","    print('load_data', diagnosis, orientation)\n","\n","    train_path = \"/content/gdrive/My Drive/thesis/Data/train\"\n","    valid_path = \"/content/gdrive/My Drive/thesis/Data/valid\"\n","    test_path = \"/content/gdrive/My Drive/thesis/Data/test\"\n","\n","    batchsize = 1\n","    numworkers = 8\n","    \n","    #assert(1==2)\n","    #train_dataset = Dataset(train_dirs, diagnosis, use_gpu)\n","    train_dataset = Dataset(train_path, diagnosis, orientation, use_gpu, transformbool)\n","    valid_dataset = Dataset(valid_path, diagnosis, orientation, use_gpu, False)\n","    test_dataset = Dataset(test_path, diagnosis, orientation, use_gpu, False)\n","\n","    train_loader = data.DataLoader(train_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    valid_loader = data.DataLoader(valid_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    test_loader = data.DataLoader(test_dataset, batch_size=batchsize, num_workers=numworkers, shuffle=False)\n","    return train_loader, valid_loader, test_loader\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting medicaltorch\n","  Downloading https://files.pythonhosted.org/packages/5a/85/b3fa267c6cdec058c937a5046e357de61dda938179aeeca72485f13b1fa2/medicaltorch-0.2-py3-none-any.whl\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.5.0)\n","Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (3.0.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.0)\n","Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.38.0)\n","Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.18.2)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (1.12.0)\n","Installing collected packages: medicaltorch\n","Successfully installed medicaltorch-0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"06tlGPqT7LKR","colab":{}},"source":["# evaluate.py\n","\n","import argparse\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import torch\n","\n","from sklearn import metrics\n","from torch.autograd import Variable\n","\n","#from loader import load_data\n","#from model import MRNet\n","\n","def get_parser():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--model_path', type=str, required=True)\n","    parser.add_argument('--split', type=str, required=True)\n","    parser.add_argument('--diagnosis', type=int, required=True)\n","    parser.add_argument('--gpu', action='store_true')\n","    return parser\n","\n","def run_model(model, loader, savedir='None', train=False, optimizer=None):\n","    preds = []\n","    labels = []\n","\n","    if train:\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    total_loss = 0.\n","    num_batches = 0\n","\n","    for batch in loader:\n","        if train:\n","            optimizer.zero_grad()\n","\n","        vol, label = batch\n","        if loader.dataset.use_gpu:\n","            vol = vol.cuda()\n","            label = label.cuda()\n","        vol = Variable(vol)\n","        label = Variable(label)\n","\n","        logit = model.forward(vol, savedir)\n","\n","        loss = loader.dataset.weighted_loss(logit, label)\n","        total_loss += loss.item()\n","\n","        #\n","        pred = torch.sigmoid(logit)\n","        pred_npy = pred.data.cpu().numpy()[0][0]\n","        label_npy = label.data.cpu().numpy()[0][0]\n","\n","        preds.append(pred_npy)\n","        labels.append(label_npy)\n","\n","        if train:\n","            loss.backward()\n","            optimizer.step()\n","        num_batches += 1\n","\n","    avg_loss = total_loss / num_batches\n","\n","    fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n","    print(\"threshold is: \", threshold)\n","    auc = metrics.auc(fpr, tpr)\n","\n","    return avg_loss, auc, preds, labels, fpr, tpr\n","\n","def evaluate(split, model_path, diagnosis, orientation, transformbool, use_gpu, savedir):\n","\n","    train_loader, valid_loader, test_loader = load_data(diagnosis, orientation, transformbool, use_gpu)\n","    try:\n","      model = MRNet(custommodel='alexnet')\n","      print('using alexnet ...')\n","    except:\n","      model = MRNet(custommodel='vgg11_bn')\n","      print('using vgg11_bn')\n","    state_dict = torch.load(model_path, map_location=(None if use_gpu else 'cpu'))\n","    model.load_state_dict(state_dict)\n","\n","    if use_gpu:\n","        model = model.cuda()\n","\n","    if split == 'train':\n","        loader = train_loader\n","    elif split == 'valid':\n","        loader = valid_loader\n","    elif split == 'test':\n","        loader = test_loader\n","    else:\n","        raise ValueError(\"split must be 'train', 'valid', or 'test'\")\n","\n","    loss, auc, preds, labels, fpr, tpr = run_model(model, loader, savedir)\n","\n","    print(f'{split} loss: {loss:0.4f}')\n","    print(f'{split} AUC: {auc:0.4f}')\n","\n","    print(\"FPR: \", fpr)\n","    print(\"TPR: \", tpr)\n","\n","    return preds, labels\n","\n","#if __name__ == '__main__':\n","#    args = get_parser().parse_args()\n","#   evaluate(args.split, args.model_path, args.diagnosis, args.gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q7WHZv0b7L10","colab":{}},"source":["import matplotlib\n","matplotlib.use('Agg')\n","gpu = True\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","#learningrate = 5e-05\n","epochs = 100\n","#diagnosis = 'ACL'\n","rundir = \"/content/gdrive/My Drive/thesis/Data\"\n","#orientation = 'axial'\n","savedir = \"/content/gdrive/My Drive/thesis/Results/round2\"\n","\n","\n","if gpu:\n","  torch.cuda.manual_seed_all(seed)\n","\n","def display_single(x_length, lr1, varray, tarray, testarray, title, xlabel, ylabel, save_dir):\n","  plt.figure(0)\n","  plt.title(title)\n","  plt.ylim(0.0,1.0)\n","  plt.plot(np.arange(x_length), varray, label='valid')\n","  plt.plot(np.arange(x_length), tarray, label='train')\n","  plt.plot(np.arange(x_length), testarray, label='test')\n","  plt.legend()\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.savefig(save_dir + '/' + title + '.eps', format='eps')\n","  plt.show()\n","  plt.close()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSFL5juaAzeo","colab_type":"text"},"source":["Change Transforms\n"]},{"cell_type":"code","metadata":{"id":"RBLxx850J5Af","colab_type":"code","colab":{}},"source":["import matplotlib\n","matplotlib.use('Agg')\n","gpu = True\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","#learningrate = 5e-05\n","epochs = 100\n","#diagnosis = 'ACL'\n","rundir = \"/content/gdrive/My Drive/thesis/Data\"\n","#orientation = 'axial'\n","savedir = \"/content/gdrive/My Drive/thesis/Results/round3\"\n","\n","\n","if gpu:\n","  torch.cuda.manual_seed_all(seed)\n","\n","def display_single(x_length, lr1, varray, tarray, testarray, title, xlabel, ylabel, save_dir):\n","  plt.figure(0)\n","  plt.title(title)\n","  plt.ylim(0.0,1.0)\n","  plt.plot(np.arange(x_length), varray, label='valid')\n","  plt.plot(np.arange(x_length), tarray, label='train')\n","  plt.plot(np.arange(x_length), testarray, label='test')\n","  plt.legend()\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.savefig(save_dir + '/' + title + '.eps', format='eps')\n","  plt.show()\n","  plt.close()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9995r_19Ymqv","colab_type":"code","colab":{}},"source":["# find models for 1 disease, with best performing validation set performance\n","# evaluate these models on the data to produce prediction labels for all three orientations\n","# use set of 3 label lists to predict on ultimate label\n","## mean, mode, logistic regression, neural net, "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGRZNOxPYyIH","colab_type":"code","colab":{}},"source":["models_path = \"/content/gdrive/My Drive/thesis/Results/models\"\n","diags = ['ACL', 'meniscus', 'abnormal']\n","oris = ['axial', 'sagittal', 'coronal']\n","\n","def choose_models(diag):\n","  # ax_path, sag_path, cor_path\n","  return_list = list()\n","  for ori in oris:\n","    temp_path = models_path + '/' + diag + '/' + ori\n","    rank_list = list()\n","    path_list = list()\n","\n","    for filename in os.listdir(temp_path):\n","      val, train, test, epoch = [entry.split('.') for entry in filename.split('_')]\n","      # if want to sort by highest validation AUC\n","      # could probably change it to something like validation * 5 - train * 3 + test or something along this line\n","      #rank_list.append(5* int(val[1]) - 3* (int(train[1]) - int(test[1])))\n","      rank_list.append(int(val[1]) - 0.2*abs(int(train[1]) - int(val[1])))\n","      path_list.append(temp_path + '/' + filename)\n","    \n","    maxi = rank_list.index(max(rank_list))\n","    #print(diag, ori, maxi, rank_list[maxi], path_list[maxi])\n","    return_list.append(path_list[maxi])\n","\n","  return return_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Asg4fmr4jlGx","colab_type":"code","colab":{}},"source":["def evaluate_three(diagnosis):\n","  modelpathslist = choose_models(diagnosis)\n","  oris = ['axial', 'sagittal', 'coronal']\n","  splits = ['train', 'valid', 'test']\n","  predslist = list()\n","  labelslist = list()\n","  start_time = datetime.now()\n","\n","  for split in splits:\n","    for index in range(3):\n","      print(split, oris[index])\n","      change = datetime.now() - start_time\n","      #print('time passed: {}'.format(str(change)))\n","      savedir = \"/content/gdrive/My Drive/thesis/Results/model_features/\" + str(diagnosis) + '/' + str(split) + '/' + str(oris[index]) + '/'\n","      preds, labels = evaluate(split, modelpathslist[index], diagnosis, oris[index], False, True, savedir)\n","      save_preds = '/content/gdrive/My Drive/thesis/Results/model_predictions/' + str(diagnosis) + '/' + str(split) + '/' + str(oris[index]) + '/' + 'predictions.npy'\n","      np.save(save_preds, preds)\n","      predslist.append([preds])\n","      labelslist.append([labels])\n","\n","  return predslist, labelslist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-SE3MvHKklde","colab_type":"code","outputId":"996fdbe5-de5a-4e34-a6c7-f18c8f5d90ef","executionInfo":{"status":"ok","timestamp":1585786909204,"user_tz":240,"elapsed":424987,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj7zAvwmd3w_EKlRuAOOuoSH8_kdtQX1tz43cWl5SVdU6dCMn8cX3z35xgy95QuD1A1OIWDaTjeeZhx0T69oQhXp0Nq-t9hMfKAImV5pdf0H1_Afdk3VufRCHCF6QnPnGCG-mgtk9fC_OoAzOB3NyaUZUCdAl2gXAYcC5apMTkyzDdSOi5vMnaLM7_06aiQVJVPXMs3LGGYuh--FAtukgq6WAR4ucCiSLcB76BZiDFTCKKifOGwxdtIF4nVl-d9A4RES5JDedEHhv2635gzuJzQn7jMNo-Whg8OUlzcAQKAXF2lOxPS68CAvOe4svKmW-0HiwBLSFZaRpb4F3iwx3xkasd2z601pptp94QeCdoy06Oy6yaBgy-IVq-MgUn1XR7okqxIOtrCaP5nDrsr5hjFprJWnwtu10IceeUwPw0pzYa6ADqRRdOXtIdcM8pCBcoLmdfRvBqF0YUPEYGs4w1Gi2uEC-XOjsYQ3Rfv3x6Fd66f5qWcFGBEXhBt17WeEBVWGyzknko9HIcrBeSpYMqsS-wxDadnir_3Iu0pswvcw4FszJ6WdL1r6TvKlX4XP34UwBlqhLUtDKmfqA84WwlowfK72RjpJuccphdJrO5RAuMYHKbd1l5yrn0zFus-I0VgF6UCFyqceteBl0pQNZhRFLOI8lCoIzjbqJn3xoSq3TTao-BOWllMUrzBgPTuGytiSNcfQphMhW7CBPwCQqqLlNHueJhuWDe0kwNHUE1hyhM7BNbkt4bv7eeyHBMl91fZ2g=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ee65357b46cd43c5bb60b667f6a07edc","6267ba9c298645e2817dd07305dca4a0","68c5fd2386214fb5bc9aed8a853e6fb8","9a20fa284bae4cd2aee93f4c7226453e","f3af8063d1184a0da7bf67c8ad9be7ab","e8fa70a8bc0043398999cddc2f2a295b","e247f6e8d9a94e1697a16a6b0d37649d","3bfbb76fafb14806b9d90479814bca11"]}},"source":["predslist_ACL, labelslist_ACL = evaluate_three('ACL')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train axial\n","load_data ACL axial\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee65357b46cd43c5bb60b667f6a07edc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=244418560), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","using alexnet ...\n","threshold is:  [1.9999987e+00 9.9999869e-01 9.9989629e-01 9.9989533e-01 9.9571663e-01\n"," 9.9552476e-01 9.9419159e-01 9.9413562e-01 9.9398613e-01 9.9369109e-01\n"," 9.8694009e-01 9.8682320e-01 9.8629123e-01 9.8619080e-01 9.8605376e-01\n"," 9.8477978e-01 9.8404467e-01 9.8292357e-01 9.7803444e-01 9.7799623e-01\n"," 9.7451383e-01 9.7351968e-01 9.7324592e-01 9.7038561e-01 9.7024035e-01\n"," 9.6864843e-01 9.6780425e-01 9.6676773e-01 9.6484852e-01 9.6276546e-01\n"," 9.6195531e-01 9.6052414e-01 9.5970494e-01 9.5948130e-01 9.5931268e-01\n"," 9.5909911e-01 9.5408475e-01 9.5401251e-01 9.5341158e-01 9.5002979e-01\n"," 9.4885296e-01 9.4697195e-01 9.4363028e-01 9.3843168e-01 9.3481541e-01\n"," 9.3157858e-01 9.3038768e-01 9.3016607e-01 9.2654383e-01 9.2167944e-01\n"," 9.2134649e-01 9.1360879e-01 9.1334587e-01 9.1178173e-01 9.1084802e-01\n"," 9.0816790e-01 9.0742785e-01 9.0720999e-01 9.0719903e-01 9.0139520e-01\n"," 9.0067708e-01 8.9646900e-01 8.9535922e-01 8.9117783e-01 8.9068246e-01\n"," 8.8628501e-01 8.8385528e-01 8.8200533e-01 8.7823486e-01 8.7727970e-01\n"," 8.7692338e-01 8.7033266e-01 8.6359656e-01 8.6215889e-01 8.6189049e-01\n"," 8.5487211e-01 8.4843737e-01 8.2509774e-01 8.2185322e-01 8.1446147e-01\n"," 8.1186843e-01 8.0995142e-01 8.0733407e-01 8.0575877e-01 8.0198920e-01\n"," 8.0161619e-01 7.9827946e-01 7.9380244e-01 7.8724653e-01 7.6019591e-01\n"," 7.5333327e-01 7.3928112e-01 7.3352343e-01 7.3108220e-01 7.2631210e-01\n"," 7.0011902e-01 6.9820303e-01 6.8562031e-01 6.8361431e-01 6.6493386e-01\n"," 6.6160607e-01 6.2851977e-01 6.2712044e-01 4.1098088e-01 4.0497592e-01\n"," 3.2273799e-01 3.1710330e-01 7.3670963e-05]\n","train loss: 0.0940\n","train AUC: 0.9731\n","FPR:  [0.         0.         0.         0.00123153 0.00123153 0.00246305\n"," 0.00246305 0.00369458 0.00369458 0.00492611 0.00492611 0.00615764\n"," 0.00615764 0.00738916 0.00738916 0.00862069 0.00862069 0.00985222\n"," 0.00985222 0.01108374 0.01108374 0.01231527 0.01231527 0.01724138\n"," 0.01724138 0.01847291 0.01847291 0.02216749 0.02216749 0.02463054\n"," 0.02463054 0.02586207 0.02586207 0.0270936  0.0270936  0.02832512\n"," 0.02832512 0.02955665 0.02955665 0.03325123 0.03325123 0.03694581\n"," 0.03694581 0.04310345 0.04310345 0.04433498 0.04433498 0.0455665\n"," 0.0455665  0.04802956 0.04802956 0.04926108 0.04926108 0.05172414\n"," 0.05172414 0.05295567 0.05295567 0.05418719 0.05418719 0.06157635\n"," 0.06157635 0.06527094 0.06527094 0.06773399 0.06773399 0.06896552\n"," 0.06896552 0.07019704 0.07019704 0.07142857 0.07142857 0.07512315\n"," 0.07512315 0.07635468 0.07635468 0.08251232 0.08251232 0.09482759\n"," 0.09482759 0.09975369 0.09975369 0.10098522 0.10098522 0.10221675\n"," 0.10221675 0.10344828 0.10344828 0.10714286 0.10714286 0.12315271\n"," 0.12315271 0.13423645 0.13423645 0.13793103 0.13793103 0.15270936\n"," 0.15270936 0.16133005 0.16133005 0.16748768 0.16748768 0.17980296\n"," 0.17980296 0.30541872 0.30541872 0.35221675 0.35221675 1.        ]\n","TPR:  [0.         0.00531915 0.04255319 0.04255319 0.45212766 0.45212766\n"," 0.47340426 0.47340426 0.4893617  0.4893617  0.57978723 0.57978723\n"," 0.58510638 0.58510638 0.59574468 0.59574468 0.61170213 0.61170213\n"," 0.64361702 0.64361702 0.68085106 0.68085106 0.69148936 0.69148936\n"," 0.69680851 0.69680851 0.71808511 0.71808511 0.72340426 0.72340426\n"," 0.73404255 0.73404255 0.7393617  0.7393617  0.74468085 0.74468085\n"," 0.75531915 0.75531915 0.76595745 0.76595745 0.77659574 0.77659574\n"," 0.78723404 0.78723404 0.79255319 0.79255319 0.80319149 0.80319149\n"," 0.81382979 0.81382979 0.81914894 0.81914894 0.82446809 0.82446809\n"," 0.83510638 0.83510638 0.84042553 0.84042553 0.84574468 0.84574468\n"," 0.85106383 0.85106383 0.85638298 0.85638298 0.86170213 0.86170213\n"," 0.87234043 0.87234043 0.87765957 0.87765957 0.88297872 0.88297872\n"," 0.88829787 0.88829787 0.89893617 0.89893617 0.90425532 0.90425532\n"," 0.90957447 0.90957447 0.91489362 0.91489362 0.92021277 0.92021277\n"," 0.93085106 0.93085106 0.93617021 0.93617021 0.94148936 0.94148936\n"," 0.95212766 0.95212766 0.95744681 0.95744681 0.96276596 0.96276596\n"," 0.96808511 0.96808511 0.97340426 0.97340426 0.9787234  0.9787234\n"," 0.98404255 0.98404255 0.99468085 0.99468085 1.         1.        ]\n","train sagittal\n","load_data ACL sagittal\n","using alexnet ...\n","threshold is:  [1.9999509e+00 9.9995089e-01 7.2465736e-01 6.8981737e-01 6.4839572e-01\n"," 6.3720024e-01 5.7615638e-01 4.3715265e-01 4.2398050e-01 4.0619180e-01\n"," 3.9071408e-01 3.3432844e-01 3.0995160e-01 3.4593614e-07]\n","train loss: 0.0155\n","train AUC: 0.9998\n","FPR:  [0.         0.         0.         0.00123153 0.00123153 0.00246305\n"," 0.00246305 0.00738916 0.00738916 0.00985222 0.00985222 0.0135468\n"," 0.0135468  1.        ]\n","TPR:  [0.         0.00531915 0.95212766 0.95212766 0.97340426 0.97340426\n"," 0.98404255 0.98404255 0.9893617  0.9893617  0.99468085 0.99468085\n"," 1.         1.        ]\n","train coronal\n","load_data ACL coronal\n","using alexnet ...\n","threshold is:  [1.9906497e+00 9.9064964e-01 9.3023378e-01 9.2043549e-01 7.9596168e-01\n"," 7.9244697e-01 7.1396464e-01 7.1243870e-01 7.0643276e-01 7.0558244e-01\n"," 6.9151419e-01 6.8974423e-01 6.7203254e-01 6.6801429e-01 6.3742012e-01\n"," 6.3044655e-01 6.1988056e-01 6.1211967e-01 5.8217329e-01 5.7909411e-01\n"," 5.6184757e-01 5.5899847e-01 5.3373504e-01 5.2491379e-01 5.2322537e-01\n"," 5.1752609e-01 5.0306475e-01 5.0033385e-01 4.9873048e-01 4.9446124e-01\n"," 4.9244955e-01 4.9201697e-01 4.8794216e-01 4.8754060e-01 4.6791595e-01\n"," 4.6210521e-01 4.4517279e-01 4.3686834e-01 4.2149422e-01 4.2075858e-01\n"," 4.1535789e-01 4.0470043e-01 4.0409282e-01 4.0379527e-01 4.0094224e-01\n"," 3.9750904e-01 3.9252946e-01 3.8881209e-01 3.7914675e-01 3.7319624e-01\n"," 3.6971718e-01 3.6959937e-01 3.6808828e-01 3.6744198e-01 3.5908383e-01\n"," 3.5721955e-01 3.5458669e-01 3.5306451e-01 3.4547856e-01 3.4450561e-01\n"," 3.3428648e-01 3.2449648e-01 3.1998578e-01 3.1742963e-01 3.0663505e-01\n"," 2.9752231e-01 2.9734072e-01 2.9370910e-01 2.8759825e-01 2.8147063e-01\n"," 2.7976948e-01 2.7076611e-01 2.6418105e-01 2.5826809e-01 2.5822538e-01\n"," 2.5109625e-01 2.5053826e-01 2.1821617e-01 2.1635447e-01 2.1391363e-01\n"," 2.1353061e-01 2.0898284e-01 2.0866276e-01 1.9533242e-01 1.8712416e-01\n"," 1.8116368e-01 1.8115033e-01 1.8013608e-01 1.7915680e-01 1.7059268e-01\n"," 1.6974410e-01 1.6557883e-01 1.6445130e-01 1.5732107e-01 1.5634294e-01\n"," 1.4624667e-01 1.4417584e-01 1.3862550e-01 1.3776626e-01 1.3652046e-01\n"," 1.3627468e-01 1.2934734e-01 1.2898465e-01 7.1184963e-02 7.0853673e-02\n"," 6.9799557e-02 6.9175534e-02 6.4409405e-02 6.3552283e-02 5.5072274e-02\n"," 5.4730553e-02 5.3002950e-02 5.2568521e-02 3.5248760e-02 3.4565832e-02\n"," 2.1812379e-02 2.1674914e-02 7.3464871e-03 7.2186985e-03 1.5871494e-05]\n","train loss: 0.1343\n","train AUC: 0.9501\n","FPR:  [0.         0.         0.         0.00123153 0.00123153 0.00246305\n"," 0.00246305 0.00369458 0.00369458 0.00492611 0.00492611 0.00615764\n"," 0.00615764 0.00862069 0.00862069 0.01108374 0.01108374 0.01231527\n"," 0.01231527 0.0135468  0.0135468  0.01477833 0.01477833 0.01724138\n"," 0.01724138 0.01970443 0.01970443 0.02093596 0.02093596 0.02339901\n"," 0.02339901 0.02463054 0.02463054 0.02586207 0.02586207 0.02832512\n"," 0.02832512 0.03448276 0.03448276 0.03571429 0.03571429 0.03694581\n"," 0.03694581 0.03817734 0.03817734 0.03940887 0.03940887 0.04310345\n"," 0.04310345 0.04433498 0.04433498 0.0455665  0.0455665  0.04679803\n"," 0.04679803 0.04926108 0.04926108 0.05172414 0.05172414 0.05295567\n"," 0.05295567 0.05788177 0.05788177 0.0591133  0.0591133  0.06403941\n"," 0.06403941 0.06773399 0.06773399 0.07142857 0.07142857 0.08004926\n"," 0.08004926 0.08128079 0.08128079 0.08866995 0.08866995 0.10344828\n"," 0.10344828 0.10714286 0.10714286 0.11206897 0.11206897 0.12561576\n"," 0.12561576 0.1317734  0.1317734  0.13300493 0.13300493 0.1453202\n"," 0.1453202  0.15024631 0.15024631 0.16009852 0.16009852 0.16871921\n"," 0.16871921 0.18103448 0.18103448 0.18472906 0.18472906 0.19704433\n"," 0.19704433 0.32389163 0.32389163 0.32758621 0.32758621 0.34605911\n"," 0.34605911 0.38054187 0.38054187 0.38793103 0.38793103 0.4679803\n"," 0.4679803  0.55172414 0.55172414 0.7364532  0.7364532  1.        ]\n","TPR:  [0.         0.00531915 0.06914894 0.06914894 0.20212766 0.20212766\n"," 0.31914894 0.31914894 0.33510638 0.33510638 0.35106383 0.35106383\n"," 0.37765957 0.37765957 0.42553191 0.42553191 0.44148936 0.44148936\n"," 0.48404255 0.48404255 0.49468085 0.49468085 0.5212766  0.5212766\n"," 0.53191489 0.53191489 0.56382979 0.56382979 0.56914894 0.56914894\n"," 0.57446809 0.57446809 0.59042553 0.59042553 0.60638298 0.60638298\n"," 0.63829787 0.63829787 0.65425532 0.65425532 0.65957447 0.65957447\n"," 0.66489362 0.66489362 0.67553191 0.67553191 0.68617021 0.68617021\n"," 0.70744681 0.70744681 0.71808511 0.71808511 0.72340426 0.72340426\n"," 0.74468085 0.74468085 0.75       0.75       0.76595745 0.76595745\n"," 0.78191489 0.78191489 0.79787234 0.79787234 0.81914894 0.81914894\n"," 0.82446809 0.82446809 0.84042553 0.84042553 0.84574468 0.84574468\n"," 0.85638298 0.85638298 0.86170213 0.86170213 0.86702128 0.86702128\n"," 0.87234043 0.87234043 0.87765957 0.87765957 0.88297872 0.88297872\n"," 0.90425532 0.90425532 0.90957447 0.90957447 0.91489362 0.91489362\n"," 0.92021277 0.92021277 0.92553191 0.92553191 0.93085106 0.93085106\n"," 0.93617021 0.93617021 0.94148936 0.94148936 0.94680851 0.94680851\n"," 0.95212766 0.95212766 0.95744681 0.95744681 0.96276596 0.96276596\n"," 0.97340426 0.97340426 0.9787234  0.9787234  0.98404255 0.98404255\n"," 0.9893617  0.9893617  0.99468085 0.99468085 1.         1.        ]\n","valid axial\n","load_data ACL axial\n","using alexnet ...\n","threshold is:  [1.9999750e+00 9.9997497e-01 9.9964333e-01 9.9962997e-01 9.9439102e-01\n"," 9.9430990e-01 9.7944587e-01 9.7686440e-01 9.4929171e-01 9.3809432e-01\n"," 9.3489665e-01 9.3033922e-01 8.9124924e-01 8.7126172e-01 8.5164577e-01\n"," 7.4174356e-01 7.0975459e-01 6.4881891e-01 6.3707387e-01 6.3303053e-01\n"," 6.1699390e-01 6.0024166e-01 5.9085083e-01 5.4381061e-01 5.2852118e-01\n"," 4.8437977e-01 4.6743420e-01 4.0019101e-01 3.8909367e-01 3.3160007e-01\n"," 3.1964019e-01 2.7788204e-01 2.5622636e-01 1.7321023e-01 1.6684350e-01\n"," 1.3041480e-01 1.1760198e-01 9.4669747e-05]\n","valid loss: 0.2721\n","valid AUC: 0.8788\n","FPR:  [0.         0.         0.         0.01515152 0.01515152 0.03030303\n"," 0.03030303 0.04545455 0.04545455 0.06060606 0.06060606 0.09090909\n"," 0.09090909 0.10606061 0.10606061 0.21212121 0.21212121 0.24242424\n"," 0.24242424 0.25757576 0.25757576 0.28787879 0.28787879 0.33333333\n"," 0.33333333 0.39393939 0.39393939 0.46969697 0.46969697 0.48484848\n"," 0.48484848 0.56060606 0.56060606 0.63636364 0.63636364 0.68181818\n"," 0.68181818 1.        ]\n","TPR:  [0.         0.03703704 0.09259259 0.09259259 0.38888889 0.38888889\n"," 0.59259259 0.59259259 0.66666667 0.66666667 0.68518519 0.68518519\n"," 0.74074074 0.74074074 0.77777778 0.77777778 0.7962963  0.7962963\n"," 0.81481481 0.81481481 0.83333333 0.83333333 0.85185185 0.85185185\n"," 0.87037037 0.87037037 0.88888889 0.88888889 0.90740741 0.90740741\n"," 0.92592593 0.92592593 0.94444444 0.94444444 0.96296296 0.96296296\n"," 1.         1.        ]\n","valid sagittal\n","load_data ACL sagittal\n","using alexnet ...\n","threshold is:  [1.99990916e+00 9.99909163e-01 9.87959981e-01 9.86497343e-01\n"," 4.19162899e-01 3.01512152e-01 2.31727406e-01 2.23906964e-01\n"," 2.23184943e-01 1.94924146e-01 1.85086951e-01 1.71414033e-01\n"," 1.50775954e-01 1.44684851e-01 1.32388115e-01 1.02460936e-01\n"," 7.04177096e-02 6.72177970e-02 6.62255883e-02 6.36995062e-02\n"," 6.35074750e-02 5.87198362e-02 5.81219867e-02 3.28454450e-02\n"," 3.26135829e-02 1.56168798e-02 1.34205502e-02 2.73558614e-03\n"," 2.63389130e-03 2.35070661e-03 2.34186882e-03 9.82267666e-04\n"," 9.05276218e-04 1.40718521e-05]\n","valid loss: 0.2760\n","valid AUC: 0.9209\n","FPR:  [0.         0.         0.         0.01515152 0.01515152 0.04545455\n"," 0.04545455 0.06060606 0.06060606 0.10606061 0.10606061 0.12121212\n"," 0.12121212 0.13636364 0.13636364 0.15151515 0.15151515 0.1969697\n"," 0.1969697  0.22727273 0.22727273 0.25757576 0.25757576 0.3030303\n"," 0.3030303  0.31818182 0.31818182 0.56060606 0.56060606 0.57575758\n"," 0.57575758 0.71212121 0.71212121 1.        ]\n","TPR:  [0.         0.01851852 0.2037037  0.2037037  0.7037037  0.7037037\n"," 0.75925926 0.75925926 0.77777778 0.77777778 0.7962963  0.7962963\n"," 0.81481481 0.81481481 0.83333333 0.83333333 0.85185185 0.85185185\n"," 0.87037037 0.87037037 0.88888889 0.88888889 0.90740741 0.90740741\n"," 0.92592593 0.92592593 0.94444444 0.94444444 0.96296296 0.96296296\n"," 0.98148148 0.98148148 1.         1.        ]\n","valid coronal\n","load_data ACL coronal\n","using alexnet ...\n","threshold is:  [1.99657679e+00 9.96576726e-01 9.42543089e-01 9.10430968e-01\n"," 6.72860563e-01 5.82374454e-01 4.64375764e-01 4.22414154e-01\n"," 4.17589754e-01 3.96986365e-01 3.94539446e-01 3.78473043e-01\n"," 3.74500871e-01 3.45356643e-01 3.22901756e-01 2.80141622e-01\n"," 2.71015197e-01 2.57114589e-01 2.07222477e-01 1.97323427e-01\n"," 1.85995504e-01 1.54900506e-01 1.51817679e-01 1.18489780e-01\n"," 1.13997266e-01 1.13141015e-01 9.73004401e-02 9.67452154e-02\n"," 9.47610885e-02 7.08912089e-02 6.28170371e-02 6.10872172e-02\n"," 5.77035956e-02 5.01879789e-02 4.67278771e-02 4.34500128e-02\n"," 3.89553681e-02 1.54578127e-02 1.51956910e-02 1.42272273e-02\n"," 1.37064476e-02 1.18858656e-02 1.01262042e-02 8.47067777e-03\n"," 7.50860525e-03 2.18202267e-03 1.87212788e-03 5.65350347e-04]\n","valid loss: 0.3917\n","valid AUC: 0.7983\n","FPR:  [0.         0.         0.         0.01515152 0.01515152 0.03030303\n"," 0.03030303 0.06060606 0.06060606 0.09090909 0.09090909 0.12121212\n"," 0.12121212 0.15151515 0.15151515 0.18181818 0.18181818 0.1969697\n"," 0.1969697  0.25757576 0.25757576 0.34848485 0.34848485 0.40909091\n"," 0.40909091 0.42424242 0.42424242 0.43939394 0.43939394 0.53030303\n"," 0.53030303 0.54545455 0.54545455 0.59090909 0.59090909 0.60606061\n"," 0.60606061 0.71212121 0.71212121 0.72727273 0.72727273 0.74242424\n"," 0.74242424 0.77272727 0.77272727 0.87878788 0.87878788 1.        ]\n","TPR:  [0.         0.01851852 0.09259259 0.09259259 0.27777778 0.27777778\n"," 0.5        0.5        0.53703704 0.53703704 0.55555556 0.55555556\n"," 0.57407407 0.57407407 0.61111111 0.61111111 0.62962963 0.62962963\n"," 0.72222222 0.72222222 0.74074074 0.74074074 0.75925926 0.75925926\n"," 0.77777778 0.77777778 0.7962963  0.7962963  0.81481481 0.81481481\n"," 0.83333333 0.83333333 0.85185185 0.85185185 0.88888889 0.88888889\n"," 0.90740741 0.90740741 0.92592593 0.92592593 0.94444444 0.94444444\n"," 0.96296296 0.96296296 0.98148148 0.98148148 1.         1.        ]\n","test axial\n","load_data ACL axial\n","using alexnet ...\n","threshold is:  [1.9981580e+00 9.9815792e-01 9.9375534e-01 9.8697078e-01 9.8492789e-01\n"," 9.7765863e-01 9.7728217e-01 9.4911182e-01 9.2972487e-01 8.2413995e-01\n"," 8.1177717e-01 8.0875474e-01 8.0600208e-01 7.7639556e-01 7.7511185e-01\n"," 7.3223984e-01 7.1509922e-01 6.9277847e-01 6.9233972e-01 5.3751403e-01\n"," 4.8902923e-01 3.8364506e-01 3.5980576e-01 2.5565273e-01 2.4818549e-01\n"," 8.4236741e-02 8.3136566e-02 4.2163959e-04]\n","test loss: 0.1563\n","test AUC: 0.8145\n","FPR:  [0.         0.         0.         0.01818182 0.01818182 0.04545455\n"," 0.04545455 0.07272727 0.07272727 0.17272727 0.17272727 0.18181818\n"," 0.18181818 0.2        0.2        0.23636364 0.23636364 0.25454545\n"," 0.25454545 0.35454545 0.35454545 0.42727273 0.42727273 0.48181818\n"," 0.48181818 0.66363636 0.66363636 1.        ]\n","TPR:  [0.   0.05 0.25 0.25 0.3  0.3  0.35 0.35 0.45 0.45 0.55 0.55 0.6  0.6\n"," 0.65 0.65 0.7  0.7  0.75 0.75 0.85 0.85 0.9  0.9  0.95 0.95 1.   1.  ]\n","test sagittal\n","load_data ACL sagittal\n","using alexnet ...\n","threshold is:  [1.98847342e+00 9.88473475e-01 8.89523685e-01 8.43594909e-01\n"," 8.14521849e-01 7.76784360e-01 7.38588870e-01 7.01129496e-01\n"," 6.36933446e-01 3.13937813e-01 2.93411970e-01 1.61533982e-01\n"," 1.49843946e-01 1.18332498e-01 1.15730226e-01 8.79030451e-02\n"," 7.49653503e-02 5.06361984e-02 3.90333459e-02 2.48735249e-02\n"," 2.13305950e-02 4.87677846e-03 4.74535488e-03 7.46971229e-04\n"," 6.07581751e-04 5.25246782e-04 4.94437059e-04 1.29674343e-04\n"," 1.15928196e-04 1.39503095e-06]\n","test loss: 0.3174\n","test AUC: 0.7991\n","FPR:  [0.         0.         0.         0.00909091 0.00909091 0.01818182\n"," 0.01818182 0.04545455 0.04545455 0.06363636 0.06363636 0.11818182\n"," 0.11818182 0.13636364 0.13636364 0.19090909 0.19090909 0.20909091\n"," 0.20909091 0.25454545 0.25454545 0.48181818 0.48181818 0.74545455\n"," 0.74545455 0.76363636 0.76363636 0.87272727 0.87272727 1.        ]\n","TPR:  [0.   0.05 0.2  0.2  0.25 0.25 0.35 0.35 0.5  0.5  0.55 0.55 0.6  0.6\n"," 0.65 0.65 0.7  0.7  0.75 0.75 0.8  0.8  0.85 0.85 0.9  0.9  0.95 0.95\n"," 1.   1.  ]\n","test coronal\n","load_data ACL coronal\n","using alexnet ...\n","threshold is:  [1.8831978e+00 8.8319778e-01 6.5125549e-01 6.4407039e-01 3.5202318e-01\n"," 2.9728088e-01 2.8605378e-01 2.6485270e-01 2.0649217e-01 1.9570205e-01\n"," 1.8134865e-01 1.5926935e-01 1.5399760e-01 1.4824858e-01 1.4016010e-01\n"," 1.3464788e-01 1.1254035e-01 1.0526133e-01 7.1425393e-02 6.9133900e-02\n"," 6.0480386e-02 5.7948653e-02 5.7649918e-02 5.6832291e-02 3.7228823e-02\n"," 3.4566343e-02 1.9806819e-02 1.9105066e-02 1.4152460e-02 1.3771031e-02\n"," 1.2345080e-02 1.1683094e-02 1.8530346e-04]\n","test loss: 0.3001\n","test AUC: 0.7036\n","FPR:  [0.         0.         0.02727273 0.02727273 0.11818182 0.11818182\n"," 0.12727273 0.12727273 0.19090909 0.19090909 0.22727273 0.22727273\n"," 0.24545455 0.24545455 0.25454545 0.25454545 0.28181818 0.28181818\n"," 0.35454545 0.35454545 0.40909091 0.40909091 0.41818182 0.41818182\n"," 0.52727273 0.52727273 0.65454545 0.65454545 0.70909091 0.70909091\n"," 0.72727273 0.72727273 1.        ]\n","TPR:  [0.   0.05 0.05 0.1  0.1  0.2  0.2  0.35 0.35 0.4  0.4  0.45 0.45 0.5\n"," 0.5  0.55 0.55 0.65 0.65 0.7  0.7  0.75 0.75 0.8  0.8  0.85 0.85 0.9\n"," 0.9  0.95 0.95 1.   1.  ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VC8b-U-Boh0N","colab_type":"code","outputId":"16c745da-4b94-45e4-e01d-e91c70be9336","executionInfo":{"status":"ok","timestamp":1584858298760,"user_tz":240,"elapsed":1798003,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDNUmrksb7ajH78ufM6_UhkFXwnC92mfPrGlVMselGrCi2rbtT0RQTAE_W4zYdJlR6aRmzSVhjT80-h3VIfU6oz4DdPcu1COE603poXAwZZwbjxVz7SdY15e4W-G1rSf0GdaX0RhwIQ3SCH7giErHIWSqvBbBvd6sPUBCVgz8GihsOSy95wrKgqRwkP1RYUlrR7BxEExDGXAZfVBPT9U9rVFnj_5OfLaLDSope-ENe1fImfSvHG_YxuUfNYgYDkt_iwJ_fZOtnZN1YoVk04CYKPxemoL3vhDb70jPfCUsYujJYeOzdApu63nJPpw4t6Tw043CpVLDWu8TlmMjPVFnxTViBUWTQ5wk_Pi0H5Nuy4H23usZTaF7MUXZg9a6b_T9AUCYLalA1Q9hnZhE4-tf0fhSz_F-yahMY8vdcF4gp3FLrysZMZxL9ntqnmBbG2_s0X17adoEfSrFfVbE4396BHDBbGmhhJ8ExSaYjLeWnoPlGjLWBxsOMuqnvRdUcml6BWDDkiusX6JgGH1EAJ9vl43dmYTwMdo_xNS9T4RfzHvHIfREZfOgUYalTU9UWYsw7Vnd1mM-CaC8mxVvfTmPX2HDu78BxDQeUkI1Yr40DBz3Ksj8shOu9Qcdt8vWGmLWkSXnbM8Yb1Yzi1NCx6stye_S25D94XuMWaXUErG8gua7KVULH7-4SOnZ9xQCza5-r-R8boJnclvGWaxk69gwjFE--isLStSMqZ7w-_wXwcFSsS5V0-wwKqlroqAX7fqzrw=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["print('ACL prediction values: train 3 oris, valid 3 oris, test 3 oris')\n","print(np.array(predslist_ACL))\n","print(np.array(predslist_ACL).shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ACL prediction values: train 3 oris, valid 3 oris, test 3 oris\n","[[list([0.001057625, 0.9956304, 0.0014649852, 0.10609255, 0.006067098, 0.0033691446, 0.009125966, 0.00021953894, 0.00025437216, 0.0054137125, 0.017695615, 0.05560858, 0.04184516, 0.084910415, 0.0036287094, 0.070385285, 0.013959859, 5.4142356e-06, 0.95615065, 0.054029137, 0.06766702, 0.0009817217, 0.0073269075, 7.367659e-05, 0.0019456818, 0.00010642096, 0.0024543295, 0.018031355, 0.01651568, 0.3127834, 0.0019737387, 0.00036177604, 0.006587421, 0.000115697374, 0.035576295, 0.005240455, 0.022196058, 0.9912947, 7.245637e-05, 0.0050794347, 0.003932356, 0.00016025078, 0.2022345, 0.27289587, 0.00059744925, 0.0021018132, 0.9958682, 0.004167748, 0.003395042, 0.9971834, 0.0034349766, 0.0093552675, 0.0022203363, 0.00032495713, 0.09394123, 0.00019477858, 0.0011986769, 0.004269341, 1.2618831e-05, 0.9999347, 9.756829e-05, 0.00208196, 0.993174, 0.0037781529, 0.00021775464, 0.0014450606, 0.00095682114, 0.011020652, 0.08001484, 1.4154802e-05, 6.0639602e-05, 0.9756771, 0.9968676, 0.005825146, 0.0032581342, 0.0075100767, 1.1874522e-05, 0.00018073195, 0.13115604, 0.029789511, 0.99613816, 0.027394345, 0.0037271865, 0.03326769, 0.00025542325, 0.008147509, 0.004271675, 0.98957425, 0.25611234, 0.0031142104, 0.42065924, 0.28897223, 0.0041797743, 0.005145061, 0.0035673364, 0.46584347, 0.019314349, 0.0010261056, 0.044284612, 0.0003485863, 7.733533e-05, 0.95499104, 0.113558255, 0.0009287945, 0.05855692, 0.98498034, 0.0014963377, 0.01038211, 0.030596495, 0.99977523, 0.0006110954, 0.04233109, 0.9814855, 0.9991283, 0.002209669, 0.26646292, 0.3933412, 0.0011624498, 0.002552393, 0.029683992, 0.0057773725, 7.942904e-05, 0.018353786, 0.023358965, 0.000846231, 0.0006041627, 0.99163204, 0.009401014, 0.04210653, 0.07583766, 0.99807906, 0.00071125, 9.089276e-06, 0.011705911, 0.000812681, 0.99878746, 0.02900104, 0.005890932, 0.9935861, 0.059653915, 0.9990526, 0.017232252, 0.052111723, 0.0021103546, 0.0001460545, 0.0028945133, 0.002715113, 1.4643166e-05, 0.006274747, 0.036618058, 0.92474186, 0.00038484106, 0.012702953, 0.0016261967, 0.023536928, 0.013218286, 0.007064287, 0.0035586958, 0.9833543, 0.0406972, 0.00024348088, 0.013752858, 0.0073700314, 0.068888016, 0.9715939, 0.0016156591, 0.68153965, 0.0139298225, 0.99600357, 0.01608408, 8.431608e-05, 0.9945529, 0.0042473977, 0.00024576308, 0.8551953, 0.011050493, 0.93718016, 0.010559741, 0.9855843, 0.9850941, 1.0817435e-05, 3.7440062e-05, 0.013579027, 0.2738506, 3.0026367e-06, 0.9958103, 0.0401642, 0.0016249331, 0.9994148, 4.481118e-05, 0.029544456, 0.998796, 0.18802042, 0.9979577, 0.3911225, 0.0007531278, 0.0006228375, 0.1917873, 0.999736, 0.000115514384, 0.008571158, 0.9960795, 0.0024481274, 0.04371993, 0.0031640234, 0.9995722, 0.0011378375, 0.011947755, 0.9930016, 0.0013223069, 0.002668317, 0.0012119054, 5.8322294e-05, 8.317713e-06, 0.030963209, 0.99811316, 0.0037247525, 0.0035970907, 0.0077942237, 0.00035052816, 3.5963185e-05, 0.0002298915, 0.10140389, 0.011947558, 0.009484495, 5.3063537e-05, 0.00010973458, 0.0026800318, 3.345663e-06, 0.048304856, 0.00010266652, 0.026983231, 0.11264121, 0.08119426, 0.0002193703, 8.434125e-05, 0.97708625, 0.0010117366, 2.2762195e-05, 0.00010427477, 0.001446867, 0.030139025, 3.992772e-05, 1.087281e-05, 0.0024845565, 0.10991199, 0.023176745, 0.003521693, 0.9955136, 0.027343178, 0.00030906062, 0.0044427915, 0.011709442, 0.99096584, 0.03147668, 0.8082917, 6.126929e-05, 4.3976226e-05, 0.00037957792, 0.9390274, 0.029838806, 0.003776599, 0.013921081, 0.016797157, 0.94453317, 0.98550004, 0.9698057, 5.0444254e-05, 0.053589255, 0.017906584, 0.9967834, 0.28259194, 0.0041523753, 0.022579491, 0.02444539, 0.9942762, 0.00027931796, 0.00018005272, 0.34479427, 0.0054788715, 0.00039237758, 0.49155256, 0.9795654, 0.07040958, 0.001760773, 0.9952341, 0.9998286, 0.0006998369, 0.016463574, 0.0023776304, 0.005112737, 0.0019031715, 0.00020009682, 0.046055716, 0.11469853, 0.00017706901, 0.0020959186, 0.016565586, 0.9826493, 0.00036588043, 0.057114676, 0.21103203, 0.9958275, 0.99387956, 0.031520583, 0.9996195, 0.0012247011, 0.016447036, 0.9851736, 0.98471975, 0.51477885, 0.9545959, 0.967227, 0.9527015, 0.9932707, 0.9973584, 0.94766784, 0.97451586, 0.9931068, 0.9944853, 0.9936593, 0.99960417, 0.9701423, 0.99961555, 0.97869146, 0.9985642, 0.16069157, 0.015145829, 0.97742313, 0.99987006, 0.007999471, 0.9543769, 0.15962116, 0.007531599, 0.00021417078, 0.00015827616, 0.0019400395, 0.0032530557, 0.039206553, 0.0006740903, 0.0039201565, 0.00028865816, 0.0038253448, 0.040074334, 0.006806903, 0.0003038974, 3.5442303e-05, 0.036541574, 0.013269104, 0.00238076, 0.00030750816, 0.0055048084, 0.0044893925, 0.00027600498, 0.004463248, 0.90724957, 0.005791232, 2.5223353e-05, 0.17558937, 0.009306988, 0.087934725, 0.043568987, 0.055550512, 0.005762847, 0.0021988018, 0.0011600163, 0.9998734, 0.0020346108, 0.99813735, 0.0037157251, 0.37412804, 0.083517976, 0.0009747253, 0.043222103, 0.9970577, 7.782991e-05, 0.002005805, 0.0001213868, 0.0010085084, 0.0003600916, 0.99945956, 0.014139872, 0.14653654, 0.012037812, 8.174164e-05, 0.029014833, 0.07230952, 0.00019366469, 0.00038313487, 0.00047935138, 0.98817897, 0.28292388, 0.9986418, 6.6670036e-05, 0.022979163, 0.00533513, 0.001334282, 0.0011903992, 0.026789857, 0.023507997, 0.005642941, 0.00096670224, 0.036904074, 0.00028839576, 0.00033980855, 0.005279215, 0.0053426274, 0.0056219683, 0.058263306, 0.008772766, 0.00011529671, 0.00015269144, 0.0067934887, 0.00017260695, 0.0017430509, 8.6263635e-06, 0.003629992, 0.019830946, 0.000401061, 0.09348861, 0.0055400995, 0.72260493, 0.0055114743, 0.053985372, 0.0042322325, 1.8555093e-05, 0.0007149619, 0.97955096, 0.0004187392, 0.019090291, 0.0005424773, 0.0036282456, 0.011705343, 0.022887953, 0.0006636461, 0.0036759702, 0.00758312, 0.004092007, 0.90099543, 0.025921797, 0.03364288, 0.0058708433, 0.006647996, 0.00020387961, 0.023387777, 0.023659388, 0.009495409, 0.9976775, 0.9992317, 0.0011661069, 0.025451077, 0.00011282222, 0.016832348, 2.0998772e-05, 0.0019216596, 0.0002070809, 0.91921437, 0.04742403, 0.9955349, 0.0018944083, 0.0077612083, 4.9848313e-05, 0.00049889716, 0.62643665, 0.2050612, 0.0017591572, 0.0005530253, 0.00033868063, 0.002237009, 0.9818564, 0.024896592, 0.9999596, 2.0854006e-05, 0.00033964272, 0.13045889, 0.0010356057, 0.0014556132, 0.0007807971, 0.039924033, 0.0013378067, 0.0011304633, 0.0019633977, 0.0012258728, 4.4597808e-05, 0.0023414777, 7.0144284e-05, 0.9834925, 0.00028903244, 0.9982889, 0.4216621, 0.0035857519, 0.0015677395, 9.319066e-06, 0.11446504, 0.9996985, 0.016908318, 0.00018446647, 0.0035227204, 0.99801046, 0.0010297461, 0.0017692423, 0.9995358, 0.038989276, 0.028920503, 1.9502027e-05, 0.29793262, 0.98325056, 0.0013434637, 0.0051520704, 0.00011944938, 0.0001106959, 0.0037182732, 0.004463563, 0.99727505, 0.0003303174, 0.0053140474, 0.00056227884, 0.9794658, 0.009773127, 0.041441035, 0.99954164, 0.9947029, 0.9630452, 0.024795767, 0.0002955215, 2.7618269e-05, 0.000677456, 0.99879056, 0.9999845, 0.003052356, 0.06578476, 0.003987609, 0.0027936127, 0.0019047655, 0.0023172982, 0.00039259795, 0.00044570206, 0.0034401875, 0.0033250519, 0.97696596, 0.002841615, 0.0017467346, 0.012180855, 0.018951777, 0.0014199865, 0.005199059, 0.072691634, 0.111393884, 0.003108862, 0.014868133, 0.058376644, 0.99135923, 4.039406e-06, 0.99997306, 0.026615841, 0.98790205, 0.014471595, 0.9959848, 0.0005077745, 0.99699867, 0.015696296, 0.11690313, 0.0005890732, 5.036547e-05, 0.030341689, 6.1810664e-05, 0.0023760984, 0.36407518, 0.0001197015, 0.002249788, 0.0023018618, 4.1454452e-05, 0.001976405, 0.0013229633, 0.0026964545, 0.001454592, 0.0062077637, 0.035441354, 0.0023522738, 0.059275005, 0.018564746, 0.031224279, 0.99870265, 0.00019447481, 0.0059679304, 0.015735315, 0.09309429, 0.0053398535, 0.00058699446, 0.0014354241, 0.014231587, 0.37067753, 0.0035150407, 0.013972118, 0.013347088, 0.00063514005, 0.00588268, 0.014121889, 0.999959, 0.056503493, 0.00030987195, 0.058623962, 3.9849052e-05, 5.957868e-05, 0.009043146, 0.014728227, 0.020928705, 0.9966054, 0.0065430976, 0.00016012508, 0.00095798826, 0.9979265, 0.05089592, 0.34564832, 0.013170246, 0.0026045486, 0.0010589972, 0.055493377, 0.0002646193, 0.9990195, 0.9909604, 0.018214537, 0.0021357962, 0.0027070849, 0.9986071, 0.0045764702, 0.0020883875, 0.00026185307, 0.08979812, 0.0026734027, 0.009435438, 0.9863137, 0.10253141, 0.0017843609, 0.007166272, 0.057929944, 0.0013471736, 0.0009233131, 0.0016134046, 0.0046554613, 0.989253, 0.010987383, 0.003560531, 0.07375798, 0.0057674823, 0.9999926, 0.022582885, 0.00048821303, 0.03157063, 0.0059244297, 0.0014986256, 0.99205387, 0.01078329, 0.99034846, 0.015530907, 0.10313581, 0.014851478, 0.0051057055, 0.00021293749, 0.008477821, 0.96770746, 3.388587e-05, 0.003927421, 1.739898e-05, 0.0020039454, 0.0153206065, 0.00599425, 0.04791237, 0.000624254, 0.0008109273, 0.9994204, 4.7241716e-05, 0.08790241, 0.014036322, 0.00026928782, 0.0001007382, 0.98837876, 0.11659208, 0.024757857, 0.0040444112, 0.022260604, 0.032128133, 0.01514935, 0.010941063, 0.9746765, 0.007853337, 0.025712548, 0.007498453, 0.9971726, 0.013790421, 0.0038949912, 0.037951905, 0.9992229, 0.029213073, 0.000118299184, 0.000560838, 0.039413, 0.99522805, 0.002605618, 0.00070382585, 0.0004517671, 0.99917895, 0.0024804992, 0.018192336, 0.022730095, 0.0085410355, 0.0025386359, 0.017933663, 0.0036780215, 0.0020324257, 0.9940103, 8.193581e-07, 0.0019736062, 0.063189, 0.984009, 0.0018174648, 0.19093303, 0.0010037214, 0.00096537406, 0.118340485, 0.0040782546, 0.9980773, 0.99276614, 0.99208647, 0.85801643, 3.3358723e-05, 0.010116651, 0.01099255, 0.0031552538, 0.9574543, 0.0045881565, 0.2102689, 2.1638465e-05, 0.0037787524, 0.0009876348, 0.96005225, 0.00039673818, 0.0018986162, 0.07969001, 0.037409153, 0.99744475, 0.0044920063, 0.037514027, 0.008663314, 0.0013606715, 0.99543285, 0.008846502, 0.0007121422, 0.0020244766, 0.06524194, 0.006141843, 6.6681794e-05, 0.9792722, 0.04795254, 0.0011692301, 0.001871841, 0.00013060929, 0.013593431, 0.008456575, 0.046743076, 6.831881e-06, 0.99654835, 0.0029194537, 0.9876479, 0.0026878945, 0.014650205, 0.004304361, 2.5429563e-05, 0.31455803, 0.04959834, 0.009276976, 0.0068820696, 0.011308752, 0.993755, 0.00037794295, 0.0011300967, 0.9326719, 0.016459798, 0.99178517, 0.0030065118, 0.0024208652, 0.9862352, 3.261441e-05, 0.1701725, 0.0002467146, 0.0019449206, 0.000109987996, 0.08370106, 0.00013820599, 0.9893127, 0.0028712484, 0.0041738204, 0.9864673, 0.99994767, 0.0007802816, 0.0014504795, 0.00093048095, 0.0029869173, 0.00028235532, 0.00030740965, 0.0132778855, 0.9997609, 0.010567198, 0.00032799336, 5.0497918e-05, 0.00014202959, 0.002252112, 0.009741899, 0.00040817095, 0.02298375, 0.9972519, 0.00047447011, 0.9998196, 0.023520527, 0.985691, 0.009138961, 0.12401902, 0.040804133, 0.0013746662, 0.9995067, 0.014939344, 0.020278601, 0.0014559951, 0.0015675141, 0.0018110754, 0.0029120937, 1.7017639e-05, 0.004398503, 0.0013542429, 0.00023736016, 0.00034288602, 0.0024298204, 0.027519325, 0.00014134408, 7.1127775e-05, 0.00028328152, 0.0022680105, 0.006623508, 0.0070163747, 9.996911e-05, 5.6473695e-05, 0.0011049554, 0.9993148, 0.0058896914, 0.0004954545, 0.014081774, 0.9999461, 0.005041842, 0.00058375736, 0.009703875, 0.9920536, 0.026108576, 0.20579533, 0.0042753736, 0.008052821, 0.0032883172, 0.019346284, 0.10266623, 7.4880925e-05, 7.025916e-05, 0.0031530184, 0.0021732976, 0.0015226926, 0.0031105354, 0.014342159, 0.006363209, 0.0033925488, 8.3701554e-05, 0.0021043231, 0.9960341, 0.99350476, 0.9173773, 0.0023352404, 0.0018822441, 0.00076771475, 0.053972945, 2.3806573e-05, 0.010663009, 0.19216946, 0.062335316, 0.00042849878, 0.9965513, 0.9867221, 0.00055684894, 0.0016503909, 0.009554583, 0.00029312962, 0.14003918, 0.009887629, 0.015070038, 0.00022703556, 0.00048007755, 0.99855787, 0.0020923892, 0.0001510948, 0.0012125323, 0.0006056599, 0.00021221714, 0.09431761, 0.00053689064, 0.0013645405, 0.0021455195, 0.0052001467, 0.14990231, 0.012113651, 0.025461508, 0.013706536, 3.850701e-05, 0.001187277, 0.02459853, 0.003456106, 0.99932206, 0.008025223, 0.99418455, 0.06969344, 0.0005155268, 0.0179915, 0.9999902, 0.01619722, 0.0021676074, 0.9994948, 0.9904985, 0.9791549, 0.0052380366, 0.018367914, 0.0032833775, 2.8157308e-05, 0.9991472, 0.99989164, 4.2967844e-05, 0.015245729, 0.00079590623, 0.97727865, 0.9790025, 0.0006390212, 0.03928438, 0.996664, 0.00010623408, 0.34307837, 0.0043411395, 0.06865056, 0.07195897, 0.31715304, 0.00073035125, 0.01666533, 0.9195568, 0.009150658, 0.00022784834, 0.9885938, 0.9833583, 0.4677879, 3.9740327e-05, 0.044681143, 0.00019998946, 0.0011856859, 0.0010631431, 0.0024615033, 0.9988171, 0.0020067722, 2.947625e-05, 0.00011550028, 0.0013827526, 4.1618878e-05, 0.00203424, 0.99617356, 0.0004619212, 0.00054382073, 0.020562539, 0.00014736922, 0.9754926, 0.98844415, 0.0015851137, 0.0026305153, 0.0001173872, 0.0061806855, 0.0022281064, 0.024122871, 0.93985206, 0.99607134, 0.30256838, 0.0011730985, 0.0021171153, 0.004696589, 0.0022362012, 0.0052156853, 0.10563098, 0.064158514, 0.00074501475, 0.03853758, 0.0045493217, 0.00014051133, 0.0010665053, 0.07485554, 0.07433526, 0.021304302, 0.0016921624, 0.014136622, 1.9569974e-05, 0.0010962615, 0.9993661])]\n"," [list([0.0025187954, 0.9992244, 2.6476422e-05, 0.68981737, 0.0027520626, 6.4479786e-06, 7.273223e-05, 0.00013546097, 0.03838386, 0.011056227, 0.0004702931, 0.00744925, 0.0008181433, 7.324067e-05, 0.0020059578, 0.0021426587, 0.00038283752, 0.0012543991, 0.8028954, 0.009572704, 0.22942139, 0.006437709, 0.0018845209, 6.0139162e-05, 4.9341033e-05, 0.0005605577, 4.927652e-05, 0.0057113445, 7.652565e-05, 0.055746775, 0.00250956, 0.020032965, 0.003749547, 0.00014920297, 8.301429e-05, 0.000961736, 0.032710537, 0.9807812, 0.0023675256, 0.015155506, 0.026586263, 0.00037898874, 0.036480278, 0.5387541, 0.013703772, 0.0005628239, 0.9993443, 0.011272444, 0.00024879188, 0.98091817, 0.016985875, 0.004747229, 3.650558e-05, 7.826299e-05, 0.006277275, 2.1899312e-05, 0.0010452236, 0.00069968146, 0.024258083, 0.9981213, 0.0042070313, 1.4360356e-05, 0.82074434, 0.0001394139, 0.005158982, 0.009149495, 0.00088061334, 0.0017967279, 0.0053423187, 0.001805712, 0.0007764909, 0.93732876, 0.99541533, 0.0060662697, 0.00028848072, 0.010355947, 0.004992, 7.330562e-06, 0.053171083, 0.07447406, 0.9549928, 0.025323195, 0.00010387709, 0.034106348, 0.0004596519, 0.00058822014, 0.0010878667, 0.7557207, 0.08448418, 0.0006794889, 0.2271595, 0.18690458, 0.0003484092, 0.00058433827, 0.12910487, 0.0029112133, 0.00018031627, 0.00012123932, 0.0022317031, 7.977207e-05, 0.0051102904, 0.9973506, 0.037769306, 0.0019894738, 0.0022022026, 0.89841866, 0.00062989636, 0.0019665596, 0.005821386, 0.994419, 0.0035792137, 0.068104655, 0.9982102, 0.97773755, 0.00022386864, 0.0319234, 0.019454706, 0.009651124, 0.0026524728, 0.019214205, 0.010537763, 0.33432844, 0.06381664, 2.2802538e-05, 9.35563e-05, 0.001121286, 0.6803897, 0.0011831586, 0.001200329, 0.0062153726, 0.9650239, 2.0152742e-05, 3.185257e-05, 0.021452485, 0.00030681645, 0.9570445, 0.0025619015, 0.00023919511, 0.96716213, 0.017548071, 0.9849754, 0.014283297, 0.16763115, 0.0026113568, 4.9976356e-05, 0.026124733, 0.009020117, 7.94689e-05, 0.008443826, 0.00021856045, 0.948771, 0.012116584, 0.0809979, 0.0038720237, 0.0027122367, 0.0019356407, 7.545458e-05, 0.0025280493, 0.9731809, 0.17056377, 0.006291494, 0.0077267666, 1.5223265e-05, 0.008104222, 0.72465736, 0.0006808401, 0.5761564, 0.03219668, 0.9261797, 0.0014650535, 0.0056679756, 0.9983015, 0.009629567, 0.0026888342, 0.93081063, 0.007985044, 0.90144634, 0.005526059, 0.9739697, 0.97123957, 0.0012393342, 0.00047969213, 0.063386, 0.0069576944, 0.000114905204, 0.9985618, 0.0019437723, 0.030954577, 0.96522486, 0.0032123162, 0.00030365383, 0.91459733, 0.00438961, 0.98765963, 0.36308315, 0.00010331923, 1.21017165e-05, 0.05421934, 0.890373, 0.02662488, 0.0055639856, 0.9944689, 2.396073e-06, 0.21695212, 0.0005121571, 0.99687696, 0.003416183, 0.004809883, 0.9780513, 0.00045739964, 0.00042075606, 0.0010870243, 0.0010272058, 0.013728748, 0.00010146928, 0.96378773, 0.009239357, 0.03204833, 0.0005925058, 1.9701465e-05, 0.0013640819, 0.00017437067, 0.0059548956, 0.019299664, 0.00023486494, 0.00024416693, 0.16382223, 6.407522e-05, 0.00010556981, 0.0012316339, 0.00012292166, 0.01603645, 0.0289991, 0.4061918, 8.8432265e-05, 0.0011077251, 0.9422549, 0.008974163, 0.00043101702, 0.0008591687, 0.004897096, 0.004517114, 0.0014862685, 0.0051945723, 0.00023844074, 0.0036557019, 0.0022407935, 0.0027468905, 0.98926187, 0.0047145416, 0.000107818814, 0.012862954, 0.0141568985, 0.99576294, 0.065639116, 0.9761873, 0.01562446, 0.0014940341, 0.00076642097, 0.9895551, 0.011976267, 1.9648196e-05, 0.06080731, 0.015377783, 0.8150327, 0.9921663, 0.9487937, 9.381404e-05, 0.013252302, 0.16959445, 0.8024987, 0.021676503, 0.00014131377, 9.870962e-05, 0.00022201972, 0.988472, 0.0017533121, 0.00033446186, 0.032026887, 0.00011733371, 0.0034392981, 0.4483697, 0.9210981, 0.008847526, 2.5728375e-06, 0.99960285, 0.9980171, 0.004195413, 0.0031154174, 0.00092420285, 0.00078045746, 5.2411862e-05, 0.00018267725, 0.089717366, 0.0024115867, 0.008439304, 0.00014906174, 5.2448864e-05, 0.8915828, 0.003910488, 0.0010180101, 0.0008028077, 0.9877857, 0.8949312, 0.0057747085, 0.978744, 0.010736585, 0.00032180725, 0.852503, 0.9162096, 0.95573133, 0.9765132, 0.9995209, 0.9521142, 0.8629323, 0.94499296, 0.9919154, 0.98023844, 0.980243, 0.8899278, 0.95025676, 0.9991392, 0.905538, 0.99745935, 0.66164124, 0.9902852, 0.43715265, 0.0036892442, 0.89506966, 0.9988096, 0.0006297541, 0.9626215, 0.10411565, 0.00068290206, 0.0015844421, 0.0010927202, 4.6839912e-05, 9.650377e-06, 0.00015089913, 0.0026504856, 0.024300601, 0.017018333, 4.9995753e-05, 0.0010284976, 0.13558666, 3.6082029e-06, 0.0030605001, 0.00026728833, 5.785063e-06, 0.21594526, 0.0006194958, 0.002858568, 0.00039312465, 0.0059962245, 0.014662471, 0.6711652, 0.0036753262, 0.0071021826, 0.026449641, 2.5288598e-05, 0.16499881, 0.042076923, 0.00023989813, 0.0019564629, 0.005554485, 0.00057257526, 0.9995603, 0.0026161713, 0.9885145, 0.0053988406, 0.016950171, 0.08661196, 0.00019335895, 0.04294582, 0.8887031, 0.012255553, 0.0010500101, 0.002014321, 0.0049701342, 0.08739282, 0.9983741, 0.0019677877, 0.010351589, 0.00617053, 0.000578154, 0.0010593206, 0.03822487, 0.003674118, 0.0007037997, 0.0015568726, 0.95091724, 0.008220016, 0.9951675, 0.00301846, 8.896488e-05, 0.012044442, 0.0002273358, 0.0039045897, 0.00046607974, 0.003095902, 0.0025977523, 0.00018308478, 0.0004019151, 0.00032030986, 0.0018985972, 0.0010091974, 0.0112548405, 0.006950223, 0.15830131, 0.00091920677, 3.1038984e-05, 0.0009320537, 0.012150278, 0.00024279609, 0.0032216695, 0.000725616, 0.0004635226, 0.09148166, 1.975761e-06, 0.0021198047, 0.004352126, 0.98527354, 0.00031475228, 0.057930525, 0.0018910925, 0.0009866172, 0.020296274, 0.93957275, 0.057349846, 0.018919019, 0.0096042305, 0.012383155, 0.27043584, 0.0029911248, 0.028611537, 0.0059009455, 0.0013667971, 0.0022403246, 0.4239805, 0.0054339124, 0.10412653, 0.001278369, 0.004057156, 7.025789e-05, 0.010322574, 8.012826e-05, 0.0018546237, 0.97969395, 0.99871695, 0.0031191604, 0.0026170039, 0.0036522022, 0.014985024, 0.00053276407, 7.433892e-05, 1.0062217e-05, 0.6483957, 0.037079774, 0.9803538, 0.12420986, 0.0016378813, 0.029959913, 0.009395519, 0.07734965, 0.032026928, 2.9838406e-05, 0.0031253821, 0.0004947631, 0.0002276119, 0.9372896, 0.12271114, 0.99679345, 0.00046938058, 0.0108655, 0.0004719552, 0.002653433, 0.0074467827, 0.0024138924, 0.0009799537, 0.02059103, 0.00076088525, 0.005934314, 0.00049379515, 0.0051827757, 7.326784e-05, 0.0017292835, 0.88985896, 0.0018034583, 0.9988951, 5.142946e-05, 0.012708825, 0.0003313421, 0.009340681, 0.008405713, 0.9255385, 0.013585382, 0.0030704075, 0.009418052, 0.9945294, 0.006825141, 7.6229444e-05, 0.93348914, 0.0035410326, 0.002547577, 0.00016965969, 0.21840215, 0.96056706, 0.0016890615, 0.00021005225, 0.0034101363, 0.012343947, 0.013089337, 9.559989e-05, 0.95277774, 0.006794442, 0.00094228605, 0.007579375, 0.9450684, 0.33555147, 0.0020254152, 0.99942446, 0.89253604, 0.9605629, 0.0029530576, 0.021914909, 0.0008500293, 0.00074570626, 0.9878071, 0.998665, 0.028775541, 0.016490502, 0.0078908615, 0.12592238, 0.00024028272, 0.0018425129, 0.00028288318, 0.0001535785, 0.0005750692, 0.0014631998, 0.953526, 0.022446405, 0.0016325822, 0.003023754, 0.14269176, 0.007831853, 0.033326905, 0.0007398651, 0.18241875, 4.7970258e-05, 0.0005059051, 0.014708414, 0.9866817, 0.0012592466, 0.985388, 0.0053030113, 0.9653503, 0.00060370564, 0.98858076, 0.00022977382, 0.864055, 0.025829304, 0.5258141, 1.9942137e-05, 0.0024105993, 0.0137614235, 0.00082204165, 0.022362467, 0.013667205, 0.0005253001, 0.0008566146, 0.0059634005, 0.0011293832, 0.047653973, 0.013460194, 0.0006986993, 0.00068243063, 0.008023376, 0.07887096, 0.00028361147, 0.4093492, 0.03634871, 0.0025734724, 0.9999509, 0.0001865316, 0.023055283, 0.63720024, 0.022587258, 3.3364737e-05, 0.015563508, 0.059632543, 2.6544356e-05, 0.21878801, 0.0011304714, 0.0036427022, 0.03335452, 0.0063910577, 0.06796486, 0.00032538714, 0.9904419, 0.014423646, 0.0014872574, 0.00013244298, 0.00030486664, 0.00036529562, 0.023383847, 0.004246986, 0.0010467482, 0.99689096, 0.0027625572, 0.00023550131, 0.00062095205, 0.95727694, 0.0012210645, 0.027473908, 0.0013643749, 6.0035967e-05, 0.006850977, 0.0011344337, 0.00028007932, 0.9858701, 0.8387038, 0.01564006, 0.00088156207, 0.030230854, 0.9928899, 0.064819306, 0.00047840943, 0.0028124845, 0.08380043, 5.0862174e-05, 0.0042090616, 0.99856406, 0.0096768215, 0.0012809461, 0.1122922, 0.0022579527, 0.03864174, 0.06849125, 0.00011287787, 0.03432713, 0.8055798, 0.0018515165, 0.011181273, 0.002379956, 0.021628816, 0.99140537, 0.045509905, 0.011002384, 0.09109258, 0.018059922, 0.0003613366, 0.96835536, 0.0069364505, 0.9903482, 0.005364357, 0.00020867088, 0.008018879, 0.0032196399, 2.7052502e-06, 4.608224e-05, 0.91696876, 0.0002909484, 0.0002921169, 0.0004931011, 2.2394226e-05, 0.002243358, 0.037096802, 0.0027918546, 0.016662594, 0.00022149534, 0.9972518, 0.0041288575, 0.03484746, 0.22231415, 4.9107028e-05, 5.9181228e-05, 0.9476499, 0.018847004, 0.0001327815, 0.020562356, 0.0011057594, 0.005404223, 0.000745938, 0.008938643, 0.98632693, 0.00075255963, 0.00018966063, 0.0047197333, 0.9810699, 0.007190455, 1.0436648e-05, 0.0037100383, 0.77024615, 0.018089982, 0.004322824, 0.0008594655, 0.076193154, 0.9721744, 0.0027005686, 0.003973983, 8.650625e-06, 0.99567974, 2.8438855e-05, 0.002081991, 0.0023998567, 0.06331454, 0.001995735, 0.011349681, 7.534686e-05, 0.11465111, 0.87128544, 0.00034412608, 2.8244012e-05, 0.0060206275, 0.8736382, 0.001547713, 0.026130058, 0.00021571296, 0.0009875308, 0.21336082, 0.060434304, 0.98734576, 0.998738, 0.9706589, 0.862437, 1.9287607e-05, 0.0027710488, 0.0015520164, 0.0014432789, 0.6294577, 0.0024793267, 0.0003169139, 0.002748329, 0.0010504413, 0.006241981, 0.9311078, 7.619019e-05, 0.0059652943, 0.00060759945, 0.004570058, 0.9746473, 0.00089690764, 0.016838685, 0.00027487654, 0.0015250325, 0.94420904, 0.0022395998, 0.0033453908, 0.00048944895, 0.00097575894, 0.008339505, 3.219599e-05, 0.99314415, 0.001068463, 0.016205624, 0.012103235, 0.0013520785, 0.00024859555, 0.00019044729, 0.04421005, 8.8791814e-05, 0.9737246, 0.0008143034, 0.9393311, 0.04597703, 0.0020614883, 2.538969e-06, 0.00044064238, 0.03975524, 0.0013072392, 0.08282755, 0.0003056329, 3.5671692e-05, 0.9320833, 0.01789379, 8.955859e-05, 0.98163176, 0.0031075412, 0.992953, 0.041879456, 0.00022019657, 0.9961331, 0.0016298566, 0.037958775, 1.1085531e-05, 0.00051429437, 0.043737788, 0.005930462, 0.0010345186, 0.9785986, 0.010094775, 0.005690543, 0.90603787, 0.39071408, 0.0054673404, 0.00037885003, 0.0011981113, 0.0018573799, 0.011234371, 0.11245919, 0.008185143, 0.9537, 0.00070331595, 0.00060648855, 5.48347e-05, 0.006863566, 0.0017127978, 0.002400293, 0.0023158125, 0.0026339854, 0.98720443, 0.0003925609, 0.9853645, 0.0005464835, 0.8220729, 0.015993351, 0.0018228836, 0.012054863, 0.00046802816, 0.98363876, 6.129524e-05, 0.000527011, 0.15135966, 0.0004892449, 0.008195434, 0.05354197, 3.2784046e-05, 0.004657475, 0.00042287578, 0.02843315, 0.0032752014, 0.0046485527, 0.012316542, 0.00029036702, 0.0011470272, 0.008705897, 0.0151379, 0.084704235, 0.0146116605, 3.822601e-05, 0.00011206716, 0.0021349897, 0.9674443, 0.00020378943, 4.0805215e-05, 0.031128434, 0.96141493, 0.05383303, 0.02476203, 0.0002642759, 0.9923883, 0.1644012, 0.0011064754, 0.0039195907, 0.0013858553, 3.4593614e-07, 0.0009452281, 0.0006783039, 0.00187109, 0.0025589399, 0.0026023856, 0.11431766, 0.059285246, 0.0008686813, 0.07321928, 0.00018103309, 1.8694807e-05, 0.014690011, 0.0016978321, 0.95855486, 0.9988783, 0.8650583, 0.0054359, 0.00339933, 0.00014720167, 0.011625419, 0.0018764114, 0.0021652943, 0.005995145, 0.00090925046, 0.00014352787, 0.9862628, 0.3099516, 0.0003143651, 0.00010395121, 0.0010394958, 0.0018857232, 0.010917281, 0.070122585, 0.0003264168, 0.046377227, 0.010639332, 0.99783105, 0.0057056695, 0.022798669, 0.002119337, 0.0015428477, 8.907099e-05, 0.282554, 5.7752404e-05, 7.181752e-05, 0.0034128665, 0.014302605, 0.026501862, 0.0021103956, 0.0021397867, 0.010806596, 4.69844e-06, 0.003328516, 0.002137776, 0.0066145505, 0.9996038, 0.00077143434, 0.99865687, 0.025294753, 0.0007013421, 0.027662452, 0.91653824, 0.00071719097, 0.0005928792, 0.97401285, 0.961067, 0.9238723, 0.007425104, 0.0028753567, 0.0008035547, 0.00031168436, 0.97844326, 0.99620664, 0.0016012922, 0.022454139, 0.025343124, 0.9857838, 0.9780227, 1.6541264e-05, 0.00036260823, 0.9863127, 0.0010566924, 0.09780732, 0.01008661, 0.1722367, 0.0005101293, 0.0006726634, 0.0010826178, 0.0025877182, 0.9717229, 0.1777586, 0.0015219807, 0.99610823, 0.9396251, 0.0233616, 0.010086601, 0.024113584, 0.07711003, 0.00015046651, 0.0020470505, 0.04259944, 0.97154665, 0.00061602116, 0.002016244, 0.00015799208, 0.00019313967, 0.00028317486, 0.011640414, 0.9783442, 5.7920734e-05, 0.004817195, 0.00062839914, 1.527275e-05, 0.9261822, 0.99126464, 0.0031746514, 0.00040399868, 0.091116644, 0.0062123276, 0.004087057, 0.0011618265, 0.99817276, 0.9618323, 0.1472145, 0.0010990724, 0.004444068, 0.00034890368, 0.013673277, 0.011048382, 0.003906653, 0.0037966266, 0.00028949496, 0.053320892, 0.00058387173, 0.007535121, 2.5103294e-05, 1.8888582e-05, 0.042767756, 0.0016751159, 0.00036693658, 0.011243442, 0.0018627527, 0.0004988109, 0.8460798])]\n"," [list([0.14439446, 0.9982048, 0.001732745, 0.12690465, 0.0112305265, 0.01805712, 0.005283401, 0.001805646, 0.35627243, 6.8414905e-05, 0.0208186, 0.31094193, 0.008131156, 0.0055696, 0.03402418, 0.008683424, 0.013483534, 0.00011106693, 0.98398983, 0.005756015, 0.024148827, 0.0085283695, 0.13908501, 0.092246264, 0.00019950778, 0.0071551125, 0.0008040273, 0.012185159, 0.027102383, 0.06592775, 0.0016991857, 0.01993302, 0.057698388, 0.008212618, 0.044077974, 0.024517784, 0.5714613, 0.86580867, 0.0332336, 0.010292998, 0.13729581, 0.00023636511, 0.6300131, 0.9949803, 0.0016767165, 0.009373408, 0.9675608, 0.040406942, 0.37758967, 0.83939, 0.004849067, 0.5378745, 0.06614637, 0.026264518, 0.87502134, 0.0013322954, 0.008404823, 0.004937704, 0.14214523, 0.9997956, 0.0004668725, 0.0014073584, 0.8627515, 0.00161632, 0.00023015842, 0.012393347, 0.003192321, 0.040027402, 0.020034036, 0.0002825387, 0.03244767, 0.93604386, 0.9223504, 0.048595864, 0.04857435, 0.0071980255, 0.015540125, 0.00088910945, 0.78947353, 0.89138156, 0.76435417, 0.014315618, 0.0065599317, 0.44884166, 0.00017366116, 0.011091187, 0.0030110248, 0.613281, 0.07258334, 0.5354536, 0.7754676, 0.5000481, 0.008726646, 0.00022749908, 0.13687058, 0.063045666, 0.00015280272, 0.0017596806, 0.010240997, 0.08534282, 0.026157945, 0.9068205, 0.09715228, 0.0009326898, 0.0045670676, 0.9922246, 0.023357892, 0.1106024, 0.005677268, 0.97499985, 0.0011829806, 0.8530223, 0.9835302, 0.9883796, 4.2878895e-05, 0.7764223, 0.019897645, 0.0027094046, 0.036120318, 0.042578433, 0.016582342, 0.037731502, 0.32178372, 0.028212266, 0.012463003, 0.0016119812, 0.94495344, 0.1153105, 0.010670925, 0.25855064, 0.98689747, 0.041940764, 2.0349304e-05, 0.1424913, 0.0026526076, 0.58887136, 0.059669435, 0.007952792, 0.97747374, 0.030701675, 0.996476, 0.006946768, 0.3898673, 0.24722245, 0.10603774, 0.20940913, 0.01881215, 0.00081700005, 0.0005505479, 0.04512993, 0.93988776, 0.015919467, 0.09361584, 0.017939618, 0.48273286, 0.07079726, 0.00989891, 0.010554422, 0.91254944, 0.02803244, 0.028319832, 0.0029488166, 0.013099757, 0.67012805, 0.9781083, 0.013328866, 0.62085485, 0.19514513, 0.93420523, 0.0044928165, 0.005661726, 0.99348575, 0.28160796, 0.00047967938, 0.6959098, 0.11233399, 0.85648006, 0.012714271, 0.9887849, 0.82116103, 0.0055986843, 0.003753049, 0.15658604, 0.02704371, 0.0052801194, 0.99823064, 0.05790893, 0.010968698, 0.96720684, 0.011191584, 0.0337387, 0.98006195, 0.13122062, 0.98323566, 0.9306446, 0.009632069, 0.0024496873, 0.19877304, 0.99966943, 0.004998088, 0.01895066, 0.96769494, 2.6491174e-05, 0.055029605, 0.0020420018, 0.9646252, 0.0003263312, 0.008384762, 0.984026, 0.0001224091, 0.021213204, 0.0033779074, 0.00033063465, 0.03514649, 0.0095782755, 0.9894539, 0.015616314, 0.3007516, 0.03512422, 0.0027253274, 0.027991377, 0.008128457, 0.0025185056, 0.12730755, 0.07775181, 0.00011702587, 0.020685103, 0.01137182, 0.0011877764, 0.009771613, 4.8618283e-05, 0.14724186, 0.0011195686, 0.9240789, 0.011892224, 0.0002461167, 0.80460924, 0.12842415, 0.13153757, 0.014613342, 0.036389556, 0.0046947836, 0.0048724483, 0.0010300404, 0.011971425, 0.027308092, 0.0035183027, 0.030055668, 0.90100986, 0.06786643, 0.058276977, 0.095510036, 0.0040020454, 0.92721075, 0.07804477, 0.9612235, 0.029921664, 4.1848674e-05, 0.0061933477, 0.9706951, 0.06555174, 0.030918851, 0.18315838, 0.020248478, 0.9084254, 0.9764189, 0.9511962, 0.014962765, 0.10579911, 0.15953077, 0.89419395, 0.060102165, 0.08382186, 0.06870871, 0.0069892886, 0.9878493, 0.0007587818, 0.0020877367, 0.42277575, 0.00229258, 0.041462198, 0.67512566, 0.8874315, 0.00028619438, 0.08034101, 0.98930013, 0.9906709, 0.013858676, 3.7152838e-06, 0.00033509763, 0.009995247, 0.009785363, 0.0036109656, 0.271506, 0.28072473, 0.0062190318, 0.00027617687, 0.17923966, 0.9931722, 0.011622964, 0.024194831, 0.07441774, 0.9878656, 0.9604968, 0.26848963, 0.9995685, 0.043433532, 0.007017365, 0.9525417, 0.9367877, 0.9561722, 0.9699412, 0.9760045, 0.9534417, 0.88996875, 0.9823429, 0.9304622, 0.94217795, 0.9936336, 0.9935154, 0.99856645, 0.98487234, 0.7930214, 0.9991918, 0.94177705, 0.99236804, 0.09934668, 0.31554344, 0.733788, 0.96830577, 0.02525011, 0.9650048, 0.068713896, 0.050966576, 0.01580333, 0.032695636, 0.0024407418, 0.002217396, 0.015033793, 0.00060902216, 0.2628417, 0.0051402063, 0.006625431, 0.0037114257, 0.35674652, 0.00051396166, 0.002868945, 0.026106825, 0.04825001, 0.27193794, 0.004549041, 0.0022119947, 0.014870557, 0.0005365492, 0.015420808, 0.89752233, 0.0011154313, 0.00043965573, 0.0036031439, 0.0007756382, 0.13154742, 0.32427523, 0.09277055, 0.011676099, 0.000113349866, 0.013643392, 0.6801885, 0.39849657, 0.94696337, 0.40294278, 0.045473758, 0.01606186, 0.027361663, 0.11527222, 0.9270817, 0.009132163, 0.016604502, 0.064193495, 0.0010794521, 0.019036451, 0.93147266, 0.007871395, 0.4583397, 0.013510962, 0.04227347, 0.20957081, 0.38423303, 3.7068945e-05, 0.010065417, 0.043045323, 0.9662143, 0.11671625, 0.99718887, 0.0068488484, 0.0020715888, 0.097571, 0.05367993, 0.044623032, 0.071087964, 0.338798, 0.0141938, 0.038174145, 0.0090148505, 0.0069929464, 0.07960893, 0.18724607, 0.004507509, 0.014871989, 0.74126184, 0.022745077, 0.003931047, 0.012465176, 0.50472784, 0.0017572698, 0.019425288, 0.0025004558, 0.024437735, 0.12626743, 0.35069337, 0.011727026, 0.33930314, 0.9809816, 0.0015653812, 0.1607051, 0.3197804, 0.0002500506, 0.008761019, 0.9298931, 0.0021588586, 0.052097272, 0.01277233, 0.043038864, 0.5956829, 0.8634278, 0.00044243032, 0.03828171, 0.010852307, 0.004435845, 0.89351344, 0.00020505421, 0.0016186684, 0.021941215, 0.0008652073, 0.0020509048, 0.018967716, 0.009923269, 0.13699342, 0.99777824, 0.99587953, 0.14461635, 0.16680613, 0.038767904, 0.004369506, 0.0042616287, 0.0011928015, 0.0010479914, 0.9733008, 0.005116527, 0.994753, 0.17617117, 0.014514699, 0.016551074, 0.29151437, 0.10916875, 0.0135884695, 0.0004386155, 0.06454573, 0.039149128, 0.02165406, 0.92768466, 0.065686114, 0.9978124, 1.3661616e-05, 0.002822363, 0.0035048155, 0.00095331605, 0.0568183, 0.0050281207, 0.120694645, 0.0031611777, 0.026266305, 0.19364373, 0.3325116, 0.054908507, 0.0066246213, 0.016730743, 0.95461255, 0.001300888, 0.985142, 0.0091082435, 0.05475007, 0.07808781, 0.046103723, 0.0103726145, 0.97863, 0.009693575, 0.0037280684, 0.16572641, 0.9961653, 0.006070432, 0.062452912, 0.679339, 0.18600646, 0.0009553827, 0.00055308035, 0.1746155, 0.97081447, 3.880531e-05, 0.035150863, 0.00025928085, 0.00018775246, 0.009356942, 0.013992017, 0.9851341, 0.0250448, 0.07043745, 0.06278333, 0.99932325, 0.004352186, 0.16724634, 0.99699545, 0.727693, 0.6588399, 0.014299519, 0.005403559, 0.0045329374, 0.034678727, 0.7533024, 0.9915768, 0.029378776, 0.05240529, 0.003337971, 0.0018175003, 0.007369537, 0.0055759978, 0.09867932, 0.012210174, 0.03334862, 0.03986781, 0.8352652, 0.0010576805, 0.008774612, 0.0069624437, 0.32410493, 0.035179336, 0.00067375886, 0.084682465, 0.5767752, 0.008538003, 0.004392374, 0.17229766, 0.9390498, 0.0028034842, 0.9872946, 0.00022029021, 0.99339163, 0.04271238, 0.99783224, 0.05434462, 0.9882514, 0.047466625, 0.8098696, 0.0009671375, 0.088298775, 0.012284888, 0.004723614, 0.035638638, 0.39145207, 0.001646295, 0.00020807485, 0.00905085, 3.1505155e-05, 0.33433414, 0.007627044, 0.01604282, 0.0035630374, 0.010329386, 0.017550735, 0.00230028, 0.5682046, 0.18637976, 0.067687504, 0.9896079, 0.0020745343, 0.011035152, 0.25943688, 0.0050627836, 0.026836678, 0.011777149, 0.0035452517, 0.0079210205, 0.14809836, 0.07786408, 0.00525307, 0.00053755887, 0.024930572, 0.21776685, 0.0042147897, 0.9983253, 0.57814234, 0.0009816226, 0.003943404, 0.025982507, 0.033883177, 0.02354875, 0.12660061, 0.053821556, 0.9742664, 0.0008568753, 0.033036154, 0.31752533, 0.996899, 0.056728415, 0.23960026, 0.035237905, 0.0307717, 0.024199104, 0.0018487445, 0.0027683605, 0.999253, 0.9964546, 0.0038776982, 0.028326776, 9.5119765e-05, 0.99424213, 0.0008030343, 0.029696165, 0.0026703924, 0.72551733, 0.09409063, 0.11288659, 0.9948007, 0.101658225, 0.041669533, 0.021563435, 0.010908067, 0.00074351014, 0.0014210335, 0.004859619, 0.0005602676, 0.9532401, 0.0142770605, 0.13056801, 0.0072745346, 0.00031642333, 0.99754274, 0.19700062, 0.09884599, 0.0912303, 0.22807893, 0.0019878878, 0.96656734, 0.20894027, 0.9696951, 0.015380801, 0.12345453, 0.27282083, 0.021066219, 0.0004469084, 0.00022507057, 0.944954, 0.0026406466, 0.061869156, 0.0017340702, 0.006542465, 0.022747472, 0.055665467, 0.027579796, 0.0010563723, 0.33398855, 0.9940387, 0.032514513, 0.5618109, 0.34112152, 0.0011308921, 0.0010314048, 0.9924178, 0.1387189, 0.02994167, 0.20864809, 4.8848327e-05, 0.018557603, 0.0016870535, 0.00604079, 0.9052121, 0.014155966, 0.0030514621, 0.003977607, 0.97108567, 0.0064395787, 0.020370742, 0.071587175, 0.95133257, 0.5603744, 0.002286773, 0.068916164, 0.342137, 0.833096, 0.0030119752, 0.008880357, 0.05332084, 0.9718788, 0.00023836165, 0.003248132, 0.01816549, 0.31568238, 0.022558754, 0.05922971, 3.142291e-05, 0.035678837, 0.7777995, 0.0015713719, 0.0014914725, 0.024443101, 0.8602054, 0.026828004, 0.47956458, 0.006705397, 0.010259844, 0.17170326, 0.093932435, 0.9996942, 0.99935526, 0.98150015, 0.7216628, 0.012480958, 0.07204074, 0.019513318, 0.00085887325, 0.90107447, 0.0018096518, 0.13321187, 0.00033966088, 0.00039410198, 0.39544803, 0.4628289, 0.0007924285, 0.001954384, 0.16131005, 0.080303855, 0.9373098, 0.00029621454, 0.056634348, 0.06391215, 0.0032809034, 0.98838997, 0.0062451614, 0.015779858, 0.00023247174, 0.11399897, 0.29342416, 0.06487594, 0.9772784, 0.000600715, 0.013341979, 0.2393425, 0.00090345496, 0.008052726, 0.025899142, 0.45728728, 0.0014303534, 0.8919439, 0.007200217, 0.99197984, 0.110758506, 0.05522053, 0.0018794091, 0.020213159, 0.31380728, 0.09870139, 0.024637152, 0.00020996596, 0.022209574, 0.9919377, 0.067928724, 0.21623254, 0.70194185, 0.024625076, 0.9810878, 0.0011566828, 0.0016383288, 0.9990569, 0.0011665991, 0.0389652, 0.012639776, 0.0012764187, 0.0128869405, 0.37119272, 0.0009970949, 0.9467856, 0.006120843, 0.10705393, 0.987884, 0.97068465, 0.1612629, 0.039606914, 0.012400627, 0.0024316655, 0.48458195, 0.15943685, 0.105222605, 0.9756825, 0.092522494, 0.0011793723, 0.0013403262, 0.03362384, 0.02465791, 0.105184406, 0.00018574837, 0.18548927, 0.98853487, 0.019648792, 0.7693901, 0.089594215, 0.95386595, 0.4829252, 0.013875427, 0.4098991, 0.0013987435, 0.99996173, 0.0065633943, 0.01561224, 0.019786522, 0.0007341869, 0.045294214, 0.02613102, 0.00016562102, 0.011706192, 0.0032109092, 0.00022757784, 0.001398324, 0.011106794, 0.042838596, 0.05468482, 0.0065158717, 0.00419913, 0.0028526129, 0.055751394, 0.3765925, 0.00031085315, 0.0034995738, 0.013531175, 0.9649508, 0.05766589, 1.2943353e-05, 0.028956097, 0.99723476, 0.08678415, 0.00013617742, 0.031341653, 0.85043246, 0.10265905, 0.009960066, 0.0012043236, 0.078023195, 0.04566547, 0.0126631735, 0.006296436, 0.017210422, 0.016332412, 0.024717137, 0.00034629204, 0.08865091, 0.0007226531, 0.004720083, 0.0068796347, 0.011654945, 0.01010916, 0.007914863, 0.9709269, 0.9797742, 0.984815, 0.057284266, 0.0013670588, 0.011684521, 0.045963135, 0.014979887, 0.054717246, 0.54572886, 0.017128373, 0.024229437, 0.9760189, 0.9613975, 0.016664822, 0.0029165, 0.052609753, 0.00047728393, 0.118696816, 0.644614, 0.046821095, 0.10833413, 0.24481182, 0.93981415, 0.00031681242, 0.0005151844, 0.31027377, 0.035775006, 0.0065078326, 0.47432905, 0.00429419, 0.02615698, 0.0035990686, 0.052186713, 0.01301742, 0.11752406, 0.042556636, 0.42052191, 0.004400226, 0.016172057, 0.03424422, 0.17079017, 0.99771416, 0.22498623, 0.9953803, 0.76003796, 0.0010464037, 0.18547854, 0.99888736, 0.013474935, 0.011434439, 0.99366164, 0.7652316, 0.9961898, 0.07174189, 0.0011262397, 0.13856737, 0.00018628081, 0.97950953, 0.9956873, 0.41243395, 0.019252988, 0.0695109, 0.6846246, 0.9342255, 0.0012016298, 0.08331583, 0.9789164, 0.01242007, 0.47504303, 0.05254436, 0.08915018, 0.009030532, 0.53475887, 0.11275847, 0.018047942, 0.77595884, 0.0013500217, 0.003806687, 0.97926027, 0.9868374, 0.14914444, 0.00036296272, 0.63487095, 0.003768816, 0.0014330359, 0.0034068662, 0.19021556, 0.9386355, 0.007079096, 0.079774626, 0.001437194, 0.03805996, 0.003747631, 0.10640972, 0.99996936, 0.14917369, 0.0002136285, 0.066287816, 0.010885998, 0.358071, 0.9797349, 0.02088891, 0.0029773149, 0.00530018, 0.3257439, 0.0028693324, 0.00046033043, 0.9051168, 0.9871071, 0.013354317, 0.010470217, 0.00014215492, 0.0636579, 0.33675405, 0.11064286, 0.1900405, 0.12554586, 0.19228403, 0.015580012, 0.0075897872, 0.0104438, 0.0042477683, 0.01514538, 0.24745302, 0.14996655, 0.0122592775, 0.06282101, 0.019068075, 0.00049957575, 0.97489953])]\n"," [list([0.0076232804, 0.005851009, 0.0019441092, 0.0015000405, 0.014744026, 0.010158288, 2.8620188e-05, 0.40811238, 0.0025437071, 0.02072409, 0.041175116, 0.00036189836, 0.049214225, 0.0065247826, 0.2602668, 1.6139644e-05, 0.0019041679, 0.022247884, 0.42542368, 2.7749084e-05, 0.002837822, 0.00014374193, 0.0030872799, 0.028880997, 0.027806712, 0.00019855417, 0.007261733, 0.0014834843, 7.3634015e-05, 0.0011555987, 0.07251107, 0.00314806, 0.88608533, 0.0071500493, 2.2422604e-05, 0.00059860916, 0.012676427, 0.69400847, 0.014708366, 0.02921397, 0.0011851375, 0.04878934, 0.9541958, 0.0006409993, 0.98969215, 0.7039294, 0.99977714, 0.900371, 0.8771349, 0.9834778, 0.02301515, 0.28069472, 0.9766549, 0.31667104, 0.23155761, 0.98776996, 0.615142, 0.055999644, 0.9975732, 0.92045325, 0.99622923, 0.9799794, 0.2000893, 0.99462163, 0.032844506, 0.16439283, 0.62133545, 0.9875886, 0.9999888, 0.9462986, 0.9886248, 0.9990728, 0.9928429, 0.9995777, 0.9947885, 0.8742557, 0.99985516, 0.99979967, 0.6610059, 0.99682117, 0.31395453, 0.0030397133, 0.05943282, 0.9971711, 0.99773055, 0.9987845, 0.48688906, 0.0007779937, 0.5869512, 0.18558648, 0.95928097, 0.022435745, 0.3506792, 0.37380344, 0.9929389, 0.9999782, 0.0012429944, 0.026507376, 0.32252324, 0.43876317, 0.9335146, 0.020436442, 0.007918259, 0.1598749, 0.021060925, 0.046886742, 0.0020338236, 0.14886141, 0.0073280144, 0.0004678096, 0.07011473, 4.5788e-05, 0.06304309, 0.005233283, 0.00034787436, 0.9943329, 0.7315173, 0.023081902, 0.6593977, 0.0029896365])]\n"," [list([0.012202803, 6.156606e-05, 0.068510816, 0.00027485166, 9.510942e-05, 0.00022845482, 0.013405784, 0.102460936, 0.060282167, 0.0005014319, 0.058719836, 0.0027355861, 0.0008890722, 0.008149004, 0.0672178, 0.00030169133, 0.0023507066, 0.30151215, 0.009956916, 1.591073e-05, 0.31137085, 0.0005288258, 0.00033852714, 0.0701276, 1.4071852e-05, 2.3774652e-05, 0.007994652, 0.0013470689, 0.00016801665, 0.17141403, 0.0009822677, 0.04121935, 0.98649734, 0.22390696, 0.003098819, 0.0037906114, 0.0007737292, 0.0058149626, 0.00346814, 0.032845445, 0.063699506, 0.01561688, 0.6107336, 0.9167758, 0.9683958, 0.99990916, 0.96140087, 0.70504403, 0.058121987, 0.98622185, 0.006981274, 0.063507475, 0.92201626, 0.0026338913, 0.83723223, 0.9845867, 0.99350786, 0.032613583, 0.9910972, 0.14468485, 0.9807811, 0.06622559, 0.18508695, 0.946919, 0.0009052762, 0.26344377, 0.74008155, 0.22318494, 0.9961302, 0.99822754, 0.9739213, 0.9180599, 0.9139849, 0.9936807, 0.6996765, 0.9509067, 0.9772176, 0.9989023, 0.13238811, 0.9910671, 0.85756934, 0.80175877, 0.4680279, 0.4191629, 0.98796, 0.9880015, 0.07041771, 0.0021443937, 0.01342055, 0.58783215, 0.9984131, 2.927056e-05, 0.19492415, 0.0009919037, 0.8070671, 0.9745242, 0.0008034257, 0.22156624, 0.8902866, 0.2902303, 0.0011306836, 0.0022652543, 0.06519999, 0.0006805034, 0.040632334, 0.0010907857, 0.006105378, 0.80537987, 0.011864777, 0.005443032, 0.000104272374, 0.0126196835, 0.0019954285, 0.001118207, 3.400597e-05, 0.15077595, 0.0023418688, 0.222942, 0.2317274, 0.013242796])]\n"," [list([0.00050677505, 0.009484562, 0.00044266405, 0.0020731033, 0.60766435, 0.3715666, 0.0011503367, 0.9025639, 0.22877519, 0.049409434, 0.027731217, 0.020478582, 0.06703387, 0.031801283, 0.0014678506, 0.087849654, 0.014479792, 0.6494453, 0.05602401, 0.046081144, 0.08469954, 0.00056076824, 0.017477358, 0.008598882, 0.14257969, 0.054715693, 0.044349406, 0.002030157, 0.009794863, 0.06815362, 0.37480748, 0.04942517, 0.92050135, 0.89229673, 0.03485257, 0.1457239, 0.038289566, 0.026544075, 0.036150184, 0.01747756, 0.0038002678, 0.02240222, 0.98384607, 0.0045319367, 0.96609026, 0.6992499, 0.98957974, 0.72400236, 0.9604748, 0.999584, 0.010090735, 0.92468876, 0.9640963, 0.06329548, 0.97477233, 0.9610353, 0.9816295, 0.21149382, 0.9019244, 0.611625, 0.95191485, 0.9698331, 0.71687686, 0.9632625, 0.60225374, 0.93978673, 0.6234462, 0.9661615, 0.9999691, 0.98958534, 0.99026674, 0.99027175, 0.92628986, 0.9947068, 0.9980971, 0.9262507, 0.57179254, 0.9997422, 0.80402696, 0.97105116, 0.98559695, 0.53367645, 0.36885244, 0.9835517, 0.9713179, 0.9501703, 0.03234827, 0.0033765275, 0.18039578, 0.7307533, 0.9940135, 0.023423204, 0.0033163195, 0.89741755, 0.93986845, 0.8773813, 0.012528898, 0.563485, 0.40704092, 0.56520426, 0.69329953, 0.008555062, 0.057885587, 0.6497005, 0.7685993, 0.52535933, 0.045342423, 0.38735366, 0.0010756437, 0.044748105, 0.5718058, 0.49712908, 0.5435173, 0.038509108, 0.09369687, 0.8502808, 0.7320767, 0.008124543, 0.48119915, 0.05274832])]\n"," [list([3.9257062e-05, 0.007877933, 0.22541855, 0.00011998559, 0.20646869, 0.5957918, 0.00055129774, 0.00436004, 0.02167437, 0.9205561, 0.0013699052, 0.00853955, 0.0009976936, 0.009737768, 0.052643005, 0.0016186739, 0.017539423, 0.01154536, 0.04753593, 0.0079646325, 0.011516071, 0.004714311, 0.00038274247, 4.75767e-06, 0.00013239337, 0.0043008947, 8.9766356e-05, 0.0051621497, 0.00023846349, 0.7719252, 0.017714497, 0.5832769, 0.20775366, 0.09511952, 0.0043422435, 0.00014813196, 0.048477266, 0.08324699, 0.19618295, 0.030711643, 0.025348924, 0.9895621, 0.007844569, 0.84111017, 0.0035103122, 0.0031999606, 0.9954326, 0.009714113, 0.0023999778, 0.0013943565, 0.33432874, 0.005725277, 2.550602e-05, 0.48629308, 0.8435848, 0.20021851, 0.03609642, 0.99877566, 0.0054071536, 0.4960399, 3.622993e-05, 0.17267033, 0.9525777, 0.2917086, 0.0074082613, 0.17573911, 0.0008539415, 0.0050130044, 0.061878853, 0.00038568067, 0.7121143, 4.6061896e-06, 0.0006254263, 0.0059548216, 0.8158949, 0.79450154, 0.06396576, 0.48061174, 0.077733, 0.81853646, 0.0020581873, 0.0037626284, 0.0035311817, 0.0043801363, 0.0077684857, 0.053064685, 0.005491946, 1.4770092e-05, 0.9931498, 0.0002309075, 0.59749806, 0.002325843, 0.00195969, 0.00010778488, 0.010886624, 0.0104713235, 0.063218616, 0.004336591, 0.18914442, 0.53892946, 0.015351437, 0.2895693, 0.00017765093, 0.0032004504, 0.13217804, 0.009076675, 0.044246566, 0.6975543, 0.03152454, 0.0006770445, 0.0018312687, 0.0066402634, 0.0029979327, 0.006998011, 0.99932516, 0.037211385, 0.083322965, 0.047972027, 0.013794922, 6.961153e-05, 0.0017157315, 0.010284122, 0.091883406, 0.0072133797, 0.0011973954, 0.0016695061, 0.0009679676, 0.0053088726, 0.07676845, 0.8658944])]\n"," [list([9.344654e-05, 0.00060758175, 0.81452185, 0.0069974377, 0.0020978875, 0.0007469712, 1.5303529e-05, 0.003157764, 0.0022170204, 0.98797673, 0.0070943553, 0.03089049, 0.0031391182, 0.00021179568, 0.0076727658, 0.0003128782, 0.001292162, 0.061642956, 8.813046e-05, 0.0028244385, 0.0066081956, 0.0013488823, 0.00075040763, 2.8722916e-05, 0.0017529774, 0.0065826424, 0.000101409416, 0.008345666, 0.0004167701, 0.19497968, 0.16153398, 2.5694762e-05, 0.025987629, 0.005613645, 0.00013191298, 0.0040970254, 0.8435949, 0.0004665293, 0.77678436, 0.11087681, 0.0027019083, 0.115730226, 0.015486686, 0.0005979015, 1.395031e-06, 0.0060023637, 0.92497945, 0.009776132, 0.0021347895, 0.0037916845, 0.20381299, 0.1183325, 3.7203185e-06, 0.08850632, 0.8895237, 0.012410991, 0.7011295, 0.039033346, 0.00014721641, 0.07496535, 0.021330595, 0.29341197, 0.6383686, 0.10728683, 0.0005252468, 0.3139378, 0.000791682, 0.0506362, 0.03158236, 0.010191093, 0.0025795077, 0.0021384656, 0.0014052471, 0.00043059507, 0.00049443706, 0.12071686, 0.002071775, 0.0021095322, 0.14984395, 0.73858887, 0.0048767785, 0.0063315164, 0.72162026, 0.087903045, 6.4022934e-05, 0.003941142, 0.0015491218, 0.00010689388, 0.65638846, 0.00020605573, 0.014747047, 0.0025706978, 0.024873525, 4.5753695e-05, 0.009343082, 0.018033186, 0.9884735, 0.10188959, 0.012131376, 0.11515443, 0.009422483, 0.0001159282, 0.0015778255, 0.00033778776, 0.71586126, 0.017812354, 0.0032089455, 0.004745355, 0.008698711, 1.9395862e-05, 0.026716301, 0.008082762, 7.2952644e-05, 4.8146056e-05, 0.6038875, 0.00015398556, 0.19188684, 0.76479995, 0.00952733, 0.0013178135, 0.277544, 0.018904982, 0.00028713042, 0.00012967434, 0.0013482363, 0.20459598, 0.0014188801, 0.0053600892, 0.0037445577, 0.63693345])]\n"," [list([0.018226674, 0.008799901, 0.4295522, 0.00033283807, 0.055596128, 0.0028432314, 0.0017037311, 0.0060195746, 0.0013349564, 0.6380409, 0.43042138, 0.011092181, 0.004192359, 0.012318969, 0.45218194, 0.15705056, 0.08293433, 0.83429235, 0.07478502, 0.00017008325, 0.08179644, 0.023943463, 0.0028064756, 0.014393959, 0.008116187, 0.07482208, 0.00063285546, 0.018803777, 0.017980224, 0.099159576, 0.2509022, 0.012476674, 0.045749735, 0.21525978, 0.08578497, 0.03573761, 0.12221684, 0.55578893, 0.56854343, 0.0060723885, 0.01588602, 0.9536134, 0.18800387, 0.12069161, 0.0063948897, 0.43249413, 0.92845106, 0.033646453, 0.0008975856, 0.0027840992, 0.5505284, 0.024057273, 0.00877353, 0.40743822, 0.91968423, 0.91068506, 0.53188527, 0.6254653, 0.001801853, 0.14851432, 0.15162459, 0.1737176, 0.87138474, 0.9911349, 0.034498174, 0.022183964, 0.0015868738, 0.0109749595, 0.7605954, 0.0009853519, 0.47034633, 0.024655364, 0.0007450609, 0.0042410796, 0.064419545, 0.1112648, 0.03874631, 0.088711806, 0.27467185, 0.24179621, 0.31470898, 0.005046075, 0.04480154, 0.0147246, 0.046662424, 0.0016426475, 0.028933281, 0.2023467, 0.9648117, 0.00015011986, 0.78511256, 0.010463551, 0.0005530777, 0.0019050654, 0.070419505, 0.119808584, 0.5599379, 0.054584928, 0.39722744, 0.04792449, 0.12152242, 0.6170603, 0.0036157968, 0.0011006189, 0.28846502, 0.0036724128, 0.015610745, 0.5740805, 0.7195023, 2.5221498e-05, 0.092672184, 0.006242132, 0.14683424, 0.13968042, 0.45799896, 0.5744634, 0.8578286, 0.94815445, 0.53284913, 0.008486455, 0.010767158, 0.008587154, 0.031232698, 0.0065135695, 0.001007594, 0.78518844, 0.000117697455, 0.0027758637, 0.03783135, 0.14989094])]]\n","(9, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qxFkM0IyB9vx","colab_type":"code","outputId":"b3b2431b-f337-4e82-a318-d2e8e8a76a78","executionInfo":{"status":"ok","timestamp":1584858298761,"user_tz":240,"elapsed":1797432,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDNUmrksb7ajH78ufM6_UhkFXwnC92mfPrGlVMselGrCi2rbtT0RQTAE_W4zYdJlR6aRmzSVhjT80-h3VIfU6oz4DdPcu1COE603poXAwZZwbjxVz7SdY15e4W-G1rSf0GdaX0RhwIQ3SCH7giErHIWSqvBbBvd6sPUBCVgz8GihsOSy95wrKgqRwkP1RYUlrR7BxEExDGXAZfVBPT9U9rVFnj_5OfLaLDSope-ENe1fImfSvHG_YxuUfNYgYDkt_iwJ_fZOtnZN1YoVk04CYKPxemoL3vhDb70jPfCUsYujJYeOzdApu63nJPpw4t6Tw043CpVLDWu8TlmMjPVFnxTViBUWTQ5wk_Pi0H5Nuy4H23usZTaF7MUXZg9a6b_T9AUCYLalA1Q9hnZhE4-tf0fhSz_F-yahMY8vdcF4gp3FLrysZMZxL9ntqnmBbG2_s0X17adoEfSrFfVbE4396BHDBbGmhhJ8ExSaYjLeWnoPlGjLWBxsOMuqnvRdUcml6BWDDkiusX6JgGH1EAJ9vl43dmYTwMdo_xNS9T4RfzHvHIfREZfOgUYalTU9UWYsw7Vnd1mM-CaC8mxVvfTmPX2HDu78BxDQeUkI1Yr40DBz3Ksj8shOu9Qcdt8vWGmLWkSXnbM8Yb1Yzi1NCx6stye_S25D94XuMWaXUErG8gua7KVULH7-4SOnZ9xQCza5-r-R8boJnclvGWaxk69gwjFE--isLStSMqZ7w-_wXwcFSsS5V0-wwKqlroqAX7fqzrw=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["print('ACL labels: train 3 oris, valid 3 oris, test 3 oris')\n","print(np.array(labelslist_ACL))\n","print(np.array(labelslist_ACL).shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ACL labels: train 3 oris, valid 3 oris, test 3 oris\n","[[list([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])]\n"," [list([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])]\n"," [list([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])]\n"," [list([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0])]\n"," [list([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0])]\n"," [list([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0])]\n"," [list([0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])]\n"," [list([0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])]\n"," [list([0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])]]\n","(9, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VXSgeV3yjfzJ","colab_type":"code","outputId":"ee211922-58cb-432a-c830-e50307780d82","executionInfo":{"status":"ok","timestamp":1584858298762,"user_tz":240,"elapsed":1796641,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDNUmrksb7ajH78ufM6_UhkFXwnC92mfPrGlVMselGrCi2rbtT0RQTAE_W4zYdJlR6aRmzSVhjT80-h3VIfU6oz4DdPcu1COE603poXAwZZwbjxVz7SdY15e4W-G1rSf0GdaX0RhwIQ3SCH7giErHIWSqvBbBvd6sPUBCVgz8GihsOSy95wrKgqRwkP1RYUlrR7BxEExDGXAZfVBPT9U9rVFnj_5OfLaLDSope-ENe1fImfSvHG_YxuUfNYgYDkt_iwJ_fZOtnZN1YoVk04CYKPxemoL3vhDb70jPfCUsYujJYeOzdApu63nJPpw4t6Tw043CpVLDWu8TlmMjPVFnxTViBUWTQ5wk_Pi0H5Nuy4H23usZTaF7MUXZg9a6b_T9AUCYLalA1Q9hnZhE4-tf0fhSz_F-yahMY8vdcF4gp3FLrysZMZxL9ntqnmBbG2_s0X17adoEfSrFfVbE4396BHDBbGmhhJ8ExSaYjLeWnoPlGjLWBxsOMuqnvRdUcml6BWDDkiusX6JgGH1EAJ9vl43dmYTwMdo_xNS9T4RfzHvHIfREZfOgUYalTU9UWYsw7Vnd1mM-CaC8mxVvfTmPX2HDu78BxDQeUkI1Yr40DBz3Ksj8shOu9Qcdt8vWGmLWkSXnbM8Yb1Yzi1NCx6stye_S25D94XuMWaXUErG8gua7KVULH7-4SOnZ9xQCza5-r-R8boJnclvGWaxk69gwjFE--isLStSMqZ7w-_wXwcFSsS5V0-wwKqlroqAX7fqzrw=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for index in range(9):\n","  # find indices where prediction value was different from label\n","  abslist = abs(np.subtract(np.array(predslist_ACL[index]),np.array(labelslist_ACL[index]))) \n","  returnlist = np.where(abslist < 0.5, 0, 1)\n","  print(np.sum(returnlist), returnlist)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1 [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n","7 [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n","34 [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n","20 [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n","  0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n","  0 0 0 0 0 0 0 0 0 0 0 0]]\n","19 [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0\n","  0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 1 1 0 1 0]]\n","23 [[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n","  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 0 1\n","  0 0 1 0 1 0 0 0 0 0 1 0]]\n","18 [[0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n","  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0\n","  0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0\n","  0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n","16 [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n","  0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n","  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n","23 [[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0\n","  0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m-0HJKPoqZ3H","colab_type":"code","outputId":"1343eb68-5f83-4037-dea6-08efe69c21d2","executionInfo":{"status":"ok","timestamp":1585438080861,"user_tz":240,"elapsed":736016,"user":{"displayName":"Miles Wang","photoUrl":"","userId":"12191090513994259530"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["predslist_meniscus, labelslist_meniscus = evaluate_three('meniscus')\n","predslist_abnormal, labelslist_abnormal = evaluate_three('abnormal')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train axial\n","load_data meniscus axial\n","using alexnet ...\n","threshold is:  [1.9985895e+00 9.9858958e-01 9.4349897e-01 9.4247985e-01 9.1868448e-01\n"," 9.1788006e-01 8.5264659e-01 8.5178310e-01 8.2650393e-01 8.2368714e-01\n"," 7.9656619e-01 7.9593551e-01 7.9221290e-01 7.9073876e-01 7.5253862e-01\n"," 7.5225055e-01 7.4259323e-01 7.4144578e-01 7.2857809e-01 7.2672981e-01\n"," 7.0517379e-01 7.0158821e-01 7.0029652e-01 6.9964916e-01 6.9682825e-01\n"," 6.9480932e-01 6.9259822e-01 6.9184762e-01 6.4329726e-01 6.4298970e-01\n"," 6.3995057e-01 6.3987446e-01 6.3132024e-01 6.1770308e-01 6.0910326e-01\n"," 6.0653198e-01 6.0490733e-01 5.9634608e-01 5.8880067e-01 5.8307576e-01\n"," 5.7983649e-01 5.7755709e-01 5.7021338e-01 5.6861156e-01 5.4403299e-01\n"," 5.3557831e-01 5.3258586e-01 5.1828957e-01 5.0888735e-01 4.9761319e-01\n"," 4.9311790e-01 4.8925805e-01 4.8488188e-01 4.8224205e-01 4.7281483e-01\n"," 4.6672267e-01 4.6429083e-01 4.6079263e-01 4.5783788e-01 4.4066018e-01\n"," 4.3139261e-01 3.6412594e-01 3.5744852e-01 3.4717691e-01 3.4618962e-01\n"," 3.4437662e-01 3.4369978e-01 2.8363544e-01 2.7748045e-01 2.3965888e-01\n"," 2.3118296e-01 1.8726215e-01 1.8640155e-01 1.2733221e-01 1.2538858e-01\n"," 9.9471547e-02 9.9301882e-02 9.2942930e-05]\n","train loss: 0.0802\n","train AUC: 0.9884\n","train sagittal\n","load_data meniscus sagittal\n","using alexnet ...\n","threshold is:  [1.99960303e+00 9.99603093e-01 9.76231754e-01 9.75262940e-01\n"," 9.60450768e-01 9.60406721e-01 9.60287750e-01 9.60267425e-01\n"," 9.56693292e-01 9.55624878e-01 9.41999495e-01 9.41812694e-01\n"," 9.28345799e-01 9.26270425e-01 9.18446064e-01 9.18083429e-01\n"," 9.11584258e-01 9.10395980e-01 8.98187637e-01 8.95895839e-01\n"," 8.89619827e-01 8.89116585e-01 8.80825341e-01 8.80286753e-01\n"," 8.69393706e-01 8.69202852e-01 8.63914430e-01 8.59656394e-01\n"," 8.45908642e-01 8.40347886e-01 8.34457040e-01 8.31058800e-01\n"," 8.30836236e-01 8.28971744e-01 8.24885011e-01 8.20145726e-01\n"," 8.13781619e-01 8.11578274e-01 8.11557949e-01 8.08230817e-01\n"," 8.02118242e-01 8.01203907e-01 7.92387962e-01 7.91921377e-01\n"," 7.85517275e-01 7.80022919e-01 7.77133286e-01 7.75630713e-01\n"," 7.67891705e-01 7.64542937e-01 7.62572110e-01 7.61074007e-01\n"," 7.60808825e-01 7.58438408e-01 7.56951094e-01 7.56500423e-01\n"," 7.47718453e-01 7.46624053e-01 7.45292246e-01 7.44539559e-01\n"," 7.42094338e-01 7.39822805e-01 7.24874556e-01 7.23807991e-01\n"," 7.23397434e-01 7.18371212e-01 7.05085993e-01 6.99499190e-01\n"," 6.97295010e-01 6.88222408e-01 6.76141024e-01 6.75477624e-01\n"," 6.72657549e-01 6.71172917e-01 6.69558764e-01 6.54454112e-01\n"," 6.49455607e-01 6.48833215e-01 6.35790288e-01 6.34900749e-01\n"," 6.30050480e-01 6.27474308e-01 6.13362968e-01 6.12105906e-01\n"," 6.10102057e-01 6.06372774e-01 6.04760289e-01 6.02927983e-01\n"," 5.91319680e-01 5.86089611e-01 5.85231602e-01 5.79503834e-01\n"," 5.78853488e-01 5.78840077e-01 5.75930059e-01 5.74167371e-01\n"," 5.64179599e-01 5.55696428e-01 5.53753138e-01 5.47298193e-01\n"," 5.46331823e-01 5.30047119e-01 5.26115239e-01 5.22187889e-01\n"," 5.20959437e-01 5.17543495e-01 5.16548157e-01 5.16492367e-01\n"," 5.12881041e-01 5.12853384e-01 5.05809128e-01 4.92622197e-01\n"," 4.91860718e-01 4.86691684e-01 4.79822159e-01 4.76104558e-01\n"," 4.75235820e-01 4.74611223e-01 4.74202722e-01 4.64281231e-01\n"," 4.61944938e-01 4.60493624e-01 4.59430248e-01 4.52936858e-01\n"," 4.51855361e-01 4.48076278e-01 4.46929157e-01 4.46796417e-01\n"," 4.46374357e-01 4.42191511e-01 4.28480327e-01 4.21327680e-01\n"," 4.20741946e-01 4.04434025e-01 4.04252738e-01 3.99191618e-01\n"," 3.98453295e-01 3.87017399e-01 3.82298648e-01 3.63865644e-01\n"," 3.63835156e-01 3.62295032e-01 3.61883461e-01 3.47816557e-01\n"," 3.39718193e-01 3.37647200e-01 3.35837215e-01 3.33702445e-01\n"," 3.32970649e-01 3.27318788e-01 3.14812660e-01 3.02851796e-01\n"," 3.00640494e-01 2.63903856e-01 2.57155687e-01 2.45088816e-01\n"," 2.37539113e-01 2.33098939e-01 2.32656479e-01 2.22372860e-01\n"," 2.21458778e-01 2.08718985e-01 2.08568737e-01 1.81650177e-01\n"," 1.81592971e-01 1.79733485e-01 1.79288298e-01 1.61626726e-01\n"," 1.60518020e-01 1.58257857e-01 1.53300181e-01 1.30192593e-01\n"," 1.27743155e-01 1.13200925e-01 1.10508382e-01 1.06928997e-01\n"," 1.06427610e-01 1.05877057e-01 1.04165144e-01 9.30479839e-02\n"," 9.20343921e-02 8.92832503e-02 8.91026035e-02 6.93074688e-02\n"," 6.90109804e-02 6.43293634e-02 6.40376061e-02 2.20484595e-04]\n","train loss: 0.1407\n","train AUC: 0.9413\n","train coronal\n","load_data meniscus coronal\n","using alexnet ...\n","threshold is:  [1.98226535e+00 9.82265353e-01 7.67628431e-01 7.67311096e-01\n"," 6.02311432e-01 6.00276291e-01 5.84969997e-01 5.84684312e-01\n"," 5.78730464e-01 5.72947681e-01 5.30184984e-01 5.22549987e-01\n"," 5.16515911e-01 5.06968260e-01 4.83217418e-01 4.82281357e-01\n"," 4.49665010e-01 4.48409349e-01 4.44511533e-01 4.38801557e-01\n"," 4.31636661e-01 4.28028554e-01 4.20843512e-01 4.20247704e-01\n"," 4.11652327e-01 4.03231472e-01 3.86146009e-01 3.80926996e-01\n"," 3.72105777e-01 3.71856153e-01 3.58570963e-01 3.58318478e-01\n"," 3.52989167e-01 3.51144999e-01 3.50946993e-01 3.48272473e-01\n"," 3.45063210e-01 3.44142288e-01 3.42731148e-01 3.39308977e-01\n"," 3.39297563e-01 3.36970568e-01 3.21850508e-01 3.12722683e-01\n"," 3.07896823e-01 3.06455195e-01 3.04940790e-01 3.03713441e-01\n"," 2.89614290e-01 2.87522763e-01 2.82048374e-01 2.80751437e-01\n"," 2.75660217e-01 2.72330016e-01 2.67602235e-01 2.63058752e-01\n"," 2.62942612e-01 2.60309190e-01 2.59421974e-01 2.57847965e-01\n"," 2.51748979e-01 2.50701159e-01 2.46055976e-01 2.45160967e-01\n"," 2.42764026e-01 2.41555020e-01 2.32459038e-01 2.32435852e-01\n"," 2.22800821e-01 2.16732875e-01 2.14056790e-01 2.14020520e-01\n"," 2.12188259e-01 2.08248138e-01 2.03618422e-01 2.01439083e-01\n"," 1.97677702e-01 1.94615975e-01 1.91717580e-01 1.89129934e-01\n"," 1.87500760e-01 1.83442861e-01 1.82814792e-01 1.79937974e-01\n"," 1.79553673e-01 1.76224425e-01 1.72941640e-01 1.72129437e-01\n"," 1.64844230e-01 1.63239136e-01 1.63128853e-01 1.62926540e-01\n"," 1.61386713e-01 1.61295593e-01 1.61028296e-01 1.59893692e-01\n"," 1.56341240e-01 1.56249478e-01 1.55392438e-01 1.50656760e-01\n"," 1.47839189e-01 1.39873400e-01 1.37256533e-01 1.34925872e-01\n"," 1.33761615e-01 1.32504880e-01 1.32464051e-01 1.32119045e-01\n"," 1.31584585e-01 1.31425798e-01 1.28483087e-01 1.27135545e-01\n"," 1.25744805e-01 1.24931224e-01 1.24383509e-01 1.19978517e-01\n"," 1.16804220e-01 1.16309114e-01 1.15406312e-01 1.11720189e-01\n"," 1.10344246e-01 1.09504580e-01 1.09341547e-01 1.06369108e-01\n"," 1.06188416e-01 1.05178118e-01 1.04141057e-01 1.03822790e-01\n"," 1.01048641e-01 9.82524902e-02 9.77482125e-02 9.65013430e-02\n"," 9.63189453e-02 9.43698585e-02 9.43110660e-02 9.19907689e-02\n"," 9.14172903e-02 8.97588134e-02 8.88822526e-02 8.87700990e-02\n"," 8.86169821e-02 8.83217603e-02 8.77632350e-02 8.77489075e-02\n"," 8.68169144e-02 8.58555958e-02 8.45469907e-02 8.40028301e-02\n"," 8.36405754e-02 8.09364244e-02 7.86369219e-02 7.77772516e-02\n"," 7.73309097e-02 7.48114586e-02 7.35129565e-02 7.04149157e-02\n"," 7.02854171e-02 6.99396059e-02 6.95913136e-02 6.86151013e-02\n"," 6.83856010e-02 6.83475062e-02 6.82443529e-02 6.75532371e-02\n"," 6.72285110e-02 6.54727668e-02 6.54190257e-02 6.09854199e-02\n"," 6.05218001e-02 5.99813387e-02 5.93986958e-02 5.73759824e-02\n"," 5.55404946e-02 5.43740802e-02 5.40019087e-02 5.21886237e-02\n"," 5.12051918e-02 5.00489064e-02 4.99738269e-02 4.44427319e-02\n"," 4.42579202e-02 4.35694903e-02 4.34771292e-02 4.31284793e-02\n"," 4.29947190e-02 4.16705497e-02 4.15008925e-02 3.94909307e-02\n"," 3.94859463e-02 3.45178396e-02 3.43313068e-02 2.05749068e-02\n"," 2.05265507e-02 1.93698965e-02 1.93339977e-02 6.43903040e-05]\n","train loss: 0.2576\n","train AUC: 0.9450\n","valid axial\n","load_data meniscus axial\n","using alexnet ...\n","threshold is:  [1.9786348e+00 9.7863483e-01 9.5658636e-01 9.5582402e-01 9.3720019e-01\n"," 9.3469840e-01 8.7642050e-01 8.7127519e-01 8.4385675e-01 8.3974093e-01\n"," 7.8098106e-01 7.7819282e-01 7.6154053e-01 7.5174826e-01 7.3820108e-01\n"," 7.3682797e-01 7.2072047e-01 7.0878422e-01 6.6959870e-01 6.4246452e-01\n"," 6.3803649e-01 6.2442958e-01 6.1593091e-01 6.0764426e-01 5.9638572e-01\n"," 5.9100723e-01 5.8820796e-01 5.8204931e-01 5.6801367e-01 5.4763913e-01\n"," 5.2856308e-01 5.0663686e-01 4.8559737e-01 4.7984791e-01 4.7221348e-01\n"," 3.7424135e-01 3.5022685e-01 3.3614308e-01 3.1509820e-01 3.0878758e-01\n"," 2.7212220e-01 2.5232050e-01 2.1753931e-01 1.9803394e-01 1.9400977e-01\n"," 1.6759874e-01 1.6507865e-01 1.3732947e-01 1.3159612e-01 1.2091510e-01\n"," 9.8024771e-02 7.3094115e-02 7.2661251e-02 4.9580459e-04]\n","valid loss: 0.2653\n","valid AUC: 0.8170\n","valid sagittal\n","load_data meniscus sagittal\n","using alexnet ...\n","threshold is:  [1.9991472e+00 9.9914718e-01 9.9706668e-01 9.8819578e-01 9.8517311e-01\n"," 9.8464048e-01 9.6273392e-01 9.6141332e-01 9.5398939e-01 9.5124096e-01\n"," 9.4694716e-01 9.3351972e-01 9.2727435e-01 9.2603087e-01 9.1353071e-01\n"," 8.9326400e-01 8.6189884e-01 8.6132264e-01 8.5720807e-01 8.3693010e-01\n"," 8.3280027e-01 8.3021510e-01 8.2460147e-01 7.6952082e-01 7.5687438e-01\n"," 7.1662194e-01 6.9862193e-01 6.8387759e-01 6.6347176e-01 6.4185065e-01\n"," 6.1886430e-01 5.9924877e-01 5.8350629e-01 4.8757392e-01 4.6681491e-01\n"," 4.4072124e-01 4.3281549e-01 3.8446301e-01 3.7759918e-01 3.7019882e-01\n"," 3.5843170e-01 3.4689930e-01 3.4333125e-01 3.1285983e-01 2.7922523e-01\n"," 1.7721269e-01 1.7237487e-01 1.3614255e-01 1.3087000e-01 1.2519072e-01\n"," 9.9829003e-02 8.6417757e-02 8.6171679e-02 3.4095973e-02 3.1939775e-02\n"," 4.9313356e-04]\n","valid loss: 0.3680\n","valid AUC: 0.7240\n","valid coronal\n","load_data meniscus coronal\n","using alexnet ...\n","threshold is:  [1.95244408e+00 9.52444017e-01 9.37751710e-01 9.10403669e-01\n"," 5.31220913e-01 5.30230284e-01 5.01582086e-01 4.75685865e-01\n"," 4.69332397e-01 4.67598677e-01 4.38495934e-01 4.07256454e-01\n"," 3.82453710e-01 3.60736161e-01 3.21872890e-01 2.95668423e-01\n"," 2.53779709e-01 2.35317931e-01 2.31626287e-01 2.29182065e-01\n"," 1.94097310e-01 1.76091269e-01 1.58439249e-01 1.49733633e-01\n"," 1.38331354e-01 1.30738765e-01 1.15162075e-01 1.14829056e-01\n"," 1.12581745e-01 8.86527896e-02 8.30411017e-02 7.85388201e-02\n"," 7.25849494e-02 5.24065904e-02 5.17546646e-02 4.27328870e-02\n"," 3.79892252e-02 2.15778518e-02 2.07584724e-02 1.81233119e-02\n"," 1.68956332e-02 5.46919927e-03 5.12535265e-03 1.53892348e-03]\n","valid loss: 0.3961\n","valid AUC: 0.8201\n","test axial\n","load_data meniscus axial\n","using alexnet ...\n","threshold is:  [1.9953864e+00 9.9538642e-01 9.9521130e-01 9.7205251e-01 9.6146256e-01\n"," 9.4532651e-01 9.3720424e-01 8.9270675e-01 8.3962661e-01 8.3091962e-01\n"," 8.0575264e-01 7.7890855e-01 7.6487809e-01 6.8522257e-01 6.5950292e-01\n"," 5.8090329e-01 5.7668525e-01 5.7463247e-01 5.6848234e-01 5.1059031e-01\n"," 4.9930266e-01 4.5843756e-01 4.4793573e-01 4.3185508e-01 3.5599729e-01\n"," 3.5250077e-01 3.2696486e-01 3.2535630e-01 1.6647589e-01 1.5820517e-01\n"," 1.5741485e-01 1.5663196e-01 7.6697916e-02 6.8538867e-02 6.2821962e-02\n"," 6.1406821e-02 5.2909829e-02 5.2433435e-02 1.3746644e-02 1.2402829e-02\n"," 1.0997897e-02 1.0174296e-02 6.9129528e-03 5.1238122e-03 1.2538461e-04]\n","test loss: 0.2842\n","test AUC: 0.8190\n","test sagittal\n","load_data meniscus sagittal\n","using alexnet ...\n","threshold is:  [1.9977628e+00 9.9776280e-01 9.9568731e-01 9.9535227e-01 9.9474597e-01\n"," 9.8898238e-01 9.8686069e-01 9.8200297e-01 9.7995478e-01 9.6975327e-01\n"," 9.6206057e-01 9.4591683e-01 9.3776655e-01 9.3331158e-01 9.3328297e-01\n"," 9.2744774e-01 9.2364055e-01 8.7489891e-01 8.3901662e-01 8.3025831e-01\n"," 8.1430930e-01 7.8985846e-01 7.7469885e-01 7.4734360e-01 7.3528850e-01\n"," 7.1461749e-01 6.2192541e-01 5.6224233e-01 4.4165465e-01 4.3951160e-01\n"," 4.0501556e-01 3.5322359e-01 3.2336769e-01 2.4305373e-01 2.1077070e-01\n"," 2.0320128e-01 2.0287879e-01 1.9813178e-01 7.5215839e-02 7.1971193e-02\n"," 6.1612587e-02 6.1413296e-02 3.5541561e-02 3.1816557e-02 2.4040358e-02\n"," 2.3099486e-02 1.7298985e-02 1.5665995e-02 1.2927882e-02 1.1132119e-02\n"," 6.8139248e-03 6.0522738e-03 6.6512363e-04]\n","test loss: 0.4230\n","test AUC: 0.7067\n","test coronal\n","load_data meniscus coronal\n","using alexnet ...\n","threshold is:  [1.93979573e+00 9.39795732e-01 9.31620598e-01 8.75240862e-01\n"," 5.76008141e-01 5.75883329e-01 5.48684120e-01 5.47370315e-01\n"," 5.23075104e-01 5.12940705e-01 4.59770083e-01 4.04596239e-01\n"," 3.96193266e-01 3.95598441e-01 3.74507546e-01 3.55253875e-01\n"," 3.20021570e-01 2.97825009e-01 2.84676343e-01 2.77933061e-01\n"," 2.75218070e-01 1.48020178e-01 1.43090636e-01 1.19613014e-01\n"," 1.17661871e-01 1.13074958e-01 1.01197623e-01 9.94578078e-02\n"," 9.63147506e-02 7.26104528e-02 7.17036352e-02 6.58852905e-02\n"," 6.50698766e-02 6.00232407e-02 5.99038005e-02 4.03418578e-02\n"," 3.95272188e-02 3.44143026e-02 3.20407823e-02 2.50381771e-02\n"," 2.46959105e-02 2.15971861e-02 2.06543021e-02 1.49207870e-02\n"," 1.38922110e-02 1.30530689e-02 1.22529510e-02 3.63480533e-03\n"," 2.71912781e-03 9.54078336e-04]\n","test loss: 0.4753\n","test AUC: 0.7394\n","train axial\n","load_data abnormal axial\n","using alexnet ...\n","threshold is:  [2.00000000e+00 1.00000000e+00 9.99999881e-01 9.99999762e-01\n"," 9.99999523e-01 9.99999404e-01 9.99999285e-01 9.99999166e-01\n"," 9.99999046e-01 9.99998927e-01 9.99998808e-01 9.99998689e-01\n"," 9.99998569e-01 9.99998450e-01 9.99998331e-01 9.99998212e-01\n"," 9.99998093e-01 9.99997973e-01 9.99997854e-01 9.99997616e-01\n"," 9.99997497e-01 9.99997020e-01 9.99996901e-01 9.99996185e-01\n"," 9.99995589e-01 9.99995351e-01 9.99994874e-01 9.99994636e-01\n"," 9.99993801e-01 9.99993563e-01 9.99993443e-01 9.99992847e-01\n"," 9.99992728e-01 9.99992609e-01 9.99991894e-01 9.99990821e-01\n"," 9.99989986e-01 9.99989867e-01 9.99989271e-01 9.99988914e-01\n"," 9.99988794e-01 9.99988198e-01 9.99987960e-01 9.99987841e-01\n"," 9.99986529e-01 9.99985218e-01 9.99984264e-01 9.99983907e-01\n"," 9.99982834e-01 9.99981880e-01 9.99971271e-01 9.99970198e-01\n"," 9.99962449e-01 9.99962211e-01 9.99958873e-01 9.99956250e-01\n"," 9.99954224e-01 9.99950290e-01 9.99838710e-01 9.99832988e-01\n"," 9.99828219e-01 9.99827385e-01 9.59806144e-01 9.57104146e-01\n"," 8.76206577e-01 8.75511646e-01 7.99819589e-01 7.90972054e-01\n"," 6.93584323e-01 6.89022064e-01 6.08619034e-01 6.05776548e-01\n"," 6.04382694e-01 5.49932897e-01 5.29197216e-01 5.25976598e-01\n"," 5.22727549e-01 5.12440562e-01 4.91770893e-01 4.89040136e-01\n"," 4.88560766e-01 4.44138438e-01 4.36663330e-01 4.06256884e-01\n"," 3.90736282e-01 3.85238409e-01 3.41679841e-01 3.40667069e-01\n"," 3.13379854e-01 3.10962707e-01 3.08104515e-01 3.07664394e-01\n"," 2.99134284e-01 2.89133608e-01 2.85641521e-01 2.79621392e-01\n"," 2.74956793e-01 2.60758162e-01 2.56662369e-01 2.50179470e-01\n"," 2.47740611e-01 2.44262114e-01 2.37742931e-01 2.09234312e-01\n"," 2.08012417e-01 1.97802484e-01 1.96003526e-01 1.84862554e-01\n"," 1.80574507e-01 1.76468849e-01 1.73751026e-01 1.52503759e-01\n"," 1.47534549e-01 1.28297627e-01 1.27602011e-01 1.21990114e-01\n"," 1.21972203e-01 1.19709916e-01 1.14046462e-01 8.88538882e-02\n"," 8.76855627e-02 6.95904791e-02 6.92661852e-02 1.03634875e-03]\n","train loss: 0.0400\n","train AUC: 0.9913\n","train sagittal\n","load_data abnormal sagittal\n","using alexnet ...\n","threshold is:  [2.0000000e+00 1.0000000e+00 9.9999988e-01 9.9999976e-01 9.9999964e-01\n"," 9.9999940e-01 9.9999905e-01 9.9999893e-01 9.9999881e-01 9.9999857e-01\n"," 9.9999809e-01 9.9999774e-01 9.9999714e-01 9.9999678e-01 9.9999666e-01\n"," 9.9999654e-01 9.9999642e-01 9.9999595e-01 9.9999571e-01 9.9999475e-01\n"," 9.9999452e-01 9.9999380e-01 9.9999356e-01 9.9999285e-01 9.9999273e-01\n"," 9.9999237e-01 9.9999213e-01 9.9999034e-01 9.9999011e-01 9.9998999e-01\n"," 9.9998987e-01 9.9998963e-01 9.9998891e-01 9.9998879e-01 9.9998772e-01\n"," 9.9998748e-01 9.9998319e-01 9.9998271e-01 9.9997139e-01 9.9997091e-01\n"," 9.9995458e-01 9.9995434e-01 9.9994493e-01 9.9994314e-01 9.9989951e-01\n"," 9.9989939e-01 9.9989855e-01 9.9989510e-01 4.5414147e-01 4.5317373e-01\n"," 2.3610371e-01 2.2388332e-01 2.0441131e-01 1.9507369e-01 1.9402155e-01\n"," 1.9150075e-01 1.6973394e-01 1.5964483e-01 1.4806998e-01 1.1318298e-01\n"," 9.8173991e-02 5.8885619e-02 5.5503622e-02 5.5045515e-02 5.4783653e-02\n"," 5.3652056e-02 5.3300496e-02 5.1659465e-02 5.1174413e-02 4.7638375e-02\n"," 4.7488026e-02 4.5048852e-02 4.2921495e-02 2.7095763e-02 2.6236314e-02\n"," 9.5760413e-03 9.5636398e-03 6.2249992e-03 6.2101376e-03 1.1977353e-04]\n","train loss: 0.0286\n","train AUC: 0.9961\n","train coronal\n","load_data abnormal coronal\n","using alexnet ...\n","threshold is:  [1.9999993e+00 9.9999928e-01 9.9999893e-01 9.9999559e-01 9.9999523e-01\n"," 9.9998486e-01 9.9998450e-01 9.9997520e-01 9.9997425e-01 9.9997115e-01\n"," 9.9997103e-01 9.9970067e-01 9.9968636e-01 9.9921179e-01 9.9920660e-01\n"," 9.9822956e-01 9.9821532e-01 6.1237073e-01 6.0972548e-01 4.7477168e-01\n"," 4.7384313e-01 4.5374131e-01 4.4962090e-01 4.4454074e-01 4.3475315e-01\n"," 3.9242673e-01 3.8464844e-01 2.7405465e-01 2.6553762e-01 2.4236855e-01\n"," 2.2657883e-01 2.2132511e-01 1.8464875e-01 1.8321991e-01 1.3181457e-01\n"," 1.2759519e-01 1.2380117e-01 1.2312125e-01 8.5658737e-02 8.5656665e-02\n"," 8.0877140e-02 7.9820044e-02 6.6214636e-02 6.4686827e-02 3.5851650e-02\n"," 3.4727160e-02 7.6916686e-04]\n","train loss: 0.0299\n","train AUC: 0.9969\n","valid axial\n","load_data abnormal axial\n","using alexnet ...\n","threshold is:  [2.         1.         0.99999964 0.9999995  0.99897707 0.99893576\n"," 0.99871516 0.9980605  0.9877949  0.9867959  0.98216045 0.9728117\n"," 0.9701095  0.9696853  0.9650926  0.9633823  0.9586065  0.9557146\n"," 0.93265116 0.9130094  0.8980553  0.88797486 0.8271057  0.4136756\n"," 0.33950478 0.1803498  0.16922788 0.00889765]\n","valid loss: 0.3200\n","valid AUC: 0.9309\n","valid sagittal\n","load_data abnormal sagittal\n","using alexnet ...\n","threshold is:  [1.9999999e+00 9.9999988e-01 9.9999976e-01 9.9999809e-01 9.9999642e-01\n"," 9.9999547e-01 9.9442577e-01 9.9378729e-01 9.9203944e-01 9.9180341e-01\n"," 9.8283917e-01 9.7215456e-01 9.3919629e-01 9.3671155e-01 8.6262536e-01\n"," 8.1133938e-01 8.0679530e-01 7.8252721e-01 6.4628971e-01 6.3276386e-01\n"," 6.1051089e-01 5.1724821e-01 4.7622371e-01 3.0345780e-01 2.9656604e-01\n"," 2.9650652e-01 2.6806986e-01 1.8070059e-04]\n","valid loss: 0.1754\n","valid AUC: 0.9528\n","valid coronal\n","load_data abnormal coronal\n","using alexnet ...\n","threshold is:  [1.9999993  0.9999993  0.9992047  0.9991954  0.99739    0.997282\n"," 0.9911157  0.99051535 0.98911184 0.98786515 0.9837059  0.98336005\n"," 0.95334613 0.9471744  0.9320835  0.9204452  0.8926087  0.8888318\n"," 0.84413844 0.80027264 0.6711988  0.65301126 0.61299634 0.5195453\n"," 0.3362154  0.1786145  0.17714415 0.04342065 0.01296966 0.00872828]\n","valid loss: 0.3297\n","valid AUC: 0.8476\n","test axial\n","load_data abnormal axial\n","using alexnet ...\n","threshold is:  [2.         1.         0.99999964 0.9999994  0.9999993  0.9999988\n"," 0.99999857 0.99646914 0.9946596  0.9922421  0.9897474  0.9677031\n"," 0.9567     0.9266472  0.9094887  0.906306   0.8924616  0.8720102\n"," 0.86519295 0.84417945 0.8208232  0.81101644 0.7945786  0.71608436\n"," 0.6961599  0.6481416  0.61730635 0.44960293 0.38906756 0.25063682\n"," 0.17634426 0.13758858 0.11218417 0.09780553 0.09154634 0.0915444\n"," 0.05518856 0.03141411 0.01459791 0.01220363 0.00296568]\n","test loss: 0.2572\n","test AUC: 0.8696\n","test sagittal\n","load_data abnormal sagittal\n","using alexnet ...\n","threshold is:  [1.9999989e+00 9.9999893e-01 9.9999332e-01 9.9998891e-01 9.9630129e-01\n"," 9.9581701e-01 9.9579042e-01 9.9555761e-01 9.1801602e-01 9.0860212e-01\n"," 8.8488764e-01 8.8348484e-01 6.7652428e-01 6.7465478e-01 6.5879339e-01\n"," 6.3909090e-01 6.2830150e-01 5.1422906e-01 4.6485877e-01 4.4971511e-01\n"," 3.8486773e-01 3.5535213e-01 2.6291272e-01 1.8438247e-01 9.9945121e-02\n"," 7.7596635e-02 4.9657542e-02 4.6628643e-02 2.4491899e-02 2.7371072e-03\n"," 1.7697115e-03 1.4615740e-03 1.4267510e-03 1.6711361e-04]\n","test loss: 0.2332\n","test AUC: 0.8628\n","test coronal\n","load_data abnormal coronal\n","using alexnet ...\n","threshold is:  [1.9999987e+00 9.9999869e-01 9.4354677e-01 9.4208223e-01 8.7940490e-01\n"," 8.7309629e-01 8.2592088e-01 8.2322222e-01 7.0061910e-01 6.7092431e-01\n"," 6.6102791e-01 5.6116217e-01 5.4343230e-01 5.3827977e-01 5.0567234e-01\n"," 4.7095320e-01 4.2898667e-01 3.6504364e-01 2.7329007e-01 2.5922784e-01\n"," 2.4319966e-01 2.1779649e-01 2.0240428e-01 1.4289744e-01 1.1724052e-01\n"," 1.0854321e-01 9.4657443e-02 7.8292839e-02 5.6914318e-02 2.6853384e-02\n"," 1.8903874e-02 3.9106794e-03 2.0724344e-03 1.3540984e-03]\n","test loss: 0.1578\n","test AUC: 0.8928\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wnnbmXcnqj94","colab_type":"code","outputId":"98fe575f-d97e-43d8-e4c3-797cb624a186","executionInfo":{"status":"ok","timestamp":1584859264180,"user_tz":240,"elapsed":2761480,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDNUmrksb7ajH78ufM6_UhkFXwnC92mfPrGlVMselGrCi2rbtT0RQTAE_W4zYdJlR6aRmzSVhjT80-h3VIfU6oz4DdPcu1COE603poXAwZZwbjxVz7SdY15e4W-G1rSf0GdaX0RhwIQ3SCH7giErHIWSqvBbBvd6sPUBCVgz8GihsOSy95wrKgqRwkP1RYUlrR7BxEExDGXAZfVBPT9U9rVFnj_5OfLaLDSope-ENe1fImfSvHG_YxuUfNYgYDkt_iwJ_fZOtnZN1YoVk04CYKPxemoL3vhDb70jPfCUsYujJYeOzdApu63nJPpw4t6Tw043CpVLDWu8TlmMjPVFnxTViBUWTQ5wk_Pi0H5Nuy4H23usZTaF7MUXZg9a6b_T9AUCYLalA1Q9hnZhE4-tf0fhSz_F-yahMY8vdcF4gp3FLrysZMZxL9ntqnmBbG2_s0X17adoEfSrFfVbE4396BHDBbGmhhJ8ExSaYjLeWnoPlGjLWBxsOMuqnvRdUcml6BWDDkiusX6JgGH1EAJ9vl43dmYTwMdo_xNS9T4RfzHvHIfREZfOgUYalTU9UWYsw7Vnd1mM-CaC8mxVvfTmPX2HDu78BxDQeUkI1Yr40DBz3Ksj8shOu9Qcdt8vWGmLWkSXnbM8Yb1Yzi1NCx6stye_S25D94XuMWaXUErG8gua7KVULH7-4SOnZ9xQCza5-r-R8boJnclvGWaxk69gwjFE--isLStSMqZ7w-_wXwcFSsS5V0-wwKqlroqAX7fqzrw=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["print('meniscus prediction values: train 3 oris, valid 3 oris, test 3 oris')\n","print(np.array(predslist_meniscus))\n","print(np.array(predslist_meniscus).shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["meniscus prediction values: train 3 oris, valid 3 oris, test 3 oris\n","[[list([0.100345574, 0.9806981, 0.1235729, 0.8986333, 0.0355485, 0.18640155, 0.03114789, 0.068646275, 0.4062755, 0.2698479, 0.97818893, 0.005730499, 0.056822166, 0.69964916, 0.0023500065, 0.34520692, 0.67486537, 0.00095475675, 0.7525386, 0.99786985, 0.88478893, 0.021545384, 0.769134, 0.004418041, 0.13788033, 0.01839473, 0.0035090114, 0.72927105, 0.47281483, 0.4006957, 0.95046616, 0.09405548, 0.8193048, 0.961641, 0.48925805, 0.76937544, 0.7948358, 0.7753738, 0.68292975, 0.84379226, 0.17789549, 0.043149468, 0.80087435, 0.95334256, 0.042563546, 0.9596362, 0.013860825, 0.08101549, 0.022852363, 0.9573596, 0.093517765, 0.018515907, 0.9080531, 0.005763147, 0.9503528, 0.13167427, 0.017446375, 0.9615856, 0.105089754, 0.7578834, 0.016394233, 0.19601604, 0.09918726, 0.9085356, 0.0006561245, 0.121285304, 0.008411156, 0.8643106, 0.0019811767, 0.0748253, 0.95207834, 0.025742076, 0.8314501, 0.005516246, 0.028004363, 0.012359058, 0.0054523223, 0.008726708, 0.9815763, 0.99541795, 0.723427, 0.32596105, 0.0071863267, 0.024032764, 0.7681691, 0.024072466, 0.041343156, 0.5859992, 0.99214125, 0.89885885, 0.9455603, 0.9944614, 0.8958495, 0.05936744, 0.98820066, 0.21908468, 0.07122787, 0.63987446, 0.7051738, 9.294293e-05, 0.03492469, 0.092158854, 0.29059815, 0.027078144, 0.9508464, 0.8973384, 0.008141095, 0.07390797, 0.8290132, 0.9420786, 0.0020928115, 0.8656967, 0.38759083, 0.84016985, 0.5355783, 0.3039087, 0.786952, 0.002540485, 0.003381981, 0.8848738, 0.0011306846, 0.061368812, 0.20949917, 0.03366686, 0.056569405, 0.46540466, 0.91188985, 0.19865781, 0.006688275, 0.048824962, 0.94950897, 0.0027594233, 0.06211062, 0.051309183, 0.028464712, 0.08571721, 0.17402539, 0.9023661, 0.95538056, 0.062840484, 0.6399506, 0.01125032, 0.61342525, 0.026964856, 0.022990245, 0.027487945, 0.100765124, 0.46429083, 0.16377291, 0.0023702336, 0.8907816, 0.009227989, 0.91306037, 0.00097589195, 0.9319753, 0.49398988, 0.076338746, 0.54891515, 0.39446908, 0.9598528, 0.16738579, 0.15491408, 0.9197893, 0.2713286, 0.02302202, 0.012996936, 0.0025903692, 0.0048674773, 0.98816186, 0.02345642, 0.007476748, 0.46672267, 0.05448312, 0.01644024, 0.8896942, 0.019241853, 0.8557497, 0.017457405, 0.96988004, 0.93076706, 0.7730134, 0.005566556, 0.5940642, 0.87849367, 0.0009877749, 0.33987758, 0.8526466, 0.007374885, 0.53294307, 0.008493985, 0.102929816, 0.8914922, 0.2309328, 0.043129124, 0.9230758, 0.039527643, 0.34369978, 0.35419187, 0.93147266, 0.0059016533, 0.34437662, 0.0112769, 0.050725568, 0.9322644, 0.92846334, 0.12330682, 0.5427158, 0.055764362, 0.4939516, 0.013091339, 0.00018852114, 0.016129754, 0.012675079, 0.41552788, 0.00801591, 0.92996246, 0.0744278, 0.5642127, 0.05477101, 0.0007478975, 0.09930188, 0.0008310997, 0.004483334, 0.21051463, 0.021086767, 0.008079536, 0.03244374, 0.005188017, 0.009276117, 0.030828727, 0.0097472, 0.9851939, 0.0012411795, 0.06399125, 0.49384004, 0.6875742, 0.15211463, 0.0030192896, 0.00067172584, 0.0034115252, 0.8167479, 0.22076683, 0.03304948, 0.0002820451, 0.004366228, 0.025691705, 0.10956439, 0.19254193, 0.58880067, 0.24591167, 0.020419339, 0.9629827, 0.07177025, 0.859796, 0.35602796, 0.1591996, 0.00019240958, 0.07497844, 0.0008959617, 0.821619, 0.8681581, 0.04202368, 0.06189406, 0.8972703, 0.37921557, 0.95048726, 0.055906966, 0.0005440673, 0.03070537, 0.82368714, 0.9164153, 0.055926763, 0.007006429, 0.048285987, 0.0039518075, 0.08432018, 0.07691845, 0.6396572, 0.12395313, 0.03885069, 0.8631143, 0.85693324, 0.03768213, 0.01509232, 0.048099052, 0.87799674, 0.0377811, 0.019099003, 0.025419014, 0.059532154, 0.009045142, 0.011110492, 0.00949579, 0.015996644, 0.97222906, 0.075156264, 0.0010359467, 0.16727579, 0.93506306, 0.0012244029, 0.28633514, 0.0053965193, 0.9645475, 0.9108332, 0.606532, 0.6990671, 0.058900848, 0.0064922175, 0.11077877, 0.034402255, 0.048639517, 0.74074143, 0.7011473, 0.9644221, 0.8936279, 0.23178592, 0.7656672, 0.08117555, 0.9599396, 0.80519885, 0.92229176, 0.9597361, 0.045467496, 0.75670284, 0.6718271, 0.8804146, 0.9487899, 0.9912021, 0.98492694, 0.99284524, 0.0464085, 0.9733729, 0.8638594, 0.9531102, 0.024951018, 0.03680266, 0.09609601, 0.0061723758, 0.033035386, 0.015931401, 0.95207393, 0.13950317, 0.045742344, 0.7945178, 0.9176649, 0.121456504, 0.04431577, 0.7590115, 0.9221898, 0.14452869, 0.544033, 0.14900903, 0.017295668, 0.00095117354, 0.05659416, 0.80419046, 0.96904147, 0.00054587336, 0.015584423, 0.048546944, 0.97600436, 0.98885614, 0.07800022, 0.084211506, 0.033559244, 0.0318456, 0.15079091, 0.079274826, 0.75502515, 0.058792118, 0.9940969, 0.48224205, 0.0029267, 0.64463747, 0.8971668, 0.00604077, 0.009618387, 0.00050125865, 0.9088918, 0.048016224, 0.75744694, 0.021068783, 0.98068374, 0.7971876, 0.00057776266, 0.93908185, 0.59349936, 0.0018183041, 0.4313926, 0.17487313, 0.120061174, 0.1999235, 0.777685, 0.01079413, 0.033500385, 0.02070054, 0.100891426, 0.9649779, 0.115785584, 0.28363544, 0.017536607, 0.007422665, 0.0014828015, 0.12464233, 0.005581931, 0.026145065, 0.016131798, 0.82135427, 0.9421187, 0.0007547148, 0.029682763, 0.0020923375, 0.010079591, 0.0077678245, 0.94349897, 0.018172354, 0.9261681, 0.9680582, 0.007943005, 0.60910326, 0.04138923, 0.56207144, 0.010185952, 0.9579596, 0.00020843664, 0.00012973718, 0.6925982, 0.018735131, 0.00085360144, 0.83545077, 0.027293509, 0.9424177, 0.98923653, 0.9420679, 0.013190234, 0.018351633, 0.012077043, 0.016530836, 0.006650957, 0.14690912, 0.1355773, 0.8954843, 0.011155595, 0.012692653, 0.9982236, 0.03223256, 0.93822473, 0.64484924, 0.45542887, 0.13911349, 0.1549376, 0.025523996, 0.7425932, 0.058076013, 0.001826787, 0.026555697, 0.9819886, 0.90938485, 0.9290505, 0.01212611, 0.0036858332, 0.0066673043, 0.013345964, 0.7841613, 0.064729705, 0.0050622793, 0.036520477, 0.0061247544, 0.06894759, 0.97211117, 0.9885925, 0.28565037, 0.0019584957, 0.0010347683, 0.9796101, 0.0056631803, 0.011340315, 0.00066879444, 0.9624682, 0.1278784, 0.15077816, 0.79073876, 0.9276535, 0.0010247071, 0.019965898, 0.010257056, 0.45411158, 0.96458054, 0.91868657, 0.64271146, 0.35744852, 0.0038075098, 0.015492756, 0.035351917, 0.95723355, 0.031066436, 0.0225873, 0.41522837, 0.2514785, 0.034790836, 0.75817245, 0.5798365, 0.7158021, 0.010289015, 0.04150645, 0.19894212, 0.9454035, 0.69682825, 0.97519344, 0.00014325237, 0.0032643434, 0.96065485, 0.0018558325, 0.22273313, 0.16517264, 0.052900005, 0.004676808, 0.83927757, 0.9812245, 0.034487557, 0.033863828, 0.51828957, 0.82305986, 0.015358287, 0.64329726, 0.022728853, 0.7311757, 0.42282838, 0.9556624, 0.44066018, 0.8542333, 0.83714074, 0.11939627, 0.0146239195, 0.011946241, 0.5460455, 0.023884093, 0.030130565, 0.12005594, 0.014271076, 0.14127779, 0.17245886, 0.023187067, 0.9381592, 0.6345646, 0.026623772, 0.7965662, 0.7922129, 0.109052345, 0.08230285, 0.0762701, 0.960439, 0.008748042, 0.65653366, 0.96969295, 0.07034206, 0.49296722, 0.8205077, 0.009247376, 0.82556266, 0.0045320573, 0.8975444, 0.008442548, 0.0033184162, 0.94620275, 0.002714136, 0.008419098, 0.91788006, 0.01861384, 0.9749346, 0.90699655, 0.022898817, 0.93942463, 0.34618962, 0.048163015, 0.9451316, 0.94247985, 0.96541315, 0.049511783, 0.8690553, 0.004777743, 0.96459985, 0.6889089, 0.0034414532, 0.10363904, 0.9841352, 0.9985896, 0.4537859, 0.0026427621, 0.009342682, 0.011794677, 0.09816547, 0.013752315, 0.17984279, 0.9405667, 0.12733221, 0.90206933, 0.0051669716, 0.15003268, 0.034831192, 0.00054127205, 0.8044816, 0.94932544, 0.13889217, 0.84484524, 0.81658167, 0.21633036, 0.53258586, 0.0015727085, 0.017993774, 0.017873565, 0.40271947, 0.06783612, 0.2488264, 0.5775571, 0.10945277, 0.00028687625, 0.989205, 0.09947155, 0.940709, 0.8794672, 0.0033347337, 0.00070765044, 0.15237366, 0.9168545, 0.0007724183, 0.20859106, 0.013806137, 0.89644194, 0.67534643, 0.028954756, 0.6536647, 0.073098674, 0.9442936, 0.06600164, 0.61671054, 0.73131436, 0.006792328, 0.020958848, 0.34480432, 0.14403664, 0.00046875034, 0.8517831, 0.015131582, 0.025907697, 0.9258383, 0.96303004, 0.017748091, 0.5702134, 0.92674804, 0.08106829, 0.16545115, 0.042398814, 0.3914138, 0.9628577, 0.9614746, 0.08800391, 0.66002023, 0.0038851297, 0.038587324, 0.8541322, 0.6450343, 0.6549566, 0.009222733, 0.014158756, 0.06122849, 0.9616435, 0.58307576, 0.03573552, 0.11939374, 0.12152136, 0.018120725, 0.8027621, 0.035872992, 0.001080184, 0.00065826625, 0.56861156, 0.95968133, 0.0035295899, 0.9821867, 0.9221483, 0.6177031, 0.1121653, 0.9186845, 0.6923192, 0.004730403, 0.24052979, 0.9696489, 0.7285781, 0.03298242, 0.07354024, 0.9955864, 0.8755699, 0.97102803, 0.121089615, 0.029521104, 0.035945058, 0.07991538, 0.97321284, 0.96575344, 0.018378256, 0.87709266, 0.0092485985, 0.0037964717, 0.0061076507, 0.16720417, 0.0024585146, 0.4931179, 0.50888735, 0.027226852, 0.75225055, 0.0007497865, 0.008310562, 0.1614333, 0.15423808, 0.0077915946, 0.8699081, 0.15546013, 0.9420111, 0.07614358, 0.9776342, 0.70612115, 0.20049463, 0.9972166, 0.7819506, 0.0039238953, 0.6917817, 0.010467095, 0.021810288, 0.01933595, 0.015753768, 0.27116805, 0.002161316, 0.057321742, 0.11358426, 0.5404335, 0.8413772, 0.22891943, 0.0066240723, 0.7267298, 0.8702252, 0.018159699, 0.9142645, 0.086707905, 0.0024330493, 0.13964342, 0.7015882, 0.0017571803, 0.061288465, 0.82650393, 0.9678841, 0.87579566, 0.7002965, 0.892821, 0.0051566064, 0.0057409033, 0.023523193, 0.14036031, 0.01498608, 0.025111614, 0.7363695, 0.97731453, 0.04309019, 0.092291325, 0.46079263, 0.24582376, 0.8067351, 0.0032626977, 0.806981, 0.8567867, 0.07572992, 0.09730931, 0.052784596, 0.9931312, 0.045391284, 0.9832977, 0.7460911, 0.07513908, 0.8637604, 0.988908, 0.07677744, 0.5963461, 0.08086041, 0.9751263, 0.89967513, 0.8595518, 0.3471769, 0.48291698, 0.0045473743, 0.023421979, 0.6948093, 0.9815028, 0.23965888, 0.9275713, 0.093634754, 0.0073429584, 0.017796902, 0.04774305, 0.0060092416, 0.0005819957, 0.006264848, 0.33782348, 0.058970544, 0.25349513, 0.006092577, 0.034119878, 0.002891021, 0.034272786, 0.0023033998, 0.040603884, 0.6488009, 0.011560797, 0.45783788, 0.009370075, 0.29566804, 0.18429473, 0.09976586, 0.96644753, 0.0022061823, 0.6429897, 0.0565569, 0.007173532, 0.81636083, 0.015928052, 0.00038227678, 0.008651368, 0.38197604, 0.08468228, 0.0709985, 0.023996616, 0.8427214, 0.3196822, 0.058121726, 0.8455835, 0.6274209, 0.93996143, 0.16543174, 0.41521916, 0.2713803, 0.025664447, 0.36412594, 0.008337853, 0.97606546, 0.98887223, 0.0068724095, 0.05044837, 0.90063304, 0.9362405, 0.085570194, 0.017467469, 0.08044712, 0.24022524, 0.39511085, 0.78490967, 0.9510624, 0.009526043, 0.015997456, 0.802798, 0.0013145185, 0.002066995, 0.06311413, 0.0058222115, 0.83231264, 0.9453, 0.9739957, 0.04110112, 0.013593437, 0.0019112118, 0.0050507933, 0.32560396, 0.81792086, 0.48488188, 0.00027742618, 0.21526207, 0.00047989085, 0.24681976, 0.0006482018, 0.01408394, 0.028835695, 0.026397245, 0.08919487, 0.9846859, 0.12737006, 0.00075652834, 0.8315133, 0.993254, 0.005427844, 0.9586561, 0.042626843, 0.13731682, 0.64488447, 0.9027385, 0.87159866, 0.18726215, 0.00043997882, 0.98854256, 0.009243216, 0.63132024, 0.42246893, 0.0060039144, 0.85482645, 0.01284802, 0.87792116, 0.2745002, 0.012314193, 0.08801953, 0.12253725, 0.010597083, 0.06298978, 0.9045119, 0.9835513, 0.4976132, 0.9629294, 0.96959746, 0.9908303, 0.07203761, 0.96578526, 0.7414458, 0.0067551495, 0.23118296, 0.60490733, 0.08349542, 0.9762941, 0.94022715, 0.017010456, 0.0010647087, 0.013222866, 0.96753526, 0.209936, 0.0008864047, 0.051566955, 0.9640387, 0.91325283, 0.021500675, 0.004156274, 0.02615624, 0.16175926, 0.00021606062, 0.99165714, 0.12954102, 0.21598224, 0.8338935, 0.006547584, 0.39786848, 0.0027064697, 0.8931395, 0.025968296, 0.00096500444, 0.7959355, 0.6918476, 0.86421156, 0.08645358, 0.28790572, 0.0037152166, 0.18485226, 0.5558751, 0.01946107, 0.054466993, 0.05421148, 0.0017036119, 0.017579593, 0.9214209, 0.0006672029, 0.84984815, 0.9500205, 0.10898998, 0.006867371, 0.10676501, 0.1562574, 0.6695917, 0.78146946, 0.050370786, 0.6590826, 0.0062003992, 0.15645875, 0.10627652, 0.052016046, 0.95981485, 0.8789119, 0.1618475, 0.8440223, 0.054643866, 0.7551146, 0.004293401, 0.014237449, 0.12538858, 0.18435137, 0.13602076, 0.015614254, 0.7431858, 0.27748045, 0.016212778, 0.021231215, 0.8461584, 0.8646429, 0.03940304, 0.10148457, 0.00028744078, 0.007805815, 0.92826074])]\n"," [list([0.6043759, 0.9692388, 0.15156528, 0.7938348, 0.091205336, 0.7027166, 0.12145643, 0.039641526, 0.45282125, 0.1877778, 0.96984565, 0.28417388, 0.11464179, 0.81498545, 0.028714078, 0.4449989, 0.6514846, 0.049225762, 0.66998327, 0.97283167, 0.87662953, 0.0497203, 0.689791, 0.04427951, 0.53891706, 0.034902714, 0.025770823, 0.72928613, 0.6687755, 0.40781862, 0.77547264, 0.7813916, 0.926791, 0.62621534, 0.64188826, 0.47813222, 0.39064035, 0.6462973, 0.74553394, 0.7228291, 0.049167294, 0.24491745, 0.7999498, 0.9731952, 0.04580189, 0.910752, 0.17089526, 0.39599502, 0.05933545, 0.81903386, 0.43364915, 0.05236404, 0.830038, 0.016188687, 0.95591456, 0.0811621, 0.01817911, 0.78999674, 0.75623745, 0.70094734, 0.19992387, 0.094024375, 0.21384881, 0.95161057, 0.003276975, 0.26059374, 0.020457512, 0.4287988, 0.12189228, 0.07774055, 0.89828825, 0.31056327, 0.94249034, 0.23268363, 0.12562917, 0.13768578, 0.20544742, 0.011520121, 0.96972847, 0.82909536, 0.7740505, 0.48880732, 0.019942492, 0.25744468, 0.3446187, 0.18456422, 0.30948853, 0.9219059, 0.7330959, 0.7300318, 0.8230207, 0.980006, 0.7952812, 0.43743816, 0.9742677, 0.510519, 0.078969665, 0.55892193, 0.45150816, 0.0036474166, 0.027254723, 0.21597177, 0.49936113, 0.7830607, 0.98040533, 0.47277567, 0.014777561, 0.34858316, 0.8953661, 0.8523045, 0.005004694, 0.82492346, 0.32040697, 0.68202126, 0.3114246, 0.2182661, 0.28300443, 0.006476323, 0.006751116, 0.82656765, 0.008268235, 0.5870262, 0.23874803, 0.02158901, 0.082899064, 0.20902741, 0.8984918, 0.43424907, 0.1766655, 0.21805882, 0.47794202, 0.09651453, 0.045100268, 0.33297932, 0.022767186, 0.2930611, 0.399353, 0.9082894, 0.85870194, 0.36562094, 0.53424287, 0.18783168, 0.70887, 0.0031850517, 0.0019251097, 0.67203707, 0.37921536, 0.19931014, 0.23068565, 0.016312698, 0.90875036, 0.047682945, 0.9511294, 0.0077758706, 0.88310933, 0.7158544, 0.41957682, 0.92476153, 0.41795993, 0.96348244, 0.29609188, 0.6298012, 0.949495, 0.5196393, 0.06569993, 0.11390587, 0.04439641, 0.16825289, 0.9540029, 0.0073241265, 0.05086931, 0.63472635, 0.11351628, 0.010438282, 0.85687166, 0.06292971, 0.695417, 0.022353185, 0.84586173, 0.7427272, 0.58964986, 0.07839871, 0.5387282, 0.6607826, 0.011081657, 0.61008185, 0.75500804, 0.10308726, 0.74352056, 0.014563007, 0.035720672, 0.82813805, 0.30503154, 0.34607798, 0.7253613, 0.0046216873, 0.5826152, 0.19157791, 0.9583088, 0.08053264, 0.7497385, 0.20171727, 0.08966098, 0.88807225, 0.834151, 0.062107556, 0.65026706, 0.5658032, 0.4895435, 0.10144505, 0.012792422, 0.113643415, 0.21751335, 0.1884299, 0.061002295, 0.7164919, 0.15249889, 0.89169925, 0.51006263, 0.081788555, 0.15758136, 0.04262915, 0.01982912, 0.19647554, 0.8867229, 0.022447629, 0.20919006, 0.0067343153, 0.004977535, 0.088409156, 0.023909254, 0.9490258, 0.06259782, 0.38664675, 0.67652106, 0.54777944, 0.055225708, 0.083486825, 0.0041477736, 0.0067211366, 0.6507796, 0.33950886, 0.035919398, 0.00645143, 0.033068348, 0.024796009, 0.18004249, 0.2734024, 0.5490706, 0.3518767, 0.07041315, 0.89074045, 0.32903153, 0.9820994, 0.2597101, 0.5617624, 0.02404939, 0.06657257, 0.023050379, 0.39844164, 0.8683328, 0.20332704, 0.12599513, 0.5525769, 0.38261384, 0.9901333, 0.04154475, 0.0019850498, 0.09279071, 0.60454255, 0.9370384, 0.2795942, 0.025023514, 0.03794252, 0.11574226, 0.059295975, 0.34198672, 0.93919814, 0.12533142, 0.03652389, 0.59123594, 0.8006672, 0.038100623, 0.14908803, 0.3082282, 0.82355934, 0.33204865, 0.13331585, 0.083375975, 0.5011164, 0.35010698, 0.06603825, 0.14219204, 0.34720182, 0.7689185, 0.66833436, 0.06761042, 0.2622429, 0.7913402, 0.34509948, 0.14273125, 0.043274548, 0.8064869, 0.8529764, 0.2681533, 0.939435, 0.089888066, 0.014077571, 0.19740377, 0.021348314, 0.08069582, 0.4222364, 0.71561056, 0.7147258, 0.9774719, 0.7360193, 0.30084956, 0.2660783, 0.78676075, 0.8389037, 0.9787249, 0.9128902, 0.4207367, 0.7851573, 0.675465, 0.63494444, 0.9427226, 0.8267134, 0.7977137, 0.8958131, 0.72072107, 0.86638033, 0.894753, 0.82941395, 0.13067546, 0.3107718, 0.06500302, 0.005130109, 0.008541032, 0.0637954, 0.89754266, 0.71555495, 0.009998059, 0.46379128, 0.9726776, 0.71659946, 0.119265966, 0.96904343, 0.93305504, 0.72934395, 0.81008244, 0.6983196, 0.27833152, 0.0038800547, 0.010387049, 0.84626937, 0.8882479, 0.022845155, 0.19340336, 0.04318825, 0.67121637, 0.8973397, 0.22091812, 0.2187137, 0.25041077, 0.08460064, 0.6350705, 0.07617797, 0.9640444, 0.084602416, 0.78209907, 0.1342637, 0.010359007, 0.75762737, 0.6461126, 0.023183413, 0.24849392, 0.008366631, 0.8396931, 0.22643998, 0.92645764, 0.06966271, 0.8420385, 0.90980387, 0.019073872, 0.809703, 0.92472684, 0.0070222346, 0.51523393, 0.3526259, 0.12998362, 0.3458502, 0.65669465, 0.21655174, 0.13982655, 0.2802371, 0.4949797, 0.7475285, 0.22185314, 0.037560727, 0.09816336, 0.50040317, 0.12306158, 0.44299152, 0.02288042, 0.038931355, 0.010003289, 0.8441747, 0.77655995, 0.034239776, 0.10332555, 0.15361188, 0.16140807, 0.011943314, 0.9167492, 0.026639497, 0.9424106, 0.94915146, 0.0422768, 0.40339777, 0.06715496, 0.5548573, 0.008561123, 0.94112337, 0.026999798, 0.007889924, 0.8582446, 0.19168073, 0.009824492, 0.6314953, 0.09550227, 0.8766232, 0.99379444, 0.67271006, 0.0255075, 0.053580236, 0.12523063, 0.01911206, 0.005466531, 0.08796592, 0.75801533, 0.9755029, 0.15520518, 0.42896, 0.90940934, 0.17112805, 0.59741604, 0.8699318, 0.33864695, 0.51580083, 0.09881864, 0.07714172, 0.8138532, 0.22761045, 0.0051243245, 0.31464952, 0.9454813, 0.8497978, 0.9557351, 0.30667546, 0.039159074, 0.04463711, 0.09935951, 0.9413523, 0.2307431, 0.051551078, 0.054889604, 0.23339821, 0.044389382, 0.7538262, 0.9714121, 0.47717768, 0.025456019, 0.037250824, 0.7310635, 0.01621262, 0.046732243, 0.009110895, 0.9177123, 0.024057513, 0.23154435, 0.22271858, 0.38757378, 0.01608071, 0.1390155, 0.45498893, 0.043508805, 0.905285, 0.69762313, 0.6916628, 0.7288742, 0.014477132, 0.13376988, 0.27735424, 0.596291, 0.108457945, 0.43022263, 0.43106067, 0.8442798, 0.10219689, 0.82955855, 0.9179755, 0.70284367, 0.004865891, 0.16943292, 0.073906094, 0.92808115, 0.26931524, 0.5403069, 0.010083997, 0.08838339, 0.91791403, 0.107823044, 0.10459584, 0.15242255, 0.113885015, 0.040412582, 0.8168842, 0.95072436, 0.09125578, 0.11728368, 0.14937304, 0.45964643, 0.102020495, 0.81051344, 0.008398689, 0.89369595, 0.87038076, 0.8353081, 0.40562585, 0.8648013, 0.5235123, 0.16281712, 0.04485176, 0.058876295, 0.4177665, 0.37306073, 0.2590385, 0.45370093, 0.29373276, 0.37233555, 0.093651794, 0.07231601, 0.9143455, 0.3943744, 0.14025868, 0.86486363, 0.7684954, 0.1913398, 0.17649059, 0.2998184, 0.90757906, 0.11992947, 0.71422845, 0.6157099, 0.517458, 0.1978249, 0.86530495, 0.013896216, 0.5569478, 0.20480599, 0.86228514, 0.019348565, 0.063336864, 0.9561756, 0.026824482, 0.079138115, 0.4895179, 0.028022217, 0.93527484, 0.4575923, 0.13281289, 0.88336796, 0.55952173, 0.048717413, 0.9762487, 0.46222806, 0.8861564, 0.06252382, 0.9014375, 0.1790187, 0.8869061, 0.7242523, 0.016132584, 0.17753929, 0.74106264, 0.98823524, 0.58199084, 0.048892427, 0.04391713, 0.18906794, 0.59012234, 0.3001246, 0.4757571, 0.9465035, 0.36045977, 0.6333744, 0.2462174, 0.07729174, 0.47108057, 0.041513216, 0.7179599, 0.8234193, 0.54882044, 0.5934976, 0.85394114, 0.55169785, 0.91024303, 0.066147804, 0.15017559, 0.23737668, 0.5414222, 0.18675967, 0.17732234, 0.33638182, 0.008357979, 0.08653163, 0.9717211, 0.3654416, 0.9388311, 0.6422248, 0.07172757, 0.042014547, 0.26240683, 0.85040516, 0.028354075, 0.110159814, 0.1516869, 0.96668684, 0.8299644, 0.111222446, 0.5312233, 0.06862849, 0.93563265, 0.053265, 0.39003277, 0.88896406, 0.10984262, 0.04075739, 0.24163331, 0.45727065, 0.009692815, 0.42074886, 0.17355092, 0.03743825, 0.9406916, 0.77266645, 0.7137636, 0.9458417, 0.8593687, 0.18233347, 0.1974405, 0.65036076, 0.39490938, 0.8809658, 0.97443193, 0.13719593, 0.4298807, 0.010340443, 0.31630537, 0.76084787, 0.9420917, 0.976233, 0.01906465, 0.061743636, 0.13928582, 0.9779834, 0.7506005, 0.13749337, 0.26105043, 0.4924482, 0.02475657, 0.8439003, 0.39916626, 0.078102656, 0.009108604, 0.062322408, 0.94420755, 0.032504667, 0.96132517, 0.46969575, 0.55955374, 0.04891499, 0.9836699, 0.3642722, 0.08048361, 0.05596108, 0.89414877, 0.5998081, 0.17218055, 0.34737104, 0.97795403, 0.44653356, 0.7501195, 0.07905308, 0.004957849, 0.26676223, 0.69893676, 0.9295215, 0.76157, 0.07949526, 0.852466, 0.111772254, 0.02088821, 0.06472133, 0.23645215, 0.011131032, 0.75337815, 0.6295191, 0.5085832, 0.47685337, 0.021275243, 0.022549061, 0.6527225, 0.11104766, 0.011823182, 0.78395736, 0.51346326, 0.93305993, 0.2232448, 0.81884706, 0.8326837, 0.2960399, 0.8880911, 0.7869012, 0.10172319, 0.80895376, 0.0038673733, 0.1929096, 0.11464666, 0.058852524, 0.80292684, 0.15095589, 0.23763779, 0.08121194, 0.60639596, 0.75064224, 0.2679121, 0.12543641, 0.31433013, 0.875519, 0.13614756, 0.87979233, 0.2841662, 0.1648484, 0.17462456, 0.83950394, 0.02961425, 0.4927069, 0.95575523, 0.84146076, 0.8858788, 0.48717722, 0.80790263, 0.048571397, 0.048025206, 0.31109676, 0.7474791, 0.119485356, 0.044180576, 0.6369321, 0.95169854, 0.14719328, 0.1626306, 0.83631754, 0.4235155, 0.68813366, 0.085712545, 0.97516453, 0.43832278, 0.13416764, 0.11446714, 0.056897372, 0.9162498, 0.026087292, 0.73856395, 0.5303595, 0.09761113, 0.8429231, 0.85090536, 0.1410596, 0.2077633, 0.1608909, 0.6714598, 0.860645, 0.83798, 0.35755044, 0.5699857, 0.019007703, 0.697397, 0.89940035, 0.96177804, 0.5930249, 0.4650418, 0.81736016, 0.120969504, 0.09833392, 0.08802003, 0.013405911, 0.013521427, 0.02214936, 0.29515713, 0.0013957536, 0.1028005, 0.035509333, 0.01236155, 0.019767385, 0.04817474, 0.07558567, 0.0054336595, 0.83489, 0.0067719086, 0.8497993, 0.031916045, 0.36780566, 0.57973325, 0.29567656, 0.94180804, 0.016012061, 0.14078034, 0.48103878, 0.0065647596, 0.7321449, 0.053462613, 0.0031781392, 0.032839265, 0.1851988, 0.018626312, 0.14313541, 0.51047087, 0.954917, 0.8686362, 0.149051, 0.9630236, 0.12920018, 0.859059, 0.4966249, 0.86750567, 0.19761871, 0.28548977, 0.29738566, 0.09752339, 0.90709025, 0.90878105, 0.023824805, 0.11842656, 0.7932425, 0.9480811, 0.07199461, 0.032294612, 0.7752265, 0.32238954, 0.66536057, 0.7211203, 0.76024365, 0.039092887, 0.18863343, 0.8698823, 0.009708459, 0.034018368, 0.0012299166, 0.09692962, 0.6220929, 0.9648595, 0.91229767, 0.01705788, 0.009638526, 0.021998342, 0.022981122, 0.2036696, 0.7810052, 0.86907, 0.02354236, 0.16004562, 0.0052658934, 0.32059276, 0.14131823, 0.13993764, 0.46405968, 0.02494426, 0.4485119, 0.91787535, 0.6278061, 0.010490225, 0.43947133, 0.94203895, 0.01575603, 0.81472665, 0.31134376, 0.60487753, 0.43833664, 0.896446, 0.73195, 0.21446711, 0.0108755855, 0.9158428, 0.012295967, 0.6374163, 0.5562602, 0.013481835, 0.93236935, 0.030343985, 0.64344335, 0.33221948, 0.03992727, 0.2682931, 0.0550579, 0.016496822, 0.20439616, 0.8005729, 0.8715025, 0.31833017, 0.9081446, 0.8067403, 0.818872, 0.56628954, 0.9485161, 0.20728813, 0.3856493, 0.4755973, 0.87428105, 0.052349705, 0.8614327, 0.6701435, 0.16820018, 0.0017686757, 0.016953468, 0.9294362, 0.7197642, 0.007838885, 0.351438, 0.864671, 0.9552526, 0.12472185, 0.089005545, 0.012538566, 0.28666347, 0.03521049, 0.9870385, 0.63463587, 0.064081356, 0.8632931, 0.31546625, 0.56080407, 0.097285636, 0.8498083, 0.06026619, 0.011478992, 0.50023067, 0.64525175, 0.86927736, 0.6743826, 0.8009843, 0.19470419, 0.2558251, 0.65088433, 0.2127651, 0.3431532, 0.22810909, 0.009250482, 0.01083434, 0.97875595, 0.018912878, 0.88583183, 0.73567736, 0.2398059, 0.20647015, 0.5431287, 0.15726437, 0.5157478, 0.9109941, 0.42351335, 0.8560462, 0.012662464, 0.086096436, 0.7197357, 0.26102352, 0.89311653, 0.7364844, 0.7890272, 0.9588845, 0.12822762, 0.6970809, 0.10678952, 0.007795887, 0.5524224, 0.12339596, 0.38848147, 0.32628542, 0.71600306, 0.2410724, 0.041771594, 0.032999434, 0.8333504, 0.9132615, 0.06585171, 0.5020886, 0.006620468, 0.010228992, 0.7589429])]\n"," [list([0.30256417, 0.9650836, 0.11006628, 0.83285755, 0.015125514, 0.8525961, 0.2838499, 0.000105796855, 0.30529663, 0.15889995, 0.94952637, 0.00482022, 0.011673475, 0.5683427, 0.19412294, 0.1252891, 0.9432044, 0.0053012036, 0.9100358, 0.88056505, 0.9563956, 0.11645274, 0.9775589, 0.02058332, 0.010942602, 0.0115094995, 0.00043839356, 0.7680879, 0.5401177, 0.039107766, 0.8612649, 0.11713973, 0.88769454, 0.97650427, 0.8525606, 0.6088158, 0.8542134, 0.83080953, 0.76479614, 0.87351245, 0.0025822488, 0.0010010989, 0.55912644, 0.99873286, 0.0058107376, 0.9745174, 0.11843967, 0.13841759, 0.04894153, 0.8587915, 0.11508962, 0.038289327, 0.580597, 0.003646401, 0.974097, 0.28116065, 0.0019864815, 0.87312454, 0.35922778, 0.9385584, 0.006688585, 0.010476692, 0.040195715, 0.96831226, 0.0014735099, 0.24276644, 0.0004564297, 0.67267805, 0.010128987, 0.0016530999, 0.91499937, 0.59832233, 0.90540713, 0.031736225, 0.014667204, 0.015039882, 0.006911797, 0.001638027, 0.9112068, 0.98990434, 0.9875409, 0.4234803, 0.11758873, 0.083791435, 0.7801479, 0.14010829, 0.044832986, 0.5305302, 0.7459228, 0.9727586, 0.98185766, 0.99398005, 0.7330619, 0.013711075, 0.9940626, 0.12754697, 0.026411174, 0.2272395, 0.90386, 0.0031004457, 0.10356571, 0.4788794, 0.17200728, 0.2664713, 0.92049825, 0.9515948, 0.0035780051, 0.06673765, 0.97618264, 0.9072838, 0.0008628269, 0.90161926, 0.8185204, 0.98153037, 0.40365562, 0.10489006, 0.5328025, 0.015850129, 0.013735492, 0.9915671, 0.005528732, 0.665099, 0.1613774, 0.14090689, 0.06364675, 0.76803476, 0.95941746, 0.019163115, 0.002168146, 0.22890304, 0.8008416, 0.071624845, 0.0051272917, 0.2505137, 0.012972193, 0.0717729, 0.049086876, 0.881665, 0.991402, 0.054886807, 0.85901463, 0.024121962, 0.86874574, 0.026915483, 0.064916, 0.13915515, 0.41143677, 0.685224, 0.014107437, 0.07018571, 0.9465532, 0.38210946, 0.9459633, 0.002406447, 0.81932634, 0.5348701, 0.15213028, 0.85331404, 0.20482333, 0.99206597, 0.13835663, 0.10112513, 0.8406401, 0.29022092, 0.09053898, 0.06758528, 0.0068058167, 0.030720148, 0.93848324, 0.025779096, 0.0049749734, 0.9323627, 0.03478036, 0.02825989, 0.44647565, 0.19622482, 0.85762155, 0.2577123, 0.98849314, 0.91951114, 0.3646086, 0.0039291, 0.7948281, 0.6292677, 0.0126943495, 0.69595474, 0.90443903, 0.010680705, 0.823926, 0.002779525, 0.04992428, 0.59284407, 0.06306982, 0.01563046, 0.8439302, 0.000642541, 0.58568233, 0.121043056, 0.9917841, 0.004318377, 0.39241007, 0.17253464, 0.08334596, 0.67578566, 0.89887047, 0.06844101, 0.10607718, 0.03315499, 0.7924719, 0.001903996, 0.0007798847, 0.058036584, 0.06050618, 0.09913464, 0.009958787, 0.85868436, 0.33325496, 0.9923016, 0.22350264, 0.12628858, 0.5776717, 0.092580825, 0.037283752, 0.055294015, 0.3803642, 0.08619158, 0.1526109, 0.018027632, 0.0015587214, 0.014909103, 0.0002470884, 0.99881303, 0.12397774, 0.2748602, 0.56667715, 0.7911226, 0.02099225, 0.04872336, 0.028534764, 0.008396673, 0.9165313, 0.27803096, 0.5697947, 0.079665914, 0.019684285, 0.0019944345, 0.1699441, 0.01364096, 0.79300886, 0.11506537, 0.017904496, 0.9251938, 0.02121606, 0.8463722, 0.2709055, 0.64865845, 0.011327331, 0.107855506, 0.0024021044, 0.7994289, 0.8157209, 0.0091239475, 0.17662752, 0.97243947, 0.8100611, 0.96418464, 0.08653234, 0.005457504, 0.0058473297, 0.8322902, 0.9777949, 0.021009097, 0.045386318, 0.010575746, 0.46739683, 0.0812492, 0.07771887, 0.8371308, 0.3664755, 0.020029416, 0.94277656, 0.94543666, 0.035262708, 0.011703423, 0.4547969, 0.9512375, 0.2059372, 0.14191276, 0.0013420774, 0.4168054, 0.058797624, 0.0016353679, 0.14993814, 0.040846713, 0.8600816, 0.24289854, 0.0022977795, 0.15124676, 0.9828948, 0.0050688544, 0.13165528, 0.079000555, 0.9067618, 0.9145112, 0.652822, 0.9603095, 0.27120575, 0.13192068, 0.026502935, 0.053361934, 0.01709046, 0.82805926, 0.6026598, 0.9128302, 0.977824, 0.90237314, 0.8085414, 0.48559663, 0.6321681, 0.9373564, 0.999129, 0.86946845, 0.07366439, 0.9651132, 0.71193504, 0.98514706, 0.88282377, 0.9078699, 0.930711, 0.96138996, 0.012362795, 0.9855538, 0.9597296, 0.9945544, 0.0236387, 0.2872091, 0.022048704, 0.0004999943, 0.24005032, 0.019214265, 0.9883286, 0.60665935, 0.002447485, 0.67484236, 0.9234991, 0.03260103, 0.08372429, 0.9356363, 0.8832596, 0.0036381397, 0.5927152, 0.4345257, 0.13060674, 0.017426874, 0.007596949, 0.88615143, 0.5940509, 0.005569772, 0.040975984, 0.0011570024, 0.98005563, 0.9719291, 0.24206132, 0.41520223, 0.0058744624, 0.0047059106, 0.0033813894, 0.07817087, 0.95765513, 0.1574306, 0.9119194, 0.023335887, 0.0011368257, 0.62666863, 0.7966957, 0.046702523, 0.0666591, 0.010907228, 0.94403905, 0.02201539, 0.84322584, 0.003343261, 0.9904604, 0.9739127, 0.05867664, 0.8889113, 0.8713581, 0.00081551325, 0.85619855, 0.37690017, 0.06439775, 0.30699074, 0.9730926, 0.0047028586, 0.00020957911, 0.027796451, 0.19453923, 0.714333, 0.3005214, 0.025942672, 0.10769116, 0.04141779, 0.02253856, 0.0016715172, 0.012282505, 0.105654486, 0.07214605, 0.99697495, 0.8538717, 0.0075705997, 0.013433669, 0.0052315905, 0.019252235, 0.016149592, 0.9807484, 0.0039682155, 0.8257921, 0.9673235, 0.0055084303, 0.8016572, 0.033545386, 0.8826502, 0.058294788, 0.98725116, 0.016930811, 0.012039904, 0.7832416, 0.029340606, 0.00053950894, 0.8288458, 0.008586277, 0.8450047, 0.9813384, 0.9993772, 0.01604266, 0.08072641, 0.11700393, 0.0053253057, 0.042613406, 0.023590995, 0.56101954, 0.9962192, 0.013882952, 0.012987289, 0.90994567, 0.006321253, 0.5263382, 0.9620727, 0.14760712, 0.7885439, 0.094567716, 0.05077536, 0.29088306, 0.082835615, 0.0007747495, 0.04700083, 0.96952784, 0.89355457, 0.6774073, 0.107753605, 0.0037937148, 0.009739011, 0.03585887, 0.8444295, 0.010564536, 0.0086065885, 0.006854053, 0.003690324, 0.036761843, 0.8923354, 0.9933136, 0.49927482, 7.701145e-05, 0.00458013, 0.71786636, 0.0038083417, 0.026864568, 0.0017877697, 0.7946584, 0.051967435, 0.026157126, 0.78070104, 0.9351588, 0.0089400625, 0.11841321, 0.104556404, 0.056152575, 0.9662712, 0.6711959, 0.7316809, 0.9530324, 0.01865928, 0.097383775, 0.046911594, 0.7466719, 0.07858494, 0.26959348, 0.48367935, 0.10397999, 0.010258131, 0.91445684, 0.9848742, 0.9546156, 0.052846298, 0.044922244, 0.038525064, 0.9970958, 0.93607247, 0.3292079, 0.0016208258, 0.048072934, 0.8975357, 0.19269025, 0.11467389, 0.023901982, 0.12023845, 0.1518266, 0.90253115, 0.8046799, 0.055854853, 0.71864, 0.6019082, 0.8412753, 0.009963691, 0.94738764, 0.026486415, 0.51557976, 0.45253146, 0.5741581, 0.40062812, 0.8155676, 0.63099736, 0.0013141029, 0.002424298, 0.028384475, 0.74690497, 0.050482552, 0.05616378, 0.14442031, 0.018498493, 0.11494967, 0.11668791, 0.025367403, 0.8685311, 0.67389125, 0.034757793, 0.9441056, 0.4444588, 0.052883416, 0.19665802, 0.031983893, 0.9912566, 0.15631528, 0.7384725, 0.54880875, 0.25925407, 0.0030145466, 0.9362931, 0.04754719, 0.6316855, 0.008408472, 0.99663264, 0.43801814, 0.019302962, 0.73835945, 0.08826993, 0.029983483, 0.9578652, 0.07060916, 0.965743, 0.7021891, 0.0025300365, 0.9654331, 0.63865805, 0.23898736, 0.95485705, 0.5911313, 0.96157676, 0.0033594812, 0.9888137, 0.045794096, 0.99774915, 0.8171407, 0.020813627, 0.10682263, 0.95063967, 0.99284863, 0.0046003032, 0.014356997, 0.0007238003, 0.028216776, 0.119770445, 0.20086618, 0.8689039, 0.73768866, 0.44377357, 0.6828864, 0.04191914, 0.027896792, 0.7700353, 0.0072215963, 0.9701325, 0.66367626, 0.9635403, 0.3474028, 0.9811127, 0.3316665, 0.8924486, 0.039843306, 0.024935858, 0.019224416, 0.13139732, 0.45141193, 0.103646494, 0.07171111, 0.008297196, 0.06908553, 0.8510405, 0.09427352, 0.9840469, 0.9898986, 0.020748878, 0.16586086, 0.003981283, 0.9765189, 0.060282446, 0.03987983, 0.04667607, 0.8750145, 0.85701776, 0.23917495, 0.8837802, 0.059417415, 0.9288609, 0.0118658785, 0.84796035, 0.9746737, 0.004991751, 0.010950282, 0.7266839, 0.04963969, 0.0095189065, 0.870043, 0.0053604227, 0.0067600873, 0.9795201, 0.9388314, 0.104659915, 0.9823331, 0.99010897, 0.11194545, 0.16014501, 0.20891832, 0.16376437, 0.9888321, 0.8694704, 0.123999946, 0.92971927, 0.014384789, 0.45497033, 0.94000345, 0.93444407, 0.9329664, 0.007480503, 0.044807915, 0.1132203, 0.9219538, 0.41438484, 0.024374187, 0.047690723, 0.35561326, 0.11272247, 0.5803406, 0.0031416009, 0.021988338, 0.0014736587, 0.24673311, 0.9977596, 0.04189044, 0.7463134, 0.82859755, 0.43856284, 0.08584713, 0.9978109, 0.2338031, 0.021122446, 0.049498253, 0.8450816, 0.8367911, 0.07274726, 0.5544666, 0.97239065, 0.8874368, 0.89229625, 0.10189381, 0.010005268, 0.31738356, 0.40747675, 0.996938, 0.95398027, 0.018511098, 0.86669844, 0.21814682, 0.0066952384, 0.08205886, 0.19395776, 0.0002673477, 0.42135495, 0.7082127, 0.061568193, 0.8063952, 0.0048964545, 0.0023666495, 0.18761437, 0.3264831, 0.029137386, 0.9424266, 0.23479564, 0.94557273, 0.097419515, 0.66512287, 0.92418724, 0.39166868, 0.9998233, 0.8499088, 0.17790899, 0.6574705, 0.03835653, 0.02386475, 0.010073231, 0.003549536, 0.15744542, 0.0015519542, 0.12561634, 0.05527029, 0.05149845, 0.9244244, 0.43246627, 0.3026428, 0.60283947, 0.9088927, 0.0012836887, 0.8919764, 0.5650191, 0.08100764, 0.053910904, 0.88455963, 0.008213038, 0.39258063, 0.9402712, 0.96992636, 0.8925047, 0.9175522, 0.7676621, 0.028973503, 0.05097911, 0.02423228, 0.25343284, 0.03674189, 0.022400517, 0.91298646, 0.9042611, 0.015566707, 0.10370782, 0.6201283, 0.3738944, 0.8425582, 0.24871005, 0.99705124, 0.6880537, 0.13023122, 0.029033337, 0.03188362, 0.9778512, 0.003152007, 0.9687347, 0.9093136, 0.011587543, 0.94591343, 0.98700017, 0.46962568, 0.5235069, 0.046669755, 0.95615405, 0.97115225, 0.96709687, 0.48148385, 0.040141147, 0.0014805864, 0.025801094, 0.59555596, 0.9019349, 0.33332327, 0.7352416, 0.5294225, 0.030331986, 0.023055369, 0.020854454, 0.20164435, 0.0023229504, 0.004131164, 0.44669107, 0.027617987, 0.030320035, 0.015336013, 0.0042619933, 0.001980139, 0.14077353, 0.0005734092, 0.040127244, 0.6223715, 0.03109754, 0.9253844, 0.0140184425, 0.60673606, 0.24724193, 0.0479729, 0.957575, 0.0039482545, 0.60120046, 0.40118122, 0.004818713, 0.69222623, 0.005252128, 0.012603492, 0.008305361, 0.029200284, 0.016684946, 0.015252438, 0.023609588, 0.73652, 0.36373737, 0.21881793, 0.9765545, 0.53698546, 0.97624016, 0.010995998, 0.86534417, 0.04570376, 0.27614892, 0.4232093, 0.07897398, 0.96522784, 0.92581165, 0.007991238, 0.083991535, 0.9718651, 0.9218429, 0.009054058, 0.009349653, 0.37011462, 0.6078311, 0.30546102, 0.96479005, 0.99141556, 0.046032563, 0.022013593, 0.8898446, 0.025605626, 0.006466584, 0.025485007, 0.013361922, 0.88887656, 0.9633251, 0.94431, 0.0055424348, 0.0014707351, 0.00062735274, 0.005519794, 0.3676529, 0.8914991, 0.95325696, 0.0046680286, 0.629332, 0.009476359, 0.09129442, 0.044842213, 0.031111958, 0.58349484, 0.018826906, 0.21575762, 0.9330636, 0.5510949, 0.07208043, 0.6766498, 0.9837924, 0.04065627, 0.9660365, 0.7062164, 0.18611716, 0.9191285, 0.9790025, 0.98498523, 0.3491389, 0.00366643, 0.97330767, 0.015742341, 0.92371875, 0.45762357, 0.009284741, 0.86625963, 0.0049584443, 0.552983, 0.05168834, 0.14627026, 0.0411508, 0.11408479, 0.0006024612, 0.023129366, 0.95871645, 0.95098823, 0.15364607, 0.937455, 0.9559664, 0.9964981, 0.007060475, 0.9553737, 0.1295146, 0.27404046, 0.8237543, 0.70707977, 0.13172463, 0.970489, 0.9622979, 0.0036131558, 0.005272291, 0.0010271511, 0.9984701, 0.13452777, 0.37649417, 0.0034562764, 0.9667618, 0.883911, 0.1794154, 0.005897386, 0.003276083, 0.13617308, 0.006488294, 0.9991379, 0.045938227, 0.14875753, 0.9564605, 0.044796154, 0.64850396, 0.025048397, 0.81227267, 0.08497255, 0.07729111, 0.6528169, 0.8717911, 0.92920953, 0.17116837, 0.37245983, 0.008249395, 0.15467834, 0.46368855, 0.01243839, 0.019965535, 0.1448353, 0.024522522, 0.002402373, 0.9490734, 0.009577294, 0.73444736, 0.8764258, 0.2897168, 0.04548277, 0.25097466, 0.05577679, 0.8795289, 0.9750957, 0.22119062, 0.8428603, 0.0106259, 0.118182115, 0.015374261, 0.03865416, 0.98498595, 0.9677847, 0.22703084, 0.7467043, 0.009880519, 0.78207177, 0.017218344, 0.01744416, 0.36287528, 0.18687983, 0.16151664, 0.15003265, 0.9577813, 0.6926348, 0.3687297, 0.019467575, 0.93638825, 0.78305006, 0.017379997, 0.22053427, 0.0041445135, 0.01090021, 0.9722644])]\n"," [list([0.0004958046, 0.03754995, 0.047766097, 0.0018816233, 0.0762372, 0.21249287, 0.012665165, 0.6244296, 0.009416708, 0.020517115, 0.19398189, 0.020889059, 0.038597766, 0.021094587, 0.41383052, 0.01273654, 0.00075732067, 0.030745933, 0.020791851, 0.00335418, 0.08641099, 0.19881782, 0.052465953, 0.037555583, 0.1209151, 0.30878758, 0.5820493, 0.54763913, 0.065583766, 0.073094115, 0.83974093, 0.006905479, 0.63401675, 0.043589644, 0.016434204, 0.057338543, 0.16130596, 0.6424645, 0.33614308, 0.040112063, 0.13732947, 0.19803394, 0.57966685, 0.07266125, 0.6159309, 0.60764426, 0.88347375, 0.2523205, 0.75174826, 0.59100723, 0.7187914, 0.6563436, 0.029920902, 0.4343244, 0.9780019, 0.16759874, 0.2853935, 0.8712752, 0.9145034, 0.7087842, 0.46281362, 0.19400977, 0.7932637, 0.9346984, 0.8338137, 0.3150982, 0.9677996, 0.58820796, 0.20716193, 0.56801367, 0.025117364, 0.6380365, 0.68114114, 0.48559737, 0.40175858, 0.72072047, 0.73682797, 0.8764205, 0.50663686, 0.7781928, 0.4798479, 0.97863483, 0.37424135, 0.6828833, 0.955824, 0.061715953, 0.96358526, 0.027399568, 0.61550254, 0.16465615, 0.6695987, 0.95658636, 0.2721222, 0.97791404, 0.9618207, 0.13159612, 0.81471556, 0.8677678, 0.7455818, 0.9372002, 0.78098106, 0.35022685, 0.16507865, 0.6987136, 0.7382011, 0.76154053, 0.8294487, 0.7662034, 0.47221348, 0.5963857, 0.7061735, 0.09802477, 0.33113647, 0.96636593, 0.5285631, 0.9702782, 0.84385675, 0.16693118, 0.50466526, 0.21753931])]\n"," [list([0.07838953, 0.059977304, 0.034084395, 0.0021326463, 0.132255, 0.4020842, 0.076540336, 0.5477399, 0.5299341, 0.039104532, 0.22804216, 0.38095567, 0.2862472, 0.37720665, 0.2870238, 0.15909399, 0.032488015, 0.17260279, 0.0072534466, 0.14047645, 0.20156074, 0.41978386, 0.027621657, 0.07161353, 0.31928426, 0.20318437, 0.59304297, 0.2740486, 0.66415626, 0.38462004, 0.57231075, 0.22983979, 0.43601066, 0.26148996, 0.036297467, 0.20725656, 0.7788769, 0.6297114, 0.14027433, 0.82745427, 0.44339636, 0.58293724, 0.75511533, 0.35021982, 0.6629509, 0.40239617, 0.75622183, 0.20962168, 0.51299095, 0.23035197, 0.9227186, 0.8062624, 0.53677976, 0.83214355, 0.9241016, 0.035930205, 0.4347028, 0.94959736, 0.47873986, 0.85124546, 0.90466946, 0.7003849, 0.8854471, 0.64279616, 0.8954595, 0.18308567, 0.85796106, 0.4285171, 0.16393845, 0.37203163, 0.34537804, 0.71089286, 0.33878067, 0.9063397, 0.84707934, 0.4285772, 0.82904434, 0.35333285, 0.5914958, 0.6100269, 0.5596894, 0.8000881, 0.9527979, 0.926689, 0.93510383, 0.6931373, 0.8417571, 0.014131711, 0.39208424, 0.13797224, 0.3655126, 0.96002, 0.79134434, 0.86973447, 0.6330461, 0.3371098, 0.9596733, 0.9213686, 0.72822315, 0.88431066, 0.23434757, 0.97618973, 0.96138364, 0.904885, 0.787828, 0.9490826, 0.20200227, 0.9520414, 0.29453644, 0.4834, 0.4273246, 0.35934803, 0.6791388, 0.93280935, 0.68287426, 0.5176172, 0.71559775, 0.38490433, 0.12973711, 0.030191297])]\n"," [list([0.008810222, 0.04303292, 0.08757807, 0.031033153, 0.14497694, 0.85726506, 0.0020090912, 0.9991511, 0.2755553, 0.4006393, 0.37958065, 0.025097523, 0.10126173, 0.47024518, 0.28682402, 0.24313602, 0.0075866305, 0.032898515, 0.08341197, 0.02850301, 0.5616574, 0.19389604, 0.0010777012, 0.0009534068, 0.19010213, 0.07197011, 0.47374606, 0.0117794685, 0.49210945, 0.51339424, 0.68080145, 0.0021443928, 0.5347407, 0.20600234, 0.021980863, 0.0015189298, 0.18065493, 0.19495319, 0.42889965, 0.539117, 0.20295912, 0.4253377, 0.85622895, 0.3017332, 0.33313695, 0.51834583, 0.6790579, 0.4686015, 0.8506797, 0.12349063, 0.78014094, 0.7641576, 0.10046884, 0.8230583, 0.99555355, 0.6587773, 0.90203655, 0.80397713, 0.769312, 0.789031, 0.34463325, 0.74574274, 0.97616994, 0.8862105, 0.75796705, 0.041541323, 0.7132726, 0.9699024, 0.6259646, 0.35467124, 0.058050916, 0.9164353, 0.2818487, 0.021338465, 0.6443657, 0.96337533, 0.16402829, 0.4659435, 0.38265017, 0.34257248, 0.56916827, 0.98898274, 0.4773405, 0.75862306, 0.441158, 0.03788901, 0.9320912, 0.0042441925, 0.62806046, 0.17165534, 0.8160869, 0.84838843, 0.80416465, 0.9922185, 0.9862184, 0.049650345, 0.70666736, 0.98617965, 0.56107324, 0.9851382, 0.9877841, 0.96743315, 0.9070101, 0.9676309, 0.8069836, 0.9608266, 0.975064, 0.9252384, 0.49432498, 0.8868685, 0.071815304, 0.84853023, 0.32707766, 0.9929223, 0.29003474, 0.39418536, 0.60414964, 0.7619847, 0.12371682, 0.012785324])]\n"," [list([0.0007576203, 0.89270675, 0.5400232, 0.00043855573, 0.092920646, 0.57668525, 0.050742965, 0.009210015, 0.060523644, 0.80575264, 0.9025686, 0.01730423, 0.002743032, 0.56848234, 0.06140682, 0.029194485, 0.076697916, 0.40484634, 0.8140288, 0.06282196, 0.02755423, 0.3559973, 0.1287291, 0.13166268, 0.011611867, 0.031417828, 0.012402829, 0.0045111803, 0.0051238122, 0.04390057, 0.7075113, 0.06853887, 0.93720424, 0.57396483, 0.07997131, 0.005000913, 0.7648781, 0.45843756, 0.15663196, 0.30030423, 0.029277785, 0.8309196, 0.16647589, 0.88427776, 0.01926239, 0.310128, 0.10093101, 0.49930266, 0.00043675926, 0.0010814556, 0.15741485, 0.9512303, 0.001729649, 0.68522257, 0.44793573, 0.8212104, 0.7354307, 0.8361862, 0.11514391, 0.5105903, 0.0015206338, 0.5893032, 0.5809033, 0.23699541, 0.22361445, 0.94533086, 0.05290983, 0.017472494, 0.7553921, 0.10432644, 0.0039659697, 0.00012538461, 0.0035164757, 0.025081316, 0.32696486, 0.9952113, 0.030383278, 0.9763629, 0.052433435, 0.17469642, 0.9872773, 0.043571014, 0.11152302, 0.7817076, 0.12429957, 0.9453265, 0.041380443, 0.0017109343, 0.57463247, 0.017789535, 0.92300874, 0.007256424, 0.052038837, 0.007824425, 0.6595029, 0.10861138, 0.3253563, 0.02096989, 0.8396266, 0.42042732, 0.9500759, 0.35250077, 0.64695984, 0.0035894576, 0.10602597, 0.010174296, 0.037111215, 0.98746467, 0.9953864, 0.014874063, 0.95643365, 0.7359029, 0.58316815, 0.020313632, 0.2408793, 0.0069129528, 0.9228338, 0.77890855, 0.88974005, 0.010997897, 0.9720525, 0.123138405, 0.96146256, 0.19558144, 0.0094789285, 0.43185508, 0.15820517, 0.013746644, 0.22318721, 0.43120846])]\n"," [list([0.01156706, 0.32118165, 0.21583255, 0.06185674, 0.008440972, 0.07317491, 0.06020132, 0.0062219677, 0.17591502, 0.9946977, 0.37500003, 0.22724581, 0.018072505, 0.7471687, 0.015158943, 0.5173762, 0.15527776, 0.36310855, 0.55441016, 0.09611058, 0.09591517, 0.5878885, 0.013099925, 0.17488581, 0.13100669, 0.042979512, 0.0543479, 0.017917352, 0.024223056, 0.40655586, 0.7479075, 0.14556937, 0.9691245, 0.6868666, 0.022174586, 0.5640148, 0.8010326, 0.1708441, 0.77955985, 0.01767576, 0.08639197, 0.640203, 0.45592937, 0.23798203, 0.18332843, 0.12978642, 0.6033655, 0.39067674, 0.013628334, 0.012423258, 0.53893936, 0.4052878, 0.008833304, 0.98932797, 0.92478997, 0.33112147, 0.107235625, 0.7820533, 0.5125911, 0.80206925, 0.012254134, 0.30246606, 0.14049205, 0.8713717, 0.18837094, 0.95265454, 0.09696201, 0.2579739, 0.9178435, 0.14207315, 0.006862156, 0.0035948902, 0.006160047, 0.0685812, 0.16258149, 0.9816027, 0.059379067, 0.7984233, 0.3318725, 0.46048862, 0.90293205, 0.02840917, 0.6466721, 0.4951541, 0.64139295, 0.8506557, 0.08666269, 0.078152664, 0.67146486, 0.017931506, 0.7634054, 0.06195784, 0.3198088, 0.04780411, 0.7767971, 0.1543867, 0.61346674, 0.34274238, 0.9070046, 0.29787463, 0.91442716, 0.052659534, 0.35282367, 0.07318208, 0.3541525, 0.11665202, 0.16335636, 0.89266586, 0.85304654, 0.2381184, 0.7084491, 0.9358026, 0.9684787, 0.21993773, 0.6730067, 0.0072538313, 0.93948424, 0.86854684, 0.7542464, 0.027166236, 0.96765924, 0.29512507, 0.8221724, 0.123415604, 0.014494477, 0.367202, 0.1973893, 0.20143417, 0.084360875, 0.14594965])]\n"," [list([0.054835886, 0.116335854, 0.666035, 0.0011149523, 0.14318424, 0.08156329, 0.010255821, 0.00630576, 0.042129993, 0.82556444, 0.13563891, 0.05252719, 0.013654517, 0.32802227, 0.2136816, 0.77673924, 0.008635389, 0.008959247, 0.74497473, 0.019704988, 0.72608435, 0.047513526, 0.2865483, 0.4216836, 0.07152887, 0.0025656314, 0.0043049827, 0.014963185, 0.0029022025, 0.61544806, 0.25514925, 0.055387754, 0.932277, 0.9463965, 0.14162084, 0.057639204, 0.31690317, 0.11100211, 0.0584358, 0.6248789, 0.15913036, 0.75334454, 0.14566828, 0.10204814, 0.4343246, 0.09486676, 0.15679197, 0.22777502, 0.0013420333, 0.006127426, 0.69880134, 0.9345915, 0.0032289436, 0.81581485, 0.98208237, 0.9105342, 0.75973225, 0.09429017, 0.21457568, 0.9572483, 0.012035531, 0.22786549, 0.46616483, 0.737058, 0.102857634, 0.8212711, 0.0038874832, 0.0074556875, 0.8760409, 0.13160548, 0.055189017, 0.017346023, 0.0013329985, 0.18852535, 0.45919785, 0.91882825, 0.12426314, 0.7766628, 0.6497023, 0.10291533, 0.8950608, 0.017581824, 0.19650012, 0.017626265, 0.13886103, 0.968679, 0.06052046, 0.3417905, 0.95112354, 0.035823517, 0.97477424, 0.0649326, 0.0027748684, 0.008609168, 0.31680283, 0.005380639, 0.694517, 0.0061889705, 0.7023023, 0.3467785, 0.9961927, 0.55281496, 0.37267816, 0.0041621295, 0.042768646, 0.005844464, 0.6599265, 0.9879765, 0.9039552, 0.021191498, 0.8581018, 0.9566638, 0.8085487, 0.043952674, 0.05119684, 0.019160239, 0.96868324, 0.8522396, 0.9085367, 0.020578256, 0.99906117, 0.2871306, 0.89651257, 0.045329597, 0.00047747046, 0.6547416, 0.1672046, 0.08281445, 0.0077717616, 0.9694769])]]\n","(9, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KviwQZNOYSJV","colab_type":"code","colab":{}},"source":["#extracting the number from feature file names\n","\n","test_string = 'name'\n","test_list = test_string.split()\n","xd = test_list[0].split('[')\n","xd2 = xd[2].split(']')\n","xd3 = float(xd2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrrKMCYc5hLd","colab_type":"text"},"source":["CLASSIFIERS"]},{"cell_type":"code","metadata":{"id":"pSIXLXqkqkHq","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","\n","def train_combo(epochs, ax_train, sag_train, cor_train, ground_truth_train, ax_valid, sag_valid, cor_valid, ground_truth_valid):\n","  #init\n","  valid_baseline_auc = 0\n","  rfc = RandomForestClassifier(n_estimators=1, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n","                               min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n","                               min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n","                               warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n","  #updated_rfc = rfc\n","  \n","  X = np.concatenate((np.expand_dims(np.array(ax_train),axis=1), np.expand_dims(np.array(sag_train),axis=1), \n","                      np.expand_dims(np.array(cor_train),axis=1)), axis=1)\n","  print('X shape', X.shape)\n","  y = np.array(ground_truth_train)\n","  print('Y shape', y.shape)\n","  auclist = []\n","\n","  for epoch in range(epochs):\n","    old_rfc = rfc\n","    cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n","    fprs, tprs, scores = [], [], []\n","    #fpr, tpr, threshold = metrics.roc_curve(labels, preds)\n","    #print(\"threshold is: \", threshold)\n","    #auc = metrics.auc(fpr, tpr)\n","\n","    #for (train, test), i in zip(cv.split(X, y), range(5)):\n","    #    rfc.fit(X[train], y[train])\n","        #_, _, auc_score_train = compute_roc_auc(train)\n","        #fpr, tpr, auc_score = compute_roc_auc(test)\n","    #    y_preds = rfc.predict(X[test])\n","    #    fpr, tpr, threshold = metrics.roc_curve(y[test], y_preds)\n","    #    auc = metrics.auc(fpr, tpr)\n","    #    scores.append(auc)\n","    #    fprs.append(fpr)\n","    #    tprs.append(tpr)\n","    rfc.fit(X, y)\n","\n","    #print('epoch ' + str(epoch), scores)\n","    X_valid = np.concatenate((np.expand_dims(np.array(ax_valid),axis=1), np.expand_dims(np.array(sag_valid),axis=1), \n","                        np.expand_dims(np.array(cor_valid),axis=1)), axis=1)\n","    #print('X shape', X_valid.shape)\n","    y_valid = np.array(ground_truth_valid)\n","    #print('Y shape', y_valid.shape)\n","    y_valid_preds = rfc.predict(X_valid)\n","    fpr, tpr, threshold = metrics.roc_curve(y_valid, y_valid_preds)\n","    auc = metrics.auc(fpr, tpr)\n","    print('valid epoch ' + str(epoch), auc)\n","\n","    if auc > valid_baseline_auc:\n","      valid_baseline_auc = auc\n","    else:\n","      rfc = old_rfc\n","\n","    auclist.append(auc)\n","\n","  return rfc, auclist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wqoyeHkUxAW","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","\n","\n","def train_gridsearch(ax_train, sag_train, cor_train, ground_truth_train, ax_valid, sag_valid, cor_valid, ground_truth_valid):\n","\n","  X = np.concatenate((np.expand_dims(np.array(ax_train),axis=1), np.expand_dims(np.array(sag_train),axis=1), \n","                      np.expand_dims(np.array(cor_train),axis=1)), axis=1)\n","  y = np.array(ground_truth_train)\n","\n","  n_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 10)]\n","  max_features = ['auto', 'sqrt']\n","  max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","  max_depth.append(None)\n","  min_samples_split = [2, 5, 10]\n","  min_samples_leaf = [1, 2, 4]\n","  bootstrap = [True, False]\n","  random_grid = {'n_estimators': n_estimators,\n","                'max_features': max_features,\n","                'max_depth': max_depth,\n","                'min_samples_split': min_samples_split,\n","                'min_samples_leaf': min_samples_leaf,\n","                'bootstrap': bootstrap}\n","\n","  rfc = RandomForestClassifier()\n","  # Random search of parameters, using 3 fold cross validation, \n","  # search across 100 different combinations, and use all available cores\n","  rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n","  # Fit the random search model\n","  rfc_random.fit(X, y)\n","\n","  X_valid = np.concatenate((np.expand_dims(np.array(ax_valid),axis=1), np.expand_dims(np.array(sag_valid),axis=1), \n","                        np.expand_dims(np.array(cor_valid),axis=1)), axis=1)\n","  #print('X shape', X_valid.shape)\n","  y_valid = np.array(ground_truth_valid)\n","  #print('Y shape', y_valid.shape)\n","  y_valid_preds = rfc_random.predict(X_valid)\n","  fpr, tpr, threshold = metrics.roc_curve(y_valid, y_valid_preds)\n","  auc = metrics.auc(fpr, tpr)\n","  print('valid auc ' , auc)\n","\n","  return rfc_random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ESWDhQjqkKB","colab_type":"code","outputId":"4b614c44-2702-4563-8f26-2baa4f1e9f0b","executionInfo":{"status":"ok","timestamp":1584859284991,"user_tz":240,"elapsed":20498,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDNUmrksb7ajH78ufM6_UhkFXwnC92mfPrGlVMselGrCi2rbtT0RQTAE_W4zYdJlR6aRmzSVhjT80-h3VIfU6oz4DdPcu1COE603poXAwZZwbjxVz7SdY15e4W-G1rSf0GdaX0RhwIQ3SCH7giErHIWSqvBbBvd6sPUBCVgz8GihsOSy95wrKgqRwkP1RYUlrR7BxEExDGXAZfVBPT9U9rVFnj_5OfLaLDSope-ENe1fImfSvHG_YxuUfNYgYDkt_iwJ_fZOtnZN1YoVk04CYKPxemoL3vhDb70jPfCUsYujJYeOzdApu63nJPpw4t6Tw043CpVLDWu8TlmMjPVFnxTViBUWTQ5wk_Pi0H5Nuy4H23usZTaF7MUXZg9a6b_T9AUCYLalA1Q9hnZhE4-tf0fhSz_F-yahMY8vdcF4gp3FLrysZMZxL9ntqnmBbG2_s0X17adoEfSrFfVbE4396BHDBbGmhhJ8ExSaYjLeWnoPlGjLWBxsOMuqnvRdUcml6BWDDkiusX6JgGH1EAJ9vl43dmYTwMdo_xNS9T4RfzHvHIfREZfOgUYalTU9UWYsw7Vnd1mM-CaC8mxVvfTmPX2HDu78BxDQeUkI1Yr40DBz3Ksj8shOu9Qcdt8vWGmLWkSXnbM8Yb1Yzi1NCx6stye_S25D94XuMWaXUErG8gua7KVULH7-4SOnZ9xQCza5-r-R8boJnclvGWaxk69gwjFE--isLStSMqZ7w-_wXwcFSsS5V0-wwKqlroqAX7fqzrw=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# ACL\n","ACL_train_axial_preds = predslist_ACL[0][0]\n","ACL_train_sagittal_preds = predslist_ACL[1][0]\n","ACL_train_coronal_preds = predslist_ACL[2][0]\n","\n","ACL_valid_axial_preds = predslist_ACL[3][0]\n","ACL_valid_sagittal_preds = predslist_ACL[4][0]\n","ACL_valid_coronal_preds = predslist_ACL[5][0]\n","\n","#print(ACL_train_axial_preds)\n","#print(len(ACL_train_axial_preds), len(ACL_train_sagittal_preds), len(ACL_train_coronal_preds), len(train_ACL_labels))\n","\n","rfc_random = train_gridsearch(ACL_train_axial_preds, ACL_train_sagittal_preds, ACL_train_coronal_preds, train_ACL_labels, \n","                      ACL_valid_axial_preds, ACL_valid_sagittal_preds, ACL_valid_coronal_preds, valid_ACL_labels)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n","[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   10.1s\n","[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   18.2s finished\n"],"name":"stderr"},{"output_type":"stream","text":["valid auc  0.8106060606060606\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bEJNkXHsmzdo","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","\n","def train_nn(ax_train, sag_train, cor_train, ground_truth_train, ax_valid, sag_valid, cor_valid, ground_truth_valid):\n","  X_train = np.concatenate((np.array(ax_train), np.array(sag_train), np.array(cor_train)), axis=1)\n","  Y_train = np.array(ground_truth_train)\n","  X_valid = np.concatenate((np.array(ax_valid), np.array(sag_valid), np.array(cor_valid)), axis=1)\n","  Y_valid = np.array(ground_truth_valid)\n","\n","  clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n","  clf.fit(X_train, y_train)\n","\n","  print(\"score\", clf.score)\n","  y_pred = clf.predict(X_valid)\n","  fpr, tpr, threshold = metrics.roc_curve(Y_valid, y_pred)\n","  auc = metrics.auc(fpr, tpr)\n","  print('auc', auc)\n","  return X_train, Y_train"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDrScDNH65NZ","colab_type":"code","outputId":"5d8fc700-0e30-4880-aacd-13f9c60e861f","executionInfo":{"status":"error","timestamp":1584859284998,"user_tz":240,"elapsed":20494,"user":{"displayName":"Miles Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQDNUmrksb7ajH78ufM6_UhkFXwnC92mfPrGlVMselGrCi2rbtT0RQTAE_W4zYdJlR6aRmzSVhjT80-h3VIfU6oz4DdPcu1COE603poXAwZZwbjxVz7SdY15e4W-G1rSf0GdaX0RhwIQ3SCH7giErHIWSqvBbBvd6sPUBCVgz8GihsOSy95wrKgqRwkP1RYUlrR7BxEExDGXAZfVBPT9U9rVFnj_5OfLaLDSope-ENe1fImfSvHG_YxuUfNYgYDkt_iwJ_fZOtnZN1YoVk04CYKPxemoL3vhDb70jPfCUsYujJYeOzdApu63nJPpw4t6Tw043CpVLDWu8TlmMjPVFnxTViBUWTQ5wk_Pi0H5Nuy4H23usZTaF7MUXZg9a6b_T9AUCYLalA1Q9hnZhE4-tf0fhSz_F-yahMY8vdcF4gp3FLrysZMZxL9ntqnmBbG2_s0X17adoEfSrFfVbE4396BHDBbGmhhJ8ExSaYjLeWnoPlGjLWBxsOMuqnvRdUcml6BWDDkiusX6JgGH1EAJ9vl43dmYTwMdo_xNS9T4RfzHvHIfREZfOgUYalTU9UWYsw7Vnd1mM-CaC8mxVvfTmPX2HDu78BxDQeUkI1Yr40DBz3Ksj8shOu9Qcdt8vWGmLWkSXnbM8Yb1Yzi1NCx6stye_S25D94XuMWaXUErG8gua7KVULH7-4SOnZ9xQCza5-r-R8boJnclvGWaxk69gwjFE--isLStSMqZ7w-_wXwcFSsS5V0-wwKqlroqAX7fqzrw=s64","userId":"12217843719772555429"}},"colab":{"base_uri":"https://localhost:8080/","height":351}},"source":["ACL_train_axial_preds = predslist_ACL[0][0]\n","ACL_train_sagittal_preds = predslist_ACL[1][0]\n","ACL_train_coronal_preds = predslist_ACL[2][0]\n","\n","ACL_valid_axial_preds = predslist_ACL[3][0]\n","ACL_valid_sagittal_preds = predslist_ACL[4][0]\n","ACL_valid_coronal_preds = predslist_ACL[5][0]\n","\n","x_train, y_train = train_nn(ACL_train_axial_preds, ACL_train_sagittal_preds, ACL_train_coronal_preds, train_ACL_labels, \n","                      ACL_valid_axial_preds, ACL_valid_sagittal_preds, ACL_valid_coronal_preds, valid_ACL_labels)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AxisError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-9403c2b47e21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m x_train, y_train = train_nn(ACL_train_axial_preds, ACL_train_sagittal_preds, ACL_train_coronal_preds, train_ACL_labels, \n\u001b[0;32m---> 10\u001b[0;31m                       ACL_valid_axial_preds, ACL_valid_sagittal_preds, ACL_valid_coronal_preds, valid_ACL_labels)\n\u001b[0m","\u001b[0;32m<ipython-input-28-b643354c4cc3>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(ax_train, sag_train, cor_train, ground_truth_train, ax_valid, sag_valid, cor_valid, ground_truth_valid)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msag_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcor_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msag_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcor_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msag_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msag_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"]}]},{"cell_type":"code","metadata":{"id":"a7meYHyTmzxH","colab_type":"code","colab":{}},"source":["# neural net try 2\n","\n","# Load libraries\n","import numpy as np\n","from keras import models\n","from keras import layers\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.datasets import make_classification\n","\n","# Set random seed\n","np.random.seed(0)\n","\n","\n","# Create function returning a compiled network\n","def create_network():\n","    \n","    # Start neural network\n","    network = models.Sequential()\n","\n","    # Add fully connected layer with a ReLU activation function\n","    network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\n","\n","    # Add fully connected layer with a ReLU activation function\n","    network.add(layers.Dense(units=16, activation='relu'))\n","\n","    # Add fully connected layer with a sigmoid activation function\n","    network.add(layers.Dense(units=1, activation='sigmoid'))\n","\n","    # Compile neural network\n","    network.compile(loss='binary_crossentropy', # Cross-entropy\n","                    optimizer='rmsprop', # Root Mean Square Propagation\n","                    metrics=['accuracy']) # Accuracy performance metric\n","    \n","    # Return compiled network\n","    return network\n","\n","# Wrap Keras model so it can be used by scikit-learn\n","neural_network = KerasClassifier(build_fn=create_network, \n","                                 epochs=10, \n","                                 batch_size=100, \n","                                 verbose=0)\n","\n","features = x_train\n","target = y_train\n","\n","cross_val_score(neural_network, features, target, cv=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ho3dCx4QuCL3","colab_type":"code","colab":{}},"source":["def linechart(x, y, title, xlabel, ylabel):\n","  plt.figure()\n","  plt.title(title)\n","  plt.plot(x, y)\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.show()\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hraU3f1U1HhQ","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","linechart(np.arange(1000), np.array(auclist), 'title', 'epoch', 'auc')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XL0VcabnSSy2","colab_type":"code","colab":{}},"source":["def test_rfc(rfc, ax_pred, sag_pred, cor_pred, ground_truth):\n","  rfc_test = rfc\n","  X = np.concatenate((np.expand_dims(np.array(ax_pred),axis=1), np.expand_dims(np.array(sag_pred),axis=1), \n","                      np.expand_dims(np.array(cor_pred),axis=1)), axis=1)\n","  print('X shape', X.shape)\n","  y = np.array(ground_truth)\n","  print('Y shape', y.shape)\n","  y_preds = rfc.predict(X)\n","  fpr, tpr, threshold = metrics.roc_curve(y, y_preds)\n","  auc = metrics.auc(fpr, tpr)\n","  return fpr, tpr, auc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYTqj1aanekV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOy6NTUgqkMV","colab_type":"code","colab":{}},"source":["a, b, c = test_rfc(acl_rfc, predslist_ACL[3][0], predslist_ACL[4][0], predslist_ACL[5][0], valid_ACL_labels)\n","\n","print(a, b, c)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwZyoU7nNd-s","colab_type":"code","colab":{}},"source":["def test_meme(threshold, ax_pred, sag_pred, cor_pred, ground_truth):\n","  X = np.concatenate((np.expand_dims(np.array(ax_pred),axis=1), np.expand_dims(np.array(sag_pred),axis=1), \n","                      np.expand_dims(np.array(cor_pred),axis=1)), axis=1)\n","  print('X shape', X.shape)\n","  y = np.array(ground_truth)\n","  print('Y shape', y.shape)\n","  newX = np.divide(np.sum(X, axis=1), 3)\n","  for index in range(newX.shape[0]):\n","    if round(newX[index]) > threshold:\n","      print('memes')\n","      newX[index] = 1\n","    else:\n","      newX[index] = 0    \n","  fpr, tpr, threshold = metrics.roc_curve(y, newX)\n","  auc = metrics.auc(fpr, tpr)\n","  return fpr, tpr, auc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SW9s9TiZNugu","colab_type":"code","colab":{}},"source":["#thresholds = np.divide(np.arange(10), 10)\n","thresholds = [1.0]\n","print(thresholds)\n","\n","for threshold in thresholds:\n","  print(threshold)\n","  a, b, c = test_meme(threshold, predslist_ACL[3][0], predslist_ACL[4][0], predslist_ACL[5][0], valid_ACL_labels)\n","  print(a, b, c)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7S28lXzefujy","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","\n","def train_combo(diagnosis, ax_pred, sag_pred, cor_pred, ground_truth):\n","  X = np.concatenate((np.array(ax_pred), np.array(sag_pred), np.array(cor_pred)), axis=1)\n","  Y = \n","\n","clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n","...                     hidden_layer_sizes=(5, 2), random_state=1)\n","...\n",">>> clf.fit(X, y)\n","MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n","              solver='lbfgs')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-jXdUzkGKEgr","colab_type":"code","colab":{}},"source":["#ax w/ aug\n","aug = True\n","epochs = 50\n","diagnosis = 'abnormal'\n","orientation = 'coronal'\n","lr = 1e-05\n","varray1, tarray1, testarray1 = train(rundir, diagnosis, orientation, epochs, lr, aug, gpu)\n","title = 'alexnet RAdam ' + diagnosis + ' ' + orientation + ' lr = ' + str(lr)\n","display_single(epochs, lr, varray1, tarray1, testarray1, title + ' aug = ' + str(aug) + \" + new transforms\", 'epoch', 'AUC', savedir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bjfA00uyLEx1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}